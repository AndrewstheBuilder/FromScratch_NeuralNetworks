{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSK0Eap+7iTsZlnWye5L0p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewstheBuilder/ScratchNeuralNetworks/blob/main/Iris_Micrograd_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VKKg7oHwBclr"
      },
      "outputs": [],
      "source": [
        "# Load the Iris Dataset\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels (0, 1, or 2)\n",
        "\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do preprocessing\n",
        "print('Features of dataset:',X[0])\n",
        "print('Labels of dataset:',y)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "PLFh7xBlBiuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec2063a-a08c-470e-bdab-53486fc1a73b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features of dataset: [-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
            "Labels of dataset: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install micrograd_andrews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90aelMJI0Y5a",
        "outputId": "4790a911-4a17-4a8a-9e9f-ce49547f6fdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting micrograd_andrews\n",
            "  Downloading micrograd_andrews-0.1.8-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading micrograd_andrews-0.1.8-py2.py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: micrograd_andrews\n",
            "Successfully installed micrograd_andrews-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def softmax(logits):\n",
        "    exps = [logit.exp() for logit in logits]\n",
        "    sum_exps = sum(exps)\n",
        "    return [exp_i / sum_exps for exp_i in exps]\n",
        "\n",
        "def cross_entropy(probs, label):\n",
        "    # Convert label to one-hot encoding\n",
        "    one_hot = [0] * len(probs)\n",
        "    one_hot[label] = 1\n",
        "    # Compute cross-entropy loss\n",
        "    loss = -sum((p_i + 1e-9).log() * y_i for p_i, y_i in zip(probs, one_hot))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aeeQy94_7FFy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Micrograd MLP to solve the Iris dataset.\n",
        "from micrograd_andrews.engine import Value\n",
        "from micrograd_andrews.nn import Neuron, Layer, MLP\n",
        "\n",
        "model = MLP(X.shape[0], [2,3])\n",
        "# Begin gradient descent iterations\n",
        "parameters_data_log = []\n",
        "parameters_grad_log = []\n",
        "# Hyperparameters\n",
        "learning_rate = 0.05\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "  correct = 0\n",
        "  parameters_data_log.append([])\n",
        "  parameters_grad_log.append([])\n",
        "  total_loss = 0.0\n",
        "  for i in range(len(X_train)):\n",
        "    logits = model(X_train[i])\n",
        "    # print(logits)\n",
        "    probs = softmax(logits)\n",
        "    y_true = y_train[i]\n",
        "    loss = cross_entropy(probs, y_true)\n",
        "    total_loss += loss.data\n",
        "    # print('actual loss:',loss.data)\n",
        "\n",
        "    # Prediction\n",
        "    pred_label = probs.index(max(probs, key=lambda p: p.data))\n",
        "    if pred_label == y_true:\n",
        "      correct += 1\n",
        "\n",
        "    # Back propagation\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    for p in model.parameters():\n",
        "      parameters_data_log[epoch].append(p.data)\n",
        "      parameters_grad_log[epoch].append(p.grad)\n",
        "      p.data -= learning_rate * p.grad\n",
        "\n",
        "  accuracy = correct / len(X_train) * 100\n",
        "  avg_loss = total_loss / len(X_train)\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "NVDDCukmBkKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a478b49-cda2-4bf0-b516-86afa1ef00f1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.9142, Accuracy: 60.00%\n",
            "Epoch 2/50, Loss: 0.6492, Accuracy: 79.17%\n",
            "Epoch 3/50, Loss: 0.5098, Accuracy: 81.67%\n",
            "Epoch 4/50, Loss: 0.4270, Accuracy: 85.00%\n",
            "Epoch 5/50, Loss: 0.3630, Accuracy: 86.67%\n",
            "Epoch 6/50, Loss: 0.3087, Accuracy: 89.17%\n",
            "Epoch 7/50, Loss: 0.2679, Accuracy: 93.33%\n",
            "Epoch 8/50, Loss: 0.2347, Accuracy: 95.00%\n",
            "Epoch 9/50, Loss: 0.2084, Accuracy: 95.83%\n",
            "Epoch 10/50, Loss: 0.1881, Accuracy: 95.83%\n",
            "Epoch 11/50, Loss: 0.1727, Accuracy: 96.67%\n",
            "Epoch 12/50, Loss: 0.1606, Accuracy: 96.67%\n",
            "Epoch 13/50, Loss: 0.1511, Accuracy: 96.67%\n",
            "Epoch 14/50, Loss: 0.1437, Accuracy: 95.83%\n",
            "Epoch 15/50, Loss: 0.1372, Accuracy: 95.83%\n",
            "Epoch 16/50, Loss: 0.1316, Accuracy: 95.83%\n",
            "Epoch 17/50, Loss: 0.1260, Accuracy: 95.83%\n",
            "Epoch 18/50, Loss: 0.1211, Accuracy: 95.83%\n",
            "Epoch 19/50, Loss: 0.1154, Accuracy: 95.83%\n",
            "Epoch 20/50, Loss: 0.1111, Accuracy: 95.83%\n",
            "Epoch 21/50, Loss: 0.1070, Accuracy: 95.83%\n",
            "Epoch 22/50, Loss: 0.1033, Accuracy: 96.67%\n",
            "Epoch 23/50, Loss: 0.1000, Accuracy: 96.67%\n",
            "Epoch 24/50, Loss: 0.0970, Accuracy: 96.67%\n",
            "Epoch 25/50, Loss: 0.0942, Accuracy: 96.67%\n",
            "Epoch 26/50, Loss: 0.0917, Accuracy: 96.67%\n",
            "Epoch 27/50, Loss: 0.0893, Accuracy: 96.67%\n",
            "Epoch 28/50, Loss: 0.0872, Accuracy: 96.67%\n",
            "Epoch 29/50, Loss: 0.0851, Accuracy: 96.67%\n",
            "Epoch 30/50, Loss: 0.0833, Accuracy: 96.67%\n",
            "Epoch 31/50, Loss: 0.0817, Accuracy: 96.67%\n",
            "Epoch 32/50, Loss: 0.0802, Accuracy: 96.67%\n",
            "Epoch 33/50, Loss: 0.0791, Accuracy: 96.67%\n",
            "Epoch 34/50, Loss: 0.0781, Accuracy: 96.67%\n",
            "Epoch 35/50, Loss: 0.0774, Accuracy: 96.67%\n",
            "Epoch 36/50, Loss: 0.0769, Accuracy: 95.83%\n",
            "Epoch 37/50, Loss: 0.0765, Accuracy: 95.83%\n",
            "Epoch 38/50, Loss: 0.0763, Accuracy: 95.83%\n",
            "Epoch 39/50, Loss: 0.0762, Accuracy: 95.83%\n",
            "Epoch 40/50, Loss: 0.0761, Accuracy: 95.83%\n",
            "Epoch 41/50, Loss: 0.0760, Accuracy: 95.83%\n",
            "Epoch 42/50, Loss: 0.0759, Accuracy: 95.83%\n",
            "Epoch 43/50, Loss: 0.0758, Accuracy: 95.83%\n",
            "Epoch 44/50, Loss: 0.0756, Accuracy: 95.83%\n",
            "Epoch 45/50, Loss: 0.0754, Accuracy: 96.67%\n",
            "Epoch 46/50, Loss: 0.0752, Accuracy: 96.67%\n",
            "Epoch 47/50, Loss: 0.0749, Accuracy: 96.67%\n",
            "Epoch 48/50, Loss: 0.0746, Accuracy: 96.67%\n",
            "Epoch 49/50, Loss: 0.0742, Accuracy: 96.67%\n",
            "Epoch 50/50, Loss: 0.0738, Accuracy: 96.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean of data:',np.mean(parameters_data_log, axis=1))\n",
        "print('mean of gradients:',np.mean(parameters_grad_log, axis=1))\n",
        "# np.array(parameters_grad_log).shape\n",
        "# np.array(X_train).shape\n",
        "np.mean(X_train, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzSgYm2f_L8e",
        "outputId": "8415be35-5c43-461c-900b-a59b2c8a9e27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean of data: [-0.01539417 -0.01420393 -0.01227521 -0.00939283 -0.00859827 -0.00905091\n",
            " -0.00953515 -0.00984313 -0.01003877 -0.010176   -0.01025027 -0.01031221\n",
            " -0.01036213 -0.01040266 -0.01041716 -0.0104329  -0.01044461 -0.01047293\n",
            " -0.01050355 -0.01053295 -0.01056191 -0.0105904  -0.01061821 -0.01064515\n",
            " -0.01066955 -0.01069434 -0.01071737 -0.01073871 -0.01075019 -0.01076631\n",
            " -0.0107823  -0.01079722 -0.01081083 -0.01082307 -0.01083395 -0.0108435\n",
            " -0.01085173 -0.01085868 -0.01086438 -0.01086885 -0.01087214 -0.01087428\n",
            " -0.01087531 -0.01087527 -0.01087419 -0.01087212 -0.01086909 -0.01086515\n",
            " -0.01086034 -0.01085338]\n",
            "mean of gradients: [-3.14051216e-04 -1.91944797e-04 -5.57054037e-04 -3.76698499e-04\n",
            "  3.99633222e-05  9.15690047e-05  7.68433242e-05  5.80188461e-05\n",
            "  3.95525287e-05  3.04725239e-05  1.71785614e-05  1.37203783e-05\n",
            "  1.08008000e-05  9.51346255e-06  6.91381697e-06  6.45727158e-06\n",
            "  4.97921455e-06  6.22610900e-06  5.93084579e-06  5.85492958e-06\n",
            "  5.78929621e-06  5.68952391e-06  5.55196624e-06  5.38169456e-06\n",
            "  5.08125012e-06  4.90985704e-06  4.59756570e-06  4.32354744e-06\n",
            "  3.45959021e-06  3.50904493e-06  3.34258555e-06  3.11767048e-06\n",
            "  2.87883761e-06  2.63861750e-06  2.40061240e-06  2.16606086e-06\n",
            "  1.93563482e-06  1.70988387e-06  1.48931508e-06  1.27438789e-06\n",
            "  1.06549887e-06  8.62972540e-07  6.67059528e-07  4.77939793e-07\n",
            "  2.95728870e-07  1.20485499e-07 -4.77803877e-08 -2.09099938e-07\n",
            " -3.63538250e-07 -2.24706303e-06]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.78508498,  0.14538307,  0.44131506, -0.75434329, -1.03323761,\n",
              "        0.22464841,  0.45510575, -0.58983559, -0.60707969, -0.27744848,\n",
              "        0.20249631,  0.48194431,  0.51685118, -0.26165751, -0.41415327,\n",
              "       -0.55613057,  0.27987316,  0.63837427,  0.3534739 ,  1.48406843,\n",
              "       -0.03802976,  1.19935575,  0.09767163, -0.63433691,  1.09585064,\n",
              "       -0.23576967, -0.66159413, -0.64593019, -0.32482646, -0.96620589,\n",
              "        0.29262939, -0.71171522, -0.92395612, -0.60808308, -0.18342011,\n",
              "       -0.67767674, -0.01338861,  1.73715865, -0.95844432,  0.12763944,\n",
              "        0.07580465, -0.1103247 ,  0.36019171,  0.20249631, -0.47714105,\n",
              "        0.03708769,  0.90076878, -0.47232756, -0.20482008, -0.82197703,\n",
              "        0.41266683, -0.77972726, -0.86569517, -0.50901317,  0.56774615,\n",
              "       -0.91090825,  0.42458573, -0.70796871, -0.50457798,  0.44499812,\n",
              "       -0.6863067 ,  1.04034224,  0.16435611,  0.14232958,  1.22441702,\n",
              "       -0.35722917, -1.19167583, -1.23995472, -0.17050725,  1.00930598,\n",
              "       -1.00178416, -0.60142886, -1.148336  ,  0.07880687,  0.99238751,\n",
              "       -0.81043789,  0.80071708,  1.02458379, -0.94236171,  0.18709294,\n",
              "        0.26941031,  0.30567726,  0.63236822,  0.83204497, -0.43327062,\n",
              "        0.87434889,  0.14591946,  0.63430506, -0.40886697, -0.314308  ,\n",
              "        0.23043278, -1.48798033,  0.29143538, -0.2757506 , -0.44444523,\n",
              "       -0.02498189,  0.90957844,  0.9714914 , -0.43921308, -0.79471981,\n",
              "        1.10312359,  0.79997279, -0.6702797 ,  0.9409078 , -0.9826668 ,\n",
              "        0.60585383,  0.88681055,  0.50719327, -0.10978831,  0.61111704,\n",
              "       -0.17315439,  0.18822337,  0.2039509 ,  0.37252781, -0.55838213,\n",
              "       -0.00282979, -0.33630201, -0.16296589, -0.24171213,  0.94843041])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    y_true = y_test[i]\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(X_test[i])\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Prediction\n",
        "    pred_label = probs.index(max(probs, key=lambda p: p.data))\n",
        "    if pred_label == y_true:\n",
        "        correct += 1\n",
        "\n",
        "test_accuracy = correct / len(X_test) * 100\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4wVrD_19j23",
        "outputId": "c6916ac8-3048-40dd-9aa4-136761662616"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.67%\n"
          ]
        }
      ]
    }
  ]
}