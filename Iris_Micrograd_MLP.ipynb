{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa/o8GBuK+Z3lUEGITO4Hi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewstheBuilder/ScratchNeuralNetworks/blob/main/Iris_Micrograd_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VKKg7oHwBclr"
      },
      "outputs": [],
      "source": [
        "# Load the Iris Dataset\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Labels (0, 1, or 2)\n",
        "\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do preprocessing\n",
        "print('Features of dataset:',X[0])\n",
        "print('Labels of dataset:',y)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "PLFh7xBlBiuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec2063a-a08c-470e-bdab-53486fc1a73b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features of dataset: [-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
            "Labels of dataset: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install micrograd_andrews"
      ],
      "metadata": {
        "id": "90aelMJI0Y5a",
        "outputId": "4790a911-4a17-4a8a-9e9f-ce49547f6fdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting micrograd_andrews\n",
            "  Downloading micrograd_andrews-0.1.8-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading micrograd_andrews-0.1.8-py2.py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: micrograd_andrews\n",
            "Successfully installed micrograd_andrews-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def softmax(logits):\n",
        "    exps = [logit.exp() for logit in logits]\n",
        "    sum_exps = sum(exps)\n",
        "    return [exp_i / sum_exps for exp_i in exps]\n",
        "\n",
        "def cross_entropy(probs, label):\n",
        "    # Convert label to one-hot encoding\n",
        "    one_hot = [0] * len(probs)\n",
        "    one_hot[label] = 1\n",
        "    # Compute cross-entropy loss\n",
        "    loss = -sum((p_i + 1e-9).log() * y_i for p_i, y_i in zip(probs, one_hot))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aeeQy94_7FFy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Micrograd MLP to solve the Iris dataset.\n",
        "from micrograd_andrews.engine import Value\n",
        "from micrograd_andrews.nn import Neuron, Layer, MLP\n",
        "\n",
        "model = MLP(X.shape[0], [2,3])\n",
        "# Begin gradient descent iterations\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.05\n",
        "epochs = 50\n",
        "total_loss = 0.0\n",
        "for epoch in range(epochs):\n",
        "  correct = 0\n",
        "  for i in range(len(X_train)):\n",
        "    logits = model(X_train[i])\n",
        "    # print(logits)\n",
        "    probs = softmax(logits)\n",
        "    y_true = y_train[i]\n",
        "    loss = cross_entropy(probs, y_true)\n",
        "    total_loss += loss.data\n",
        "\n",
        "    # Prediction\n",
        "    pred_label = probs.index(max(probs, key=lambda p: p.data))\n",
        "    if pred_label == y_true:\n",
        "      correct += 1\n",
        "\n",
        "    # Back propagation\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    for p in model.parameters():\n",
        "      p.data -= learning_rate * p.grad\n",
        "      avg_loss = total_loss / len(X_train)\n",
        "\n",
        "  accuracy = correct / len(X_train) * 100\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "NVDDCukmBkKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5182b0b-1bf0-4689-e323-37fdc85bebbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.7606, Accuracy: 78.33%\n",
            "Epoch 2/50, Loss: 1.2923, Accuracy: 85.83%\n",
            "Epoch 3/50, Loss: 1.6955, Accuracy: 88.33%\n",
            "Epoch 4/50, Loss: 2.0011, Accuracy: 93.33%\n",
            "Epoch 5/50, Loss: 2.2333, Accuracy: 95.83%\n",
            "Epoch 6/50, Loss: 2.4165, Accuracy: 95.83%\n",
            "Epoch 7/50, Loss: 2.5683, Accuracy: 96.67%\n",
            "Epoch 8/50, Loss: 2.6998, Accuracy: 96.67%\n",
            "Epoch 9/50, Loss: 2.8175, Accuracy: 96.67%\n",
            "Epoch 10/50, Loss: 2.9254, Accuracy: 96.67%\n",
            "Epoch 11/50, Loss: 3.0260, Accuracy: 96.67%\n",
            "Epoch 12/50, Loss: 3.1211, Accuracy: 96.67%\n",
            "Epoch 13/50, Loss: 3.2118, Accuracy: 96.67%\n",
            "Epoch 14/50, Loss: 3.2991, Accuracy: 96.67%\n",
            "Epoch 15/50, Loss: 3.3835, Accuracy: 96.67%\n",
            "Epoch 16/50, Loss: 3.4656, Accuracy: 96.67%\n",
            "Epoch 17/50, Loss: 3.5457, Accuracy: 96.67%\n",
            "Epoch 18/50, Loss: 3.6240, Accuracy: 96.67%\n",
            "Epoch 19/50, Loss: 3.7009, Accuracy: 95.83%\n",
            "Epoch 20/50, Loss: 3.7766, Accuracy: 95.83%\n",
            "Epoch 21/50, Loss: 3.8512, Accuracy: 95.83%\n",
            "Epoch 22/50, Loss: 3.9249, Accuracy: 95.83%\n",
            "Epoch 23/50, Loss: 3.9979, Accuracy: 95.83%\n",
            "Epoch 24/50, Loss: 4.0702, Accuracy: 95.83%\n",
            "Epoch 25/50, Loss: 4.1421, Accuracy: 95.83%\n",
            "Epoch 26/50, Loss: 4.2134, Accuracy: 96.67%\n",
            "Epoch 27/50, Loss: 4.2844, Accuracy: 96.67%\n",
            "Epoch 28/50, Loss: 4.3551, Accuracy: 96.67%\n",
            "Epoch 29/50, Loss: 4.4254, Accuracy: 96.67%\n",
            "Epoch 30/50, Loss: 4.4956, Accuracy: 96.67%\n",
            "Epoch 31/50, Loss: 4.5656, Accuracy: 96.67%\n",
            "Epoch 32/50, Loss: 4.6354, Accuracy: 96.67%\n",
            "Epoch 33/50, Loss: 4.7050, Accuracy: 96.67%\n",
            "Epoch 34/50, Loss: 4.7745, Accuracy: 96.67%\n",
            "Epoch 35/50, Loss: 4.8439, Accuracy: 96.67%\n",
            "Epoch 36/50, Loss: 4.9133, Accuracy: 96.67%\n",
            "Epoch 37/50, Loss: 4.9825, Accuracy: 96.67%\n",
            "Epoch 38/50, Loss: 5.0518, Accuracy: 96.67%\n",
            "Epoch 39/50, Loss: 5.1210, Accuracy: 96.67%\n",
            "Epoch 40/50, Loss: 5.1902, Accuracy: 97.50%\n",
            "Epoch 41/50, Loss: 5.2594, Accuracy: 97.50%\n",
            "Epoch 42/50, Loss: 5.3286, Accuracy: 97.50%\n",
            "Epoch 43/50, Loss: 5.3979, Accuracy: 97.50%\n",
            "Epoch 44/50, Loss: 5.4671, Accuracy: 97.50%\n",
            "Epoch 45/50, Loss: 5.5364, Accuracy: 97.50%\n",
            "Epoch 46/50, Loss: 5.6057, Accuracy: 97.50%\n",
            "Epoch 47/50, Loss: 5.6749, Accuracy: 97.50%\n",
            "Epoch 48/50, Loss: 5.7442, Accuracy: 97.50%\n",
            "Epoch 49/50, Loss: 5.8134, Accuracy: 97.50%\n",
            "Epoch 50/50, Loss: 5.8827, Accuracy: 97.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    y_true = y_test[i]\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(X_test[i])\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Prediction\n",
        "    pred_label = probs.index(max(probs, key=lambda p: p.data))\n",
        "    if pred_label == y_true:\n",
        "        correct += 1\n",
        "\n",
        "test_accuracy = correct / len(X_test) * 100\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "S4wVrD_19j23",
        "outputId": "270ef4f4-4da0-44ac-b882-66da4068f538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.67%\n"
          ]
        }
      ]
    }
  ]
}