{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8HgrmH3S8JttLcYd+gFQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewstheBuilder/FromScratch_NeuralNetworks/blob/main/Micrograd_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST using micrograd_andrews module"
      ],
      "metadata": {
        "id": "cww1kBB3myu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "Xmlx3Bs_8yXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V3k6RqFdmtlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b526b5c5-e3d3-4fbc-9c9c-6cb8b57a5e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting micrograd_andrews\n",
            "  Downloading micrograd_andrews-0.1.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading micrograd_andrews-0.1.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Installing collected packages: micrograd_andrews\n",
            "Successfully installed micrograd_andrews-0.1.1\n"
          ]
        }
      ],
      "source": [
        "pip install micrograd_andrews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Micrograd imports\n",
        "from micrograd_andrews.engine import Value\n",
        "from micrograd_andrews.nn import Neuron, Layer, MLP\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "from keras.datasets import mnist\n",
        "import copy\n",
        "\n",
        "np.random.seed(1337)\n",
        "random.seed(1337)"
      ],
      "metadata": {
        "id": "kCrO58at6U-b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and test data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "train_X = train_X.astype('float32') / 255.0\n",
        "test_X = test_X.astype('float32') / 255.0\n",
        "\n",
        "print('X_train: ' + str(train_X.shape))\n",
        "print('Y_train: ' + str(train_y.shape))\n",
        "print('X_test:  '  + str(test_X.shape))\n",
        "print('Y_test:  '  + str(test_y.shape))\n",
        "\n",
        "print('train_x[1] raw',train_X[1][5][10:21])\n",
        "pyplot.imshow(train_X[0], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()\n",
        "\n",
        "# def findOne(x):\n",
        "#   if x == 1:\n",
        "#     return True\n",
        "#   else:\n",
        "#     return False\n",
        "\n",
        "# results = filter(findOne, train_y)\n",
        "\n",
        "# for y in results:\n",
        "#   print(y)\n",
        "\n",
        "# from matplotlib import pyplot\n",
        "# for i in range(9):\n",
        "#   pyplot.subplot(330 + 1 + i)\n",
        "#   pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
        "#   pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "XGmI8jW182Rj",
        "outputId": "e8127793-4242-4b4a-89b1-2b19308d2a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_train: (60000, 28, 28)\n",
            "Y_train: (60000,)\n",
            "X_test:  (10000, 28, 28)\n",
            "Y_test:  (10000,)\n",
            "train_x[1] raw [0.         0.         0.         0.         0.1882353  0.93333334\n",
            " 0.9882353  0.9882353  0.9882353  0.92941177 0.        ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy = copy.deepcopy(train_y)\n",
        "unique_integers = list(set(yy))\n",
        "unique_integers.sort()\n",
        "print(unique_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbgu3ZUc9DbQ",
        "outputId": "a116a159-ce12-4dd6-cc10-85a8ab8bde98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train on MNIST"
      ],
      "metadata": {
        "id": "gvNrpHWQ9GR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(number, num_classes):\n",
        "    one_hot_vector = [0] * num_classes\n",
        "    one_hot_vector[number] = 1\n",
        "    return one_hot_vector\n",
        "# convert train_y to one hot encoding\n",
        "num_classes = len(unique_integers)\n",
        "yy_one = [one_hot_encode(num, num_classes) for num in yy]\n",
        "print(yy_one[2])\n",
        "print(yy[2])"
      ],
      "metadata": {
        "id": "VYiY7GSkHKSR",
        "outputId": "afc06fbd-1a36-457d-ea08-d65345ea4d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Draft 1 Gradient Descent for MNIST\n",
        "- It seems like this draft the gradients are not getting through to the parameters somehow. Its being stopped!!"
      ],
      "metadata": {
        "id": "ptGkUKlIgLt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MLP model\n",
        "in_inputs=28*28\n",
        "output_dim = len(unique_integers)\n",
        "model = MLP(in_inputs, [2,2,output_dim])\n",
        "\n",
        "# forward the model to get scores\n",
        "limit_x=5\n",
        "# reshape here to flatten the 2D [28,28] into 1D -> 28*28\n",
        "inputs = train_X[:limit_x].reshape(limit_x,-1)\n",
        "scores = list(map(model, inputs))\n",
        "expected_outputs = yy_one[:limit_x]\n",
        "\n",
        "iterations = 10\n",
        "for iter in range(iterations):\n",
        "  # Begin gradient descent iterations\n",
        "  # Get probabilities of each output\n",
        "  probs_predicted = []\n",
        "  for i in range(len(scores)):\n",
        "      total = sum(scores[i])\n",
        "      probs_predicted.append([])\n",
        "      if total.data == 0:\n",
        "          print(f\"Alert: Sum of scores at index {i} is zero.\")\n",
        "          # layer_num = 0\n",
        "          # for layer in model.layers:\n",
        "            # print(f'layer {layer_num}')\n",
        "            # print(layer.parameters())\n",
        "            # print(\"len of parameters:\",len(layer.parameters()))\n",
        "            # layer_num += 1\n",
        "          # You can also raise an exception if needed\n",
        "          # raise ValueError(f\"Sum of scores at index {i} is zero.\")\n",
        "          # How can I log the parameters if my model is fing up?\n",
        "          # for p in model.parameters():\n",
        "          #   print('p',p)\n",
        "      for j in range(len(scores[i])):\n",
        "          if total.data == 0:\n",
        "              probs_predicted[i].append(Value(0.0))\n",
        "          else:\n",
        "              probs_predicted[i].append(scores[i][j] / total)\n",
        "\n",
        "  # probs = [Value(0.0) if sum(scores[i]).data == 0 else scores[i][j]/sum(scores[i]) for i in range(len(scores)) for j in range(len(scores[i]))]\n",
        "  # Why do I get all zeros as the outputs for certain inputs??\n",
        "    # its because of relu()\n",
        "    # Solution: I think it will work itself out once I start training it\n",
        "  # print(probs_predicted)\n",
        "  # print(expected_outputs)\n",
        "  # print(np.array(probs_predicted).shape)\n",
        "  # print(len(probs_predicted))\n",
        "\n",
        "  # Mean Squared Error(MSE) Loss\n",
        "    # Gain an intuition for how this will back propagate to help you update your parameters\n",
        "  losses = []\n",
        "  for yi_one, probs in zip(yy_one, probs_predicted):\n",
        "    loss = []\n",
        "    for k in range(len(yi_one)):\n",
        "      # (actual-expected)**2\n",
        "      loss.append((yi_one[i]-probs[i])**2)\n",
        "    losses.append(loss)\n",
        "  # print('losses',losses)\n",
        "  # print('losses shape',np.array(losses).shape)\n",
        "  # losses = [(yi_one-probs)**2 for yi_one, probs in zip(yy_one, probs_predicted)]\n",
        "\n",
        "  # Back propagation\n",
        "    # take (sum_of_each_example/num_classes)\n",
        "    # then data_loss = sum across all the examples / num_of_examples\n",
        "    # data_loss.backward()\n",
        "  data_loss = None\n",
        "  data_loss = [sum(loss)/num_classes for loss in losses ]\n",
        "  data_loss = sum(data_loss)/limit_x\n",
        "  # print(data_loss)\n",
        "  data_loss.backward()\n",
        "\n",
        "  # Update parameters\n",
        "  for p in model.parameters():\n",
        "    p -= p.grad"
      ],
      "metadata": {
        "id": "3lRRbGK187eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794743cc-5f7c-49e0-d938-1069f626cb5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 2 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Draft 2 Gradient Descent for MNIST\n",
        "\n",
        "*   Managed to get the MLP to overfit to the smaller sample size of training data\n",
        "\n"
      ],
      "metadata": {
        "id": "6Wp00cBXgS_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MLP model\n",
        "in_inputs=28*28\n",
        "output_dim = len(unique_integers)\n",
        "model = MLP(in_inputs, [2,2,output_dim])\n",
        "\n",
        "# limit the training set to 5 examples for now\n",
        "limit_x=5\n",
        "# reshape here to flatten the 2D [28,28] into 1D -> 28*28\n",
        "inputs = train_X[:limit_x].reshape(limit_x,-1)\n",
        "expected_outputs = yy_one[:limit_x]\n",
        "\n",
        "# Begin gradient descent iterations\n",
        "iterations = 100\n",
        "for iter in range(iterations):\n",
        "  # forward the model to get scores\n",
        "  scores = list(map(model, inputs))\n",
        "  # print('scores',scores)\n",
        "  # print('scores.shape',np.array(scores).shape)\n",
        "  # Get probabilities of each output\n",
        "  probs_predicted = []\n",
        "  for i in range(len(scores)):\n",
        "      total = sum(scores[i])\n",
        "      probs_predicted.append([])\n",
        "      if total.data == 0:\n",
        "          print(f\"Alert: Sum of scores at index {i} is zero.\")\n",
        "          # layer_num = 0\n",
        "          # for layer in model.layers:\n",
        "            # print(f'layer {layer_num}')\n",
        "            # print(layer.parameters())\n",
        "            # print(\"len of parameters:\",len(layer.parameters()))\n",
        "            # layer_num += 1\n",
        "          # You can also raise an exception if needed\n",
        "          # raise ValueError(f\"Sum of scores at index {i} is zero.\")\n",
        "          # How can I log the parameters if my model is fing up?\n",
        "          # for p in model.parameters():\n",
        "          #   print('p',p)\n",
        "      for j in range(len(scores[i])):\n",
        "          if total.data == 0:\n",
        "              probs_predicted[i].append(Value(0.0))\n",
        "          else:\n",
        "              probs_predicted[i].append(scores[i][j] / total)\n",
        "\n",
        "  # probs = [Value(0.0) if sum(scores[i]).data == 0 else scores[i][j]/sum(scores[i]) for i in range(len(scores)) for j in range(len(scores[i]))]\n",
        "  # Why do I get all zeros as the outputs for certain inputs??\n",
        "    # its because of relu()\n",
        "    # Solution: I think it will work itself out once I start training it\n",
        "  # print(probs_predicted)\n",
        "  # print(expected_outputs)\n",
        "  # print(np.array(probs_predicted).shape)\n",
        "  # print(len(probs_predicted))\n",
        "\n",
        "  # Mean Squared Error(MSE) Loss\n",
        "    # Gain an intuition for how this will back propagate to help you update your parameters\n",
        "  losses = []\n",
        "  for yi_one, probs in zip(yy_one, probs_predicted):\n",
        "    loss = []\n",
        "    for k in range(len(yi_one)):\n",
        "      # (actual-expected)**2\n",
        "      loss.append((yi_one[i]-probs[i])**2)\n",
        "    losses.append(loss)\n",
        "  # Calculate total loss\n",
        "    # take (sum_of_each_example/num_classes)\n",
        "    # then data_loss = sum across all the examples / num_of_examples\n",
        "    # data_loss.backward()\n",
        "  data_loss = [sum(loss)/num_classes for loss in losses ]\n",
        "  data_loss = sum(data_loss)/limit_x\n",
        "  # print('losses',losses)\n",
        "  # print('losses shape',np.array(losses).shape)\n",
        "  # losses = [(yi_one-probs)**2 for yi_one, probs in zip(yy_one, probs_predicted)]\n",
        "\n",
        "  # Back propagation\n",
        "  model.zero_grad()\n",
        "  data_loss.backward()\n",
        "  print('Iteration '+str(iter) +' total loss: '+str(round(data_loss.data,4)*100)+'%')\n",
        "\n",
        "  # Update parameters\n",
        "  for p in model.parameters():\n",
        "    # print('p.grad',p.grad)\n",
        "    # print('p before',p)\n",
        "    p.data -= p.grad\n",
        "    # print('p after',p)\n",
        "    # print()"
      ],
      "metadata": {
        "id": "9pYEsJfXgSXB",
        "outputId": "ab10636a-7eaa-46eb-dada-a89dfb03032e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alert: Sum of scores at index 0 is zero.\n",
            "Alert: Sum of scores at index 1 is zero.\n",
            "Alert: Sum of scores at index 3 is zero.\n",
            "Alert: Sum of scores at index 4 is zero.\n",
            "Iteration 0 total loss: 45.36%\n",
            "Iteration 1 total loss: 26.040000000000003%\n",
            "Iteration 2 total loss: 41.349999999999994%\n",
            "Iteration 3 total loss: 37.49%\n",
            "Iteration 4 total loss: 35.06%\n",
            "Iteration 5 total loss: 33.01%\n",
            "Iteration 6 total loss: 31.22%\n",
            "Iteration 7 total loss: 29.64%\n",
            "Iteration 8 total loss: 28.22%\n",
            "Iteration 9 total loss: 26.919999999999998%\n",
            "Iteration 10 total loss: 25.72%\n",
            "Iteration 11 total loss: 24.6%\n",
            "Iteration 12 total loss: 23.54%\n",
            "Iteration 13 total loss: 22.52%\n",
            "Iteration 14 total loss: 21.54%\n",
            "Iteration 15 total loss: 20.59%\n",
            "Iteration 16 total loss: 19.64%\n",
            "Iteration 17 total loss: 18.7%\n",
            "Iteration 18 total loss: 17.75%\n",
            "Iteration 19 total loss: 16.78%\n",
            "Iteration 20 total loss: 15.770000000000001%\n",
            "Iteration 21 total loss: 14.71%\n",
            "Iteration 22 total loss: 13.569999999999999%\n",
            "Iteration 23 total loss: 12.33%\n",
            "Iteration 24 total loss: 10.96%\n",
            "Iteration 25 total loss: 9.45%\n",
            "Iteration 26 total loss: 7.829999999999999%\n",
            "Iteration 27 total loss: 6.4%\n",
            "Iteration 28 total loss: 5.75%\n",
            "Iteration 29 total loss: 5.59%\n",
            "Iteration 30 total loss: 5.4399999999999995%\n",
            "Iteration 31 total loss: 5.3%\n",
            "Iteration 32 total loss: 5.17%\n",
            "Iteration 33 total loss: 5.04%\n",
            "Iteration 34 total loss: 4.92%\n",
            "Iteration 35 total loss: 4.81%\n",
            "Iteration 36 total loss: 4.6899999999999995%\n",
            "Iteration 37 total loss: 4.590000000000001%\n",
            "Iteration 38 total loss: 4.49%\n",
            "Iteration 39 total loss: 4.390000000000001%\n",
            "Iteration 40 total loss: 4.29%\n",
            "Iteration 41 total loss: 4.2%\n",
            "Iteration 42 total loss: 4.109999999999999%\n",
            "Iteration 43 total loss: 4.03%\n",
            "Iteration 44 total loss: 3.95%\n",
            "Iteration 45 total loss: 3.8699999999999997%\n",
            "Iteration 46 total loss: 3.7900000000000005%\n",
            "Iteration 47 total loss: 3.7199999999999998%\n",
            "Iteration 48 total loss: 3.65%\n",
            "Iteration 49 total loss: 3.58%\n",
            "Iteration 50 total loss: 3.51%\n",
            "Iteration 51 total loss: 3.45%\n",
            "Iteration 52 total loss: 3.39%\n",
            "Iteration 53 total loss: 3.3300000000000005%\n",
            "Iteration 54 total loss: 3.27%\n",
            "Iteration 55 total loss: 3.2099999999999995%\n",
            "Iteration 56 total loss: 3.16%\n",
            "Iteration 57 total loss: 3.1%\n",
            "Iteration 58 total loss: 3.05%\n",
            "Iteration 59 total loss: 3.0%\n",
            "Iteration 60 total loss: 2.9499999999999997%\n",
            "Iteration 61 total loss: 2.9000000000000004%\n",
            "Iteration 62 total loss: 2.86%\n",
            "Iteration 63 total loss: 2.81%\n",
            "Iteration 64 total loss: 2.77%\n",
            "Iteration 65 total loss: 2.7199999999999998%\n",
            "Iteration 66 total loss: 2.68%\n",
            "Iteration 67 total loss: 2.64%\n",
            "Iteration 68 total loss: 2.6%\n",
            "Iteration 69 total loss: 2.56%\n",
            "Iteration 70 total loss: 2.52%\n",
            "Iteration 71 total loss: 2.4899999999999998%\n",
            "Iteration 72 total loss: 2.45%\n",
            "Iteration 73 total loss: 2.41%\n",
            "Iteration 74 total loss: 2.3800000000000003%\n",
            "Iteration 75 total loss: 2.35%\n",
            "Iteration 76 total loss: 2.31%\n",
            "Iteration 77 total loss: 2.2800000000000002%\n",
            "Iteration 78 total loss: 2.25%\n",
            "Iteration 79 total loss: 2.22%\n",
            "Iteration 80 total loss: 2.19%\n",
            "Iteration 81 total loss: 2.16%\n",
            "Iteration 82 total loss: 2.13%\n",
            "Iteration 83 total loss: 2.1%\n",
            "Iteration 84 total loss: 2.07%\n",
            "Iteration 85 total loss: 2.0500000000000003%\n",
            "Iteration 86 total loss: 2.02%\n",
            "Iteration 87 total loss: 2.0%\n",
            "Iteration 88 total loss: 1.97%\n",
            "Iteration 89 total loss: 1.95%\n",
            "Iteration 90 total loss: 1.92%\n",
            "Iteration 91 total loss: 1.9%\n",
            "Iteration 92 total loss: 1.87%\n",
            "Iteration 93 total loss: 1.8499999999999999%\n",
            "Iteration 94 total loss: 1.83%\n",
            "Iteration 95 total loss: 1.81%\n",
            "Iteration 96 total loss: 1.78%\n",
            "Iteration 97 total loss: 1.76%\n",
            "Iteration 98 total loss: 1.7399999999999998%\n",
            "Iteration 99 total loss: 1.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Figure out why gradients are not flowing to parameters with a MLP with less parameters and a toy problem"
      ],
      "metadata": {
        "id": "3wvtiL5TnobB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Downscale MNIST images"
      ],
      "metadata": {
        "id": "TSnNVeXXq5Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = copy.deepcopy(train_X)\n",
        "\n",
        "# Define downscaling function\n",
        "def downscale_image(image, scale_factor):\n",
        "    width = int(image.shape[1] * scale_factor)\n",
        "    height = int(image.shape[0] * scale_factor)\n",
        "    dim = (width, height)\n",
        "    downscaled_image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
        "    return downscaled_image\n",
        "\n",
        "# Define scale factor (e.g., 0.5 for half the size)\n",
        "scale_factor = 0.1\n",
        "\n",
        "# Downscale images in MNIST dataset\n",
        "downscaled_images = [downscale_image(np.array(image), scale_factor) for image in mnist]\n",
        "downscaled_images = np.array(downscaled_images)\n",
        "\n",
        "# Print shape of the downscaled images\n",
        "print(downscaled_images.shape)\n",
        "pyplot.imshow(downscaled_images[0], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "HSl1L2YLq4iT",
        "outputId": "c334b940-16d1-4fa5-a196-5d62641f2387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 2, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MLP model\n",
        "in_inputs=downscaled_images[0].shape[0]*downscaled_images[0].shape[1]\n",
        "output_dim = len(unique_integers)\n",
        "model = MLP(in_inputs, [2,output_dim])\n",
        "\n",
        "# limit the training set to 5 examples for now\n",
        "limit_x=5\n",
        "# reshape here to flatten the 2D [downscaled_images.shape[0],downscaled_images.shape[1]] into 1D -> downscaled_images.shape[0]*downscaled_images.shape[1]\n",
        "inputs = downscaled_images[:limit_x].reshape(limit_x,-1)\n",
        "expected_outputs = yy_one[:limit_x]\n",
        "\n",
        "# Begin gradient descent iterations\n",
        "iterations = 10\n",
        "for iter in range(iterations):\n",
        "  # forward the model to get scores\n",
        "  scores = list(map(model, inputs))\n",
        "  print('scores',scores)\n",
        "  print('scores.shape',np.array(scores).shape)\n",
        "  # Get probabilities of each output\n",
        "  probs_predicted = []\n",
        "  for i in range(len(scores)):\n",
        "      total = sum(scores[i])\n",
        "      probs_predicted.append([])\n",
        "      if total.data == 0:\n",
        "          print(f\"Alert: Sum of scores at index {i} is zero.\")\n",
        "          # layer_num = 0\n",
        "          # for layer in model.layers:\n",
        "            # print(f'layer {layer_num}')\n",
        "            # print(layer.parameters())\n",
        "            # print(\"len of parameters:\",len(layer.parameters()))\n",
        "            # layer_num += 1\n",
        "          # You can also raise an exception if needed\n",
        "          # raise ValueError(f\"Sum of scores at index {i} is zero.\")\n",
        "          # How can I log the parameters if my model is fing up?\n",
        "          # for p in model.parameters():\n",
        "          #   print('p',p)\n",
        "      for j in range(len(scores[i])):\n",
        "          if total.data == 0:\n",
        "              probs_predicted[i].append(Value(0.0))\n",
        "          else:\n",
        "              probs_predicted[i].append(scores[i][j] / total)\n",
        "\n",
        "  # probs = [Value(0.0) if sum(scores[i]).data == 0 else scores[i][j]/sum(scores[i]) for i in range(len(scores)) for j in range(len(scores[i]))]\n",
        "  # Why do I get all zeros as the outputs for certain inputs??\n",
        "    # its because of relu()\n",
        "    # Solution: I think it will work itself out once I start training it\n",
        "  print(probs_predicted)\n",
        "  # print(expected_outputs)\n",
        "  # print(np.array(probs_predicted).shape)\n",
        "  # print(len(probs_predicted))\n",
        "\n",
        "  # Mean Squared Error(MSE) Loss\n",
        "    # Gain an intuition for how this will back propagate to help you update your parameters\n",
        "  losses = []\n",
        "  for yi_one, probs in zip(yy_one, probs_predicted):\n",
        "    loss = []\n",
        "    for k in range(len(yi_one)):\n",
        "      # (actual-expected)**2\n",
        "      loss.append((yi_one[i]-probs[i])**2)\n",
        "    losses.append(loss)\n",
        "  # Calculate total loss\n",
        "    # take (sum_of_each_example/num_classes)\n",
        "    # then data_loss = sum across all the examples / num_of_examples\n",
        "    # data_loss.backward()\n",
        "  data_loss = [sum(loss)/num_classes for loss in losses ]\n",
        "  data_loss = sum(data_loss)/limit_x\n",
        "  # print('losses',losses)\n",
        "  # print('losses shape',np.array(losses).shape)\n",
        "  # losses = [(yi_one-probs)**2 for yi_one, probs in zip(yy_one, probs_predicted)]\n",
        "\n",
        "  # Back propagation\n",
        "  model.zero_grad()\n",
        "  data_loss.backward()\n",
        "  print('total loss:',data_loss)\n",
        "\n",
        "  # Update parameters\n",
        "  for p in model.parameters():\n",
        "    # print('p.grad',p.grad)\n",
        "    # print('p before',p)\n",
        "    p.data -= p.grad\n",
        "    # print('p after',p)\n",
        "    # print()\n",
        "# for l in range(len(model.layers)):\n",
        "#   print(f'Layer {l}')\n",
        "#   for p in model.layers[l].parameters():\n",
        "#     print('p',p)"
      ],
      "metadata": {
        "id": "WNewOzFMnnms",
        "outputId": "235ceafa-adde-47b5-8d33-51a7884dc043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scores [[Value(data=14.761208020038612, grad=0), Value(data=-29.240798196111747, grad=0), Value(data=-5.3943238632547885, grad=0), Value(data=-1.0464944879799334, grad=0), Value(data=24.92118483231581, grad=0), Value(data=3.147339342161426, grad=0), Value(data=-38.55324612727477, grad=0), Value(data=36.02671562214486, grad=0), Value(data=-34.96476111353706, grad=0), Value(data=-2.222324062950971, grad=0)], [Value(data=17.204355661852752, grad=0), Value(data=-34.08048252686659, grad=0), Value(data=-6.287145752073221, grad=0), Value(data=-1.2197012158445395, grad=0), Value(data=29.045924072602418, grad=0), Value(data=3.6682597628581624, grad=0), Value(data=-44.934246397189334, grad=0), Value(data=41.98954638742268, grad=0), Value(data=-40.75182634188205, grad=0), Value(data=-2.590143945061899, grad=0)], [Value(data=13.096896271840654, grad=0), Value(data=-25.94392683582675, grad=0), Value(data=-4.786119130484139, grad=0), Value(data=-0.9285032593213419, grad=0), Value(data=22.111345648481347, grad=0), Value(data=2.7924799136096428, grad=0), Value(data=-34.2064053826903, grad=0), Value(data=31.964738717712226, grad=0), Value(data=-31.022518539948376, grad=0), Value(data=-1.9717592012369873, grad=0)], [Value(data=8.416802242711517, grad=0), Value(data=-16.67302672664757, grad=0), Value(data=-3.0758293717234935, grad=0), Value(data=-0.5967084226072511, grad=0), Value(data=14.209994473549548, grad=0), Value(data=1.7946046690566988, grad=0), Value(data=-21.982960204025805, grad=0), Value(data=20.542339111701356, grad=0), Value(data=-19.93681542572837, grad=0), Value(data=-1.267163373870574, grad=0)], [Value(data=16.347870493514232, grad=0), Value(data=-32.383852418317794, grad=0), Value(data=-5.974152508172023, grad=0), Value(data=-1.1589807784327726, grad=0), Value(data=27.59992960132841, grad=0), Value(data=3.4856426313449296, grad=0), Value(data=-42.69728290107914, grad=0), Value(data=39.89917901691826, grad=0), Value(data=-38.72307644095317, grad=0), Value(data=-2.4611986990782757, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=-0.4532774870468397, grad=0), Value(data=0.8979072381870428, grad=0), Value(data=0.1656453565137506, grad=0), Value(data=0.0321350658479964, grad=0), Value(data=-0.7652633862816045, grad=0), Value(data=-0.09664643069604631, grad=0), Value(data=1.1838677768341415, grad=0), Value(data=-1.106284736424589, grad=0), Value(data=1.0736749344106649, grad=0), Value(data=0.06824166865548338, grad=0)], [Value(data=-0.4532774870468398, grad=0), Value(data=0.897907238187043, grad=0), Value(data=0.16564535651375065, grad=0), Value(data=0.03213506584799641, grad=0), Value(data=-0.7652633862816047, grad=0), Value(data=-0.09664643069604634, grad=0), Value(data=1.1838677768341417, grad=0), Value(data=-1.1062847364245894, grad=0), Value(data=1.073674934410665, grad=0), Value(data=0.06824166865548341, grad=0)], [Value(data=-0.4532774870468397, grad=0), Value(data=0.8979072381870427, grad=0), Value(data=0.1656453565137506, grad=0), Value(data=0.0321350658479964, grad=0), Value(data=-0.7652633862816044, grad=0), Value(data=-0.0966464306960463, grad=0), Value(data=1.1838677768341415, grad=0), Value(data=-1.106284736424589, grad=0), Value(data=1.0736749344106649, grad=0), Value(data=0.06824166865548338, grad=0)], [Value(data=-0.4532774870468397, grad=0), Value(data=0.8979072381870428, grad=0), Value(data=0.1656453565137506, grad=0), Value(data=0.0321350658479964, grad=0), Value(data=-0.7652633862816045, grad=0), Value(data=-0.09664643069604631, grad=0), Value(data=1.1838677768341412, grad=0), Value(data=-1.106284736424589, grad=0), Value(data=1.0736749344106649, grad=0), Value(data=0.06824166865548338, grad=0)], [Value(data=-0.45327748704683973, grad=0), Value(data=0.8979072381870429, grad=0), Value(data=0.16564535651375062, grad=0), Value(data=0.03213506584799641, grad=0), Value(data=-0.7652633862816045, grad=0), Value(data=-0.09664643069604631, grad=0), Value(data=1.1838677768341415, grad=0), Value(data=-1.106284736424589, grad=0), Value(data=1.0736749344106649, grad=0), Value(data=0.0682416686554834, grad=0)]]\n",
            "total loss: Value(data=1.09173340489583, grad=1)\n",
            "scores [[Value(data=-93.595846148432, grad=0), Value(data=-137.59785236458234, grad=0), Value(data=-113.75137803172538, grad=0), Value(data=-109.40354865645054, grad=0), Value(data=-225.03032702342873, grad=0), Value(data=-105.20971482630917, grad=0), Value(data=-146.91030029574534, grad=0), Value(data=-72.33033854632576, grad=0), Value(data=-143.32181528200763, grad=0), Value(data=-110.57937823142156, grad=0)], [Value(data=-109.07855175123086, grad=0), Value(data=-160.3633899399502, grad=0), Value(data=-132.5700531651568, grad=0), Value(data=-127.50260862892814, grad=0), Value(data=-262.2558639989288, grad=0), Value(data=-122.61464765022542, grad=0), Value(data=-171.2171538102729, grad=0), Value(data=-84.29336102566094, grad=0), Value(data=-167.03473375496563, grad=0), Value(data=-128.8730513581455, grad=0)], [Value(data=-83.0487762998433, grad=0), Value(data=-122.08959940751069, grad=0), Value(data=-100.93179170216807, grad=0), Value(data=-97.07417583100528, grad=0), Value(data=-199.67168824902447, grad=0), Value(data=-93.35319265807429, grad=0), Value(data=-130.3520779543742, grad=0), Value(data=-64.18093385397172, grad=0), Value(data=-127.16819111163231, grad=0), Value(data=-98.11743177292092, grad=0)], [Value(data=-53.39010287124186, grad=0), Value(data=-78.47993184060094, grad=0), Value(data=-64.88273448567686, grad=0), Value(data=-62.40361353656062, grad=0), Value(data=-128.36244342549048, grad=0), Value(data=-60.01230044489667, grad=0), Value(data=-83.78986531797915, grad=0), Value(data=-41.26456600225203, grad=0), Value(data=-81.74372053968173, grad=0), Value(data=-63.074068487823936, grad=0)], [Value(data=-103.65083731940786, grad=0), Value(data=-152.3825602312399, grad=0), Value(data=-125.97286032109409, grad=0), Value(data=-121.15768859135486, grad=0), Value(data=-249.2058461623979, grad=0), Value(data=-116.51306518157715, grad=0), Value(data=-162.6959907140012, grad=0), Value(data=-80.09952879600384, grad=0), Value(data=-158.72178425387526, grad=0), Value(data=-122.45990651200034, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07441645582468064, grad=0), Value(data=0.10940169808199775, grad=0), Value(data=0.09044177435898154, grad=0), Value(data=0.08698488961513003, grad=0), Value(data=0.1789177626921103, grad=0), Value(data=0.08365044409431248, grad=0), Value(data=0.11680586609379194, grad=0), Value(data=0.057508614588309054, grad=0), Value(data=0.11395272305922988, grad=0), Value(data=0.08791977159145638, grad=0)], [Value(data=0.07441553937505307, grad=0), Value(data=0.10940306748488429, grad=0), Value(data=0.0904419049655496, grad=0), Value(data=0.08698479435707138, grad=0), Value(data=0.1789161229263445, grad=0), Value(data=0.08365013097151473, grad=0), Value(data=0.11680771926740499, grad=0), Value(data=0.05750659342055166, grad=0), Value(data=0.11395438981526347, grad=0), Value(data=0.08791973741636239, grad=0)], [Value(data=0.07441727581707587, grad=0), Value(data=0.10940047281012338, grad=0), Value(data=0.09044165749888435, grad=0), Value(data=0.08698497484718351, grad=0), Value(data=0.17891922987090272, grad=0), Value(data=0.0836507242606252, grad=0), Value(data=0.11680420796853985, grad=0), Value(data=0.057510423026155146, grad=0), Value(data=0.11395123173092213, grad=0), Value(data=0.08791980216958786, grad=0)], [Value(data=0.07442131835328455, grad=0), Value(data=0.10939443225908105, grad=0), Value(data=0.09044108138235317, grad=0), Value(data=0.08698539503847358, grad=0), Value(data=0.17892646301529225, grad=0), Value(data=0.08365210547156099, grad=0), Value(data=0.11679603346422844, grad=0), Value(data=0.057519338566734066, grad=0), Value(data=0.11394387953019648, grad=0), Value(data=0.08791995291879523, grad=0)], [Value(data=0.07441582948247383, grad=0), Value(data=0.10940263399249428, grad=0), Value(data=0.09044186362128642, grad=0), Value(data=0.08698482451155981, grad=0), Value(data=0.17891664200366492, grad=0), Value(data=0.0836502300923442, grad=0), Value(data=0.11680713263459842, grad=0), Value(data=0.05750723323287454, grad=0), Value(data=0.113953862194018, grad=0), Value(data=0.08791974823468571, grad=0)]]\n",
            "total loss: Value(data=0.16044440397571338, grad=1)\n",
            "scores [[Value(data=-93.58155184628785, grad=0), Value(data=-137.58357240311898, grad=0), Value(data=-113.73709029846464, grad=0), Value(data=-109.38925950619002, grad=0), Value(data=-225.09613847181333, grad=0), Value(data=-105.19542430923751, grad=0), Value(data=-146.89602336929912, grad=0), Value(data=-72.31603731354633, grad=0), Value(data=-143.30753718603933, grad=0), Value(data=-110.5650894643753, grad=0)], [Value(data=-109.06201212645043, grad=0), Value(data=-160.3469232200726, grad=0), Value(data=-132.55354693515127, grad=0), Value(data=-127.48609519520384, grad=0), Value(data=-262.3328502008964, grad=0), Value(data=-122.59812726793051, grad=0), Value(data=-171.2007025197625, grad=0), Value(data=-84.2767861670378, grad=0), Value(data=-167.01827651885927, grad=0), Value(data=-128.8565398725992, grad=0)], [Value(data=-83.0360656199612, grad=0), Value(data=-122.07688861201503, grad=0), Value(data=-100.91908096932809, grad=0), Value(data=-97.06146510958907, grad=0), Value(data=-199.73001733935968, grad=0), Value(data=-93.3404819476772, grad=0), Value(data=-130.33936713441045, grad=0), Value(data=-64.16822322996394, grad=0), Value(data=-127.15548030109714, grad=0), Value(data=-98.10472104841526, grad=0)], [Value(data=-53.38211092732147, grad=0), Value(data=-78.47202405617138, grad=0), Value(data=-64.87478109180104, grad=0), Value(data=-62.39565182690245, grad=0), Value(data=-128.40037064066857, grad=0), Value(data=-60.004330713992424, grad=0), Value(data=-83.78197534480286, grad=0), Value(data=-41.25653338531588, grad=0), Value(data=-81.73582370306674, grad=0), Value(data=-63.06610902709092, grad=0)], [Value(data=-103.63498038878386, grad=0), Value(data=-152.36670654023962, grad=0), Value(data=-125.95700487441015, grad=0), Value(data=-121.14183282456433, grad=0), Value(data=-249.27866365199668, grad=0), Value(data=-116.49720910601789, grad=0), Value(data=-162.68013770862484, grad=0), Value(data=-80.08367029971842, grad=0), Value(data=-158.70593098429862, grad=0), Value(data=-122.44405083177965, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.0744088045259874, grad=0), Value(data=0.10939580443959916, grad=0), Value(data=0.09043492817124876, grad=0), Value(data=0.08697786975373263, grad=0), Value(data=0.17897902136325974, grad=0), Value(data=0.0836432567105891, grad=0), Value(data=0.11680034443631249, grad=0), Value(data=0.057500113840772235, grad=0), Value(data=0.11394705806003003, grad=0), Value(data=0.08791279869846866, grad=0)], [Value(data=0.07440788803258146, grad=0), Value(data=0.10939717392610342, grad=0), Value(data=0.0904350587923934, grad=0), Value(data=0.0869777744976626, grad=0), Value(data=0.17897738144042766, grad=0), Value(data=0.08364294357763782, grad=0), Value(data=0.11680219772050497, grad=0), Value(data=0.05749809256766783, grad=0), Value(data=0.11394872491625355, grad=0), Value(data=0.08791276452876756, grad=0)], [Value(data=0.07440962455451636, grad=0), Value(data=0.10939457909744588, grad=0), Value(data=0.09043481129854197, grad=0), Value(data=0.08697795498369117, grad=0), Value(data=0.17898048867715294, grad=0), Value(data=0.08364353688494902, grad=0), Value(data=0.11679868621826066, grad=0), Value(data=0.057501922366179695, grad=0), Value(data=0.11394556664760075, grad=0), Value(data=0.08791282927166158, grad=0)], [Value(data=0.07441366722043076, grad=0), Value(data=0.10938853827230198, grad=0), Value(data=0.09043423512674881, grad=0), Value(data=0.08697837515961934, grad=0), Value(data=0.17898772240092273, grad=0), Value(data=0.08364491811900984, grad=0), Value(data=0.1167905113543872, grad=0), Value(data=0.05751083823161829, grad=0), Value(data=0.11393821412024466, grad=0), Value(data=0.08791297999471648, grad=0)], [Value(data=0.07440817815951904, grad=0), Value(data=0.1093967403987883, grad=0), Value(data=0.09043501744270943, grad=0), Value(data=0.08697780465210962, grad=0), Value(data=0.17897790057759333, grad=0), Value(data=0.08364304270361472, grad=0), Value(data=0.1168016110412514, grad=0), Value(data=0.05749873242581851, grad=0), Value(data=0.11394819725300091, grad=0), Value(data=0.08791277534559468, grad=0)]]\n",
            "total loss: Value(data=0.16044182495873244, grad=1)\n",
            "scores [[Value(data=-93.56729384564846, grad=0), Value(data=-137.5693288807427, grad=0), Value(data=-113.72283892972953, grad=0), Value(data=-109.37500670686065, grad=0), Value(data=-225.16175804004226, grad=0), Value(data=-105.18117012998403, grad=0), Value(data=-146.88178291105746, grad=0), Value(data=-72.30177231578023, grad=0), Value(data=-143.29329554705535, grad=0), Value(data=-110.55083705193671, grad=0)], [Value(data=-109.04551480428572, grad=0), Value(data=-160.33049897826095, grad=0), Value(data=-132.5370830881281, grad=0), Value(data=-127.46962412712571, grad=0), Value(data=-262.4096130238985, grad=0), Value(data=-122.58164923455956, grad=0), Value(data=-171.18429374444983, grad=0), Value(data=-84.26025352623792, grad=0), Value(data=-167.00186178364214, grad=0), Value(data=-128.84007075738748, grad=0)], [Value(data=-83.02338711035007, grad=0), Value(data=-122.06421008602915, grad=0), Value(data=-100.90640245221634, grad=0), Value(data=-97.0487865940953, grad=0), Value(data=-199.7881760186187, grad=0), Value(data=-93.32780343374412, grad=0), Value(data=-130.32668860495906, grad=0), Value(data=-64.15554472826648, grad=0), Value(data=-127.14280177298117, grad=0), Value(data=-98.09204253248392, grad=0)], [Value(data=-53.37413972060547, grad=0), Value(data=-78.4641371251381, grad=0), Value(data=-64.86684848835239, grad=0), Value(data=-62.38771089619056, grad=0), Value(data=-128.43818882662057, grad=0), Value(data=-59.9963817509602, grad=0), Value(data=-83.77410624961331, grad=0), Value(data=-41.248521449430335, grad=0), Value(data=-81.72794773496275, grad=0), Value(data=-63.05817034840907, grad=0)], [Value(data=-103.61916359160085, grad=0), Value(data=-152.3508930990806, grad=0), Value(data=-125.94118961448541, grad=0), Value(data=-121.12601723303155, grad=0), Value(data=-249.35126842462657, grad=0), Value(data=-116.48139319462226, grad=0), Value(data=-162.6643249777243, grad=0), Value(data=-80.06785188061951, grad=0), Value(data=-158.69011797970506, grad=0), Value(data=-122.42823532992713, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07440117331694132, grad=0), Value(data=0.10938992740386339, grad=0), Value(data=0.09042810047774948, grad=0), Value(data=0.08697086873072171, grad=0), Value(data=0.17904011429377778, grad=0), Value(data=0.08363608849721561, grad=0), Value(data=0.11679483864836787, grad=0), Value(data=0.05749163486615651, grad=0), Value(data=0.11394140921441195, grad=0), Value(data=0.08790584455079446, grad=0)], [Value(data=0.07440025677981893, grad=0), Value(data=0.10939129697382373, grad=0), Value(data=0.09042823111343024, grad=0), Value(data=0.08697077347662192, grad=0), Value(data=0.17903847421428887, grad=0), Value(data=0.08363577535411375, grad=0), Value(data=0.11679669204293087, grad=0), Value(data=0.05748961348787506, grad=0), Value(data=0.11394307617063473, grad=0), Value(data=0.08790581038646193, grad=0)], [Value(data=0.07440199338155117, grad=0), Value(data=0.1093887019915721, grad=0), Value(data=0.090427983592469, grad=0), Value(data=0.08697095395860203, grad=0), Value(data=0.1790415817424095, grad=0), Value(data=0.08363636867962107, grad=0), Value(data=0.1167931803376982, grad=0), Value(data=0.05749344347897884, grad=0), Value(data=0.11393991771802732, grad=0), Value(data=0.08790587511907078, grad=0)], [Value(data=0.07440603617686464, grad=0), Value(data=0.10938266089309187, grad=0), Value(data=0.09042740736559818, grad=0), Value(data=0.08697137411924677, grad=0), Value(data=0.17904881604368264, grad=0), Value(data=0.08363774993678318, grad=0), Value(data=0.11678500511525473, grad=0), Value(data=0.05750235966845247, grad=0), Value(data=0.11393256486494541, grad=0), Value(data=0.08790602581608026, grad=0)], [Value(data=0.07440054692625964, grad=0), Value(data=0.10939086341162574, grad=0), Value(data=0.09042818975833737, grad=0), Value(data=0.08697080363103392, grad=0), Value(data=0.1790389934111818, grad=0), Value(data=0.08363587448523918, grad=0), Value(data=0.11679610531728432, grad=0), Value(data=0.05749025339181282, grad=0), Value(data=0.11394254846542445, grad=0), Value(data=0.08790582120180071, grad=0)]]\n",
            "total loss: Value(data=0.16043926039432962, grad=1)\n",
            "scores [[Value(data=-93.5530720797641, grad=0), Value(data=-137.55512173035083, grad=0), Value(data=-113.70862385860868, grad=0), Value(data=-109.36079019158592, grad=0), Value(data=-225.22718625906523, grad=0), Value(data=-105.16695222170584, grad=0), Value(data=-146.86757885384304, grad=0), Value(data=-72.28754348644823, grad=0), Value(data=-143.2790902979072, grad=0), Value(data=-110.53662092721981, grad=0)], [Value(data=-109.02905970698055, grad=0), Value(data=-160.31411713630695, grad=0), Value(data=-132.52066154612402, grad=0), Value(data=-127.45319534677512, grad=0), Value(data=-262.48615308584397, grad=0), Value(data=-122.56521347223709, grad=0), Value(data=-171.16792740603083, grad=0), Value(data=-84.24376302572365, grad=0), Value(data=-166.98548947104715, grad=0), Value(data=-128.82364393457962, grad=0)], [Value(data=-83.01074071189834, grad=0), Value(data=-122.05156377018726, grad=0), Value(data=-100.89375609160483, grad=0), Value(data=-97.03614022532112, grad=0), Value(data=-199.84616475828307, grad=0), Value(data=-93.3151570570964, grad=0), Value(data=-130.31404230660047, grad=0), Value(data=-64.14289828989064, grad=0), Value(data=-127.13015546788552, grad=0), Value(data=-98.07939616591726, grad=0)], [Value(data=-53.36618921295763, grad=0), Value(data=-78.45627100906401, grad=0), Value(data=-64.85893663705687, grad=0), Value(data=-62.379790706180636, grad=0), Value(data=-128.47589828486454, grad=0), Value(data=-59.98845351758436, grad=0), Value(data=-83.76625799390978, grad=0), Value(data=-41.24053015660456, grad=0), Value(data=-81.72009259689354, grad=0), Value(data=-63.05025241352606, grad=0)], [Value(data=-103.60338685413832, grad=0), Value(data=-152.33511983374405, grad=0), Value(data=-125.92541446746279, grad=0), Value(data=-121.11024174292886, grad=0), Value(data=-249.42366106876017, grad=0), Value(data=-116.46561737359103, grad=0), Value(data=-162.64855244721772, grad=0), Value(data=-80.05207346513073, grad=0), Value(data=-158.67434516603706, grad=0), Value(data=-122.41245993260722, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07439356215414987, grad=0), Value(data=0.10938406693201463, grad=0), Value(data=0.09042129123537365, grad=0), Value(data=0.08696388650292633, grad=0), Value(data=0.17910104187152961, grad=0), Value(data=0.08362893941096233, grad=0), Value(data=0.11678934868731282, grad=0), Value(data=0.05748317762077128, grad=0), Value(data=0.11393577647968019, grad=0), Value(data=0.08789890910527934, grad=0)], [Value(data=0.07439264557337302, grad=0), Value(data=0.10938543658526957, grad=0), Value(data=0.09042142188555018, grad=0), Value(data=0.08696379125077847, grad=0), Value(data=0.17909940163579263, grad=0), Value(data=0.08362862625771288, grad=0), Value(data=0.11679120219203751, grad=0), Value(data=0.05748115613748283, grad=0), Value(data=0.11393744353571159, grad=0), Value(data=0.08789887494629109, grad=0)], [Value(data=0.07439438225478769, grad=0), Value(data=0.10938284144972618, grad=0), Value(data=0.09042117433755535, grad=0), Value(data=0.08696397172874512, grad=0), Value(data=0.17910250945453818, grad=0), Value(data=0.08362921960141152, grad=0), Value(data=0.11678769028420716, grad=0), Value(data=0.057484986320861915, grad=0), Value(data=0.11393428489950617, grad=0), Value(data=0.08789893966866091, grad=0)], [Value(data=0.07439842517919337, grad=0), Value(data=0.10937680007867422, grad=0), Value(data=0.09042059805579078, grad=0), Value(data=0.08696439187418445, grad=0), Value(data=0.17910974433144114, grad=0), Value(data=0.08363060088165084, grad=0), Value(data=0.11677951470418502, grad=0), Value(data=0.05749390283354591, grad=0), Value(data=0.1139269317216024, grad=0), Value(data=0.08789909033973164, grad=0)], [Value(data=0.07439293573930313, grad=0), Value(data=0.10938500298823088, grad=0), Value(data=0.0904213805250603, grad=0), Value(data=0.0869638214051618, grad=0), Value(data=0.17909992089229487, grad=0), Value(data=0.08362872539398783, grad=0), Value(data=0.11679061542005202, grad=0), Value(data=0.057481796087166866, grad=0), Value(data=0.11393691578859316, grad=0), Value(data=0.08789888576014938, grad=0)]]\n",
            "total loss: Value(data=0.16043671020554068, grad=1)\n",
            "scores [[Value(data=-93.53888648186783, grad=0), Value(data=-137.5409508848242, grad=0), Value(data=-113.69444501817377, grad=0), Value(data=-109.34660989347233, grad=0), Value(data=-225.2924236585026, grad=0), Value(data=-105.15277051754302, grad=0), Value(data=-146.85341113046212, grad=0), Value(data=-72.27335075895365, grad=0), Value(data=-143.26492137142984, grad=0), Value(data=-110.52244102332172, grad=0)], [Value(data=-109.01264675675887, grad=0), Value(data=-160.2977776159833, grad=0), Value(data=-132.50428223115622, grad=0), Value(data=-127.43680877621388, grad=0), Value(data=-262.5624710030955, grad=0), Value(data=-122.54881990306791, grad=0), Value(data=-171.15160342618273, grad=0), Value(data=-84.227314587937, grad=0), Value(data=-166.96915950278824, grad=0), Value(data=-128.80725932622545, grad=0)], [Value(data=-82.99812636547892, grad=0), Value(data=-122.0389496051085, grad=0), Value(data=-100.88114182825021, grad=0), Value(data=-97.02352594404826, grad=0), Value(data=-199.90398402865458, grad=0), Value(data=-93.30254275853994, grad=0), Value(data=-130.30142817990009, grad=0), Value(data=-64.13028385583202, grad=0), Value(data=-127.11754132639629, grad=0), Value(data=-98.06678188949022, grad=0)], [Value(data=-53.35825936623221, grad=0), Value(data=-78.44842566950307, grad=0), Value(data=-64.8510454996312, grad=0), Value(data=-62.371891218619055, grad=0), Value(data=-128.51349931616343, grad=0), Value(data=-59.980545975639906, grad=0), Value(data=-83.75843053918267, grad=0), Value(data=-41.23255946883794, grad=0), Value(data=-81.71225825037398, grad=0), Value(data=-63.042355184180224, grad=0)], [Value(data=-103.58765010265616, grad=0), Value(data=-152.31938667019216, grad=0), Value(data=-125.90967935946576, grad=0), Value(data=-121.09450628040915, grad=0), Value(data=-249.495842171398, grad=0), Value(data=-116.44988156910549, grad=0), Value(data=-162.63282004300427, grad=0), Value(data=-80.03633497965583, grad=0), Value(data=-158.65861246921799, grad=0), Value(data=-122.39672456596485, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07438597099427113, grad=0), Value(data=0.10937822298137223, grad=0), Value(data=0.09041450040108227, grad=0), Value(data=0.08695692302724206, grad=0), Value(data=0.17916180448373212, grad=0), Value(data=0.0836218094086618, grad=0), Value(data=0.1167838745106066, grad=0), Value(data=0.05747474206095506, grad=0), Value(data=0.11393015981323998, grad=0), Value(data=0.08789199231883656, grad=0)], [Value(data=0.07438505436990198, grad=0), Value(data=0.10937959271776046, grad=0), Value(data=0.09041463106571433, grad=0), Value(data=0.08695682777702801, grad=0), Value(data=0.1791601640921552, grad=0), Value(data=0.08362149624526795, grad=0), Value(data=0.11678572812528437, grad=0), Value(data=0.057472720472829746, grad=0), Value(data=0.11393182696888964, grad=0), Value(data=0.08789195816516852, grad=0)], [Value(data=0.07438679113088391, grad=0), Value(data=0.10937699742922732, grad=0), Value(data=0.09041438349076185, grad=0), Value(data=0.08695700825101593, grad=0), Value(data=0.17916327220075645, grad=0), Value(data=0.08362208960715287, grad=0), Value(data=0.11678221601524665, grad=0), Value(data=0.0574765508481674, grad=0), Value(data=0.11392866814944252, grad=0), Value(data=0.08789202287734516, grad=0)], [Value(data=0.07439083418407486, grad=0), Value(data=0.1093709557863677, grad=0), Value(data=0.0904138071542872, grad=0), Value(data=0.08695742838132768, grad=0), Value(data=0.17917050765141943, grad=0), Value(data=0.08362347091044514, grad=0), Value(data=0.11677404007863663, grad=0), Value(data=0.05748546768323717, grad=0), Value(data=0.1139213146476203, grad=0), Value(data=0.08789217352258359, grad=0)], [Value(data=0.07438534455530757, grad=0), Value(data=0.1093791590859231, grad=0), Value(data=0.09041458969983915, grad=0), Value(data=0.08695685793138887, grad=0), Value(data=0.17916068340814884, grad=0), Value(data=0.0836215953866933, grad=0), Value(data=0.11678514130701381, grad=0), Value(data=0.05747336046821914, grad=0), Value(data=0.11393129917991235, grad=0), Value(data=0.087891968977554, grad=0)]]\n",
            "total loss: Value(data=0.16043417431578139, grad=1)\n",
            "scores [[Value(data=-93.52473698517673, grad=0), Value(data=-137.5268162770284, grad=0), Value(data=-113.68030234148085, grad=0), Value(data=-109.33246574561068, grad=0), Value(data=-225.3574707666489, grad=0), Value(data=-105.13862495061987, grad=0), Value(data=-146.83927967370582, grad=0), Value(data=-72.25919406668346, grad=0), Value(data=-143.25078870044305, grad=0), Value(data=-110.50829727332382, grad=0)], [Value(data=-108.99627587582579, grad=0), Value(data=-160.28148033904472, grad=0), Value(data=-132.48794506522358, grad=0), Value(data=-127.42046433748534, grad=0), Value(data=-262.63856739047264, grad=0), Value(data=-122.53246844913828, grad=0), Value(data=-171.13532172656494, grad=0), Value(data=-84.21090813530076, grad=0), Value(data=-166.95287180056164, grad=0), Value(data=-128.79091685435617, grad=0)], [Value(data=-82.98554401195013, grad=0), Value(data=-122.02636753139788, grad=0), Value(data=-100.86855960289475, grad=0), Value(data=-97.01094369104403, grad=0), Value(data=-199.9616342988583, grad=0), Value(data=-93.28996047886623, grad=0), Value(data=-130.28884616540932, grad=0), Value(data=-64.1177013670713, grad=0), Value(data=-127.10495928908558, grad=0), Value(data=-98.05419964396334, grad=0)], [Value(data=-53.35035014227459, grad=0), Value(data=-78.44060106800096, grad=0), Value(data=-64.84317503778347, grad=0), Value(data=-62.364012395243535, grad=0), Value(data=-128.55099222052695, grad=0), Value(data=-59.97265908689311, grad=0), Value(data=-83.75062384691422, grad=0), Value(data=-41.2246093481207, grad=0), Value(data=-81.70444465691081, grad=0), Value(data=-63.034478622101275, grad=0)], [Value(data=-103.57195326339584, grad=0), Value(data=-152.30369353436933, grad=0), Value(data=-125.89398421659972, grad=0), Value(data=-121.07881077160721, grad=0), Value(data=-249.56781231807216, grad=0), Value(data=-116.4341857073287, grad=0), Value(data=-162.61712769096542, grad=0), Value(data=-80.02063635057992, grad=0), Value(data=-158.6429198151536, grad=0), Value(data=-122.38102915612681, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07437839979401402, grad=0), Value(data=0.10937239550935053, grad=0), Value(data=0.09040772793190735, grad=0), Value(data=0.08694997826063128, grad=0), Value(data=0.17922240251695443, grad=0), Value(data=0.08361469844720917, grad=0), Value(data=0.11677841607581282, grad=0), Value(data=0.057466328143075854, grad=0), Value(data=0.11392455917259744, grad=0), Value(data=0.0878850941484473, grad=0)], [Value(data=0.0743774831261146, grad=0), Value(data=0.10937376532871057, grad=0), Value(data=0.09040785861095464, grad=0), Value(data=0.0869498830123328, grad=0), Value(data=0.17922076196994463, grad=0), Value(data=0.08361438527367396, grad=0), Value(data=0.11678026980023495, grad=0), Value(data=0.057464306450283706, grad=0), Value(data=0.11392622642767489, grad=0), Value(data=0.08788506000007525, grad=0)], [Value(data=0.07437921996654866, grad=0), Value(data=0.10937116988748974, grad=0), Value(data=0.09040761100912045, grad=0), Value(data=0.0869500634823767, grad=0), Value(data=0.1792238703676341, grad=0), Value(data=0.08361497865374014, grad=0), Value(data=0.11677675748838018, grad=0), Value(data=0.05746813701726318, grad=0), Value(data=0.11392306742534235, grad=0), Value(data=0.0878851247021046, grad=0)], [Value(data=0.07438326314821767, grad=0), Value(data=0.10936512797358594, grad=0), Value(data=0.09040703461811897, grad=0), Value(data=0.08695048359763832, grad=0), Value(data=0.17923110639019063, grad=0), Value(data=0.08361635998006076, grad=0), Value(data=0.11676858119617234, grad=0), Value(data=0.057477054173894114, grad=0), Value(data=0.11391571360050444, grad=0), Value(data=0.0878852753216168, grad=0)], [Value(data=0.07437777333098188, grad=0), Value(data=0.10937333166211678, grad=0), Value(data=0.090407817239706, grad=0), Value(data=0.0869499131666775, grad=0), Value(data=0.17922128134531226, grad=0), Value(data=0.08361448442025068, grad=0), Value(data=0.11677968293573338, grad=0), Value(data=0.05746494649133761, grad=0), Value(data=0.11392569859688821, grad=0), Value(data=0.08788507081099574, grad=0)]]\n",
            "total loss: Value(data=0.16043165264884618, grad=1)\n",
            "scores [[Value(data=-93.51062352289264, grad=0), Value(data=-137.5127178398143, grad=0), Value(data=-113.66619576157107, grad=0), Value(data=-109.31835768107676, grad=0), Value(data=-225.4223281104753, grad=0), Value(data=-105.12451545404564, grad=0), Value(data=-146.82518441635088, grad=0), Value(data=-72.2450733430091, grad=0), Value(data=-143.2366922177522, grad=0), Value(data=-110.49418961029255, grad=0)], [Value(data=-108.97994698636869, grad=0), Value(data=-160.26522522722905, grad=0), Value(data=-132.4716499703075, grad=0), Value(data=-127.40416195261537, grad=0), Value(data=-262.71444286125546, grad=0), Value(data=-122.51615903251691, grad=0), Value(data=-171.11908222882013, grad=0), Value(data=-84.19454359021952, grad=0), Value(data=-166.93662628604662, grad=0), Value(data=-128.77461644098568, grad=0)], [Value(data=-82.97299359215651, grad=0), Value(data=-122.01381748964718, grad=0), Value(data=-100.85600935626724, grad=0), Value(data=-96.99839340706218, grad=0), Value(data=-200.019116036845, grad=0), Value(data=-93.27741015885307, grad=0), Value(data=-130.27629620366648, grad=0), Value(data=-64.10515076457523, grad=0), Value(data=-127.09240929651227, grad=0), Value(data=-98.04164937008362, grad=0)], [Value(data=-53.342461502921715, grad=0), Value(data=-78.43279716609548, grad=0), Value(data=-64.83532521321358, grad=0), Value(data=-62.35615419778353, grad=0), Value(data=-128.58837729721293, grad=0), Value(data=-59.96479281310196, grad=0), Value(data=-83.74283787857892, grad=0), Value(data=-41.21667975643435, grad=0), Value(data=-81.69665177800287, grad=0), Value(data=-63.026622689010686, grad=0)], [Value(data=-103.55629626258153, grad=0), Value(data=-152.28804035220313, grad=0), Value(data=-125.87832896495301, grad=0), Value(data=-121.06315514264065, grad=0), Value(data=-249.63957209284928, grad=0), Value(data=-116.41852971440655, grad=0), Value(data=-162.60147531696606, grad=0), Value(data=-80.00497750427043, grad=0), Value(data=-158.62726712973293, grad=0), Value(data=-122.36537362920286, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07437084851013816, grad=0), Value(data=0.10936658447345837, grad=0), Value(data=0.09040097378495175, grad=0), Value(data=0.08694305216012277, grad=0), Value(data=0.17928283635711784, grad=0), Value(data=0.0836076064835618, grad=0), Value(data=0.11677297334059897, grad=0), Value(data=0.057457935823531175, grad=0), Value(data=0.11391897451535897, grad=0), Value(data=0.08787821455116043, grad=0)], [Value(data=0.0743699317987707, grad=0), Value(data=0.10936795437562911, grad=0), Value(data=0.09040110447837417, grad=0), Value(data=0.08694295691372182, grad=0), Value(data=0.17928119565508183, grad=0), Value(data=0.0836072932998885, grad=0), Value(data=0.116774827174557, grad=0), Value(data=0.05745591402624239, grad=0), Value(data=0.11392064186967393, grad=0), Value(data=0.08787818040806036, grad=0)], [Value(data=0.07437166871854159, grad=0), Value(data=0.10936535878202232, grad=0), Value(data=0.09040085684973401, grad=0), Value(data=0.08694313737985626, grad=0), Value(data=0.17928430434109321, grad=0), Value(data=0.0836078866981307, grad=0), Value(data=0.11677131466127522, grad=0), Value(data=0.057459744784546816, grad=0), Value(data=0.11391748268481199, grad=0), Value(data=0.08787824509998808, grad=0)], [Value(data=0.07437571202838128, grad=0), Value(data=0.10935931659783718, grad=0), Value(data=0.0904002804043885, grad=0), Value(data=0.08694355748014483, grad=0), Value(data=0.17929154093368024, grad=0), Value(data=0.08360926804745478, grad=0), Value(data=0.11676313801445885, grad=0), Value(data=0.057468662261914306, grad=0), Value(data=0.11391012853786045, grad=0), Value(data=0.08787839569387973, grad=0)], [Value(data=0.0743702220230858, grad=0), Value(data=0.109367520674321, grad=0), Value(data=0.09040106310176388, grad=0), Value(data=0.08694298706805663, grad=0), Value(data=0.17928171508970606, grad=0), Value(data=0.08360739245161751, grad=0), Value(data=0.11677424026387842, grad=0), Value(data=0.05745655411291986, grad=0), Value(data=0.11392011399712731, grad=0), Value(data=0.0878781912175236, grad=0)]]\n",
            "total loss: Value(data=0.16042914512890644, grad=1)\n",
            "scores [[Value(data=-93.49654602820324, grad=0), Value(data=-137.49865550601936, grad=0), Value(data=-113.65212521147167, grad=0), Value(data=-109.30428563293242, grad=0), Value(data=-225.48699621563256, grad=0), Value(data=-105.11044196091555, grad=0), Value(data=-146.8111252911606, grad=0), Value(data=-72.23098852128747, grad=0), Value(data=-143.22263185614915, grad=0), Value(data=-110.48011796728038, grad=0)], [Value(data=-108.96366001055843, grad=0), Value(data=-160.24901220225848, grad=0), Value(data=-132.45539686837333, grad=0), Value(data=-127.38790154361362, grad=0), Value(data=-262.7900980271874, grad=0), Value(data=-122.49989157525624, grad=0), Value(data=-171.10288485457562, grad=0), Value(data=-84.17822087508098, grad=0), Value(data=-166.9204228809071, grad=0), Value(data=-128.75835800811166, grad=0)], [Value(data=-82.9604750469296, grad=0), Value(data=-122.00129942043564, grad=0), Value(data=-100.84349102908364, grad=0), Value(data=-96.98587503284358, grad=0), Value(data=-200.07642970939332, grad=0), Value(data=-93.26489173926544, grad=0), Value(data=-130.26377823519732, grad=0), Value(data=-64.09263198929726, grad=0), Value(data=-127.07989128922277, grad=0), Value(data=-98.0291310085852, grad=0)], [Value(data=-53.334593410002725, grad=0), Value(data=-78.42501392531726, grad=0), Value(data=-64.82749598761396, grad=0), Value(data=-62.348316587960966, grad=0), Value(data=-128.62565484472935, grad=0), Value(data=-59.956947116016806, grad=0), Value(data=-83.73507259564423, grad=0), Value(data=-41.208770655752325, grad=0), Value(data=-81.68887957514198, grad=0), Value(data=-63.01878734662238, grad=0)], [Value(data=-103.540679026421, grad=0), Value(data=-152.27242704960534, grad=0), Value(data=-125.86271353059782, grad=0), Value(data=-121.0475393196109, grad=0), Value(data=-249.71112207833357, grad=0), Value(data=-116.40291351646871, grad=0), Value(data=-162.5858628468553, grad=0), Value(data=-79.98935836707818, grad=0), Value(data=-158.61165433882925, grad=0), Value(data=-122.3497579112865, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07436331709945425, grad=0), Value(data=0.10936078983129932, grad=0), Value(data=0.09039423791738933, grad=0), Value(data=0.08693614468281206, grad=0), Value(data=0.17934310638949663, grad=0), Value(data=0.08360053347473968, grad=0), Value(data=0.11676754626273637, grad=0), Value(data=0.05744956505874854, grad=0), Value(data=0.11391340579923123, grad=0), Value(data=0.08787135348409263, grad=0)], [Value(data=0.07436240034468104, grad=0), Value(data=0.10936215981611971, grad=0), Value(data=0.09039436862514684, grad=0), Value(data=0.08693604943829072, grad=0), Value(data=0.17934146553284025, grad=0), Value(data=0.08360022028093163, grad=0), Value(data=0.11676940020602203, grad=0), Value(data=0.05744754315713334, grad=0), Value(data=0.11391507325259365, grad=0), Value(data=0.08787131934624062, grad=0)], [Value(data=0.07436413734367327, grad=0), Value(data=0.10935956407042849, grad=0), Value(data=0.09039412096977625, grad=0), Value(data=0.08693622990054999, grad=0), Value(data=0.1793445745064086, grad=0), Value(data=0.08360081369734443, grad=0), Value(data=0.11676588749170293, grad=0), Value(data=0.05745137410644573, grad=0), Value(data=0.11391191388555802, grad=0), Value(data=0.08787138402811219, grad=0)], [Value(data=0.07436818078137608, grad=0), Value(data=0.10935352161672422, grad=0), Value(data=0.09039354447026918, grad=0), Value(data=0.08693664998594226, grad=0), Value(data=0.1793518116671666, grad=0), Value(data=0.08360219506964672, grad=0), Value(data=0.11675771049126671, grad=0), Value(data=0.05746029190372519, grad=0), Value(data=0.11390455941739423, grad=0), Value(data=0.08787153459648862, grad=0)], [Value(data=0.07436269058843002, grad=0), Value(data=0.10936172608013936, grad=0), Value(data=0.09039432724318662, grad=0), Value(data=0.0869360795926218, grad=0), Value(data=0.1793419850266039, grad=0), Value(data=0.08360031943781378, grad=0), Value(data=0.11676881324922035, grad=0), Value(data=0.05744818328939336, grad=0), Value(data=0.11391454533833642, grad=0), Value(data=0.08787133015425433, grad=0)]]\n",
            "total loss: Value(data=0.16042665168050926, grad=1)\n",
            "scores [[Value(data=-93.482504434283, grad=0), Value(data=-137.48462920846868, grad=0), Value(data=-113.63809062419705, grad=0), Value(data=-109.2902495342266, grad=0), Value(data=-225.55147560645406, grad=0), Value(data=-105.09640440431183, grad=0), Value(data=-146.79710223088603, grad=0), Value(data=-72.21693953486196, grad=0), Value(data=-143.20860754841343, grad=0), Value(data=-110.4660822773269, grad=0)], [Value(data=-108.94741487055033, grad=0), Value(data=-160.2328411858407, grad=0), Value(data=-132.4391856813714, grad=0), Value(data=-127.37168303247464, grad=0), Value(data=-262.8655334984791, grad=0), Value(data=-122.48366599939345, grad=0), Value(data=-171.08672952544427, grad=0), Value(data=-84.16193991225688, grad=0), Value(data=-166.9042615067924, grad=0), Value(data=-128.7421414777167, grad=0)], [Value(data=-82.94798831708893, grad=0), Value(data=-121.98881326433096, grad=0), Value(data=-100.83100456204812, grad=0), Value(data=-96.97338850911733, grad=0), Value(data=-200.13357578211293, grad=0), Value(data=-93.25240516085637, grad=0), Value(data=-130.25129220051636, grad=0), Value(data=-64.08014498217861, grad=0), Value(data=-127.06740520775205, grad=0), Value(data=-98.01664450019041, grad=0)], [Value(data=-53.32674582533948, grad=0), Value(data=-78.41725130719013, grad=0), Value(data=-64.81968732266995, grad=0), Value(data=-62.34049952749063, grad=0), Value(data=-128.66282516083558, grad=0), Value(data=-59.949121957380854, grad=0), Value(data=-83.72732795957091, grad=0), Value(data=-41.20088200804047, grad=0), Value(data=-81.68112800981321, grad=0), Value(data=-63.010972556643196, grad=0)], [Value(data=-103.5251014811068, grad=0), Value(data=-152.25685355247322, grad=0), Value(data=-125.8471378395914, grad=0), Value(data=-121.03196322860444, grad=0), Value(data=-249.78246285567022, grad=0), Value(data=-116.38733703962977, grad=0), Value(data=-162.57029020646786, grad=0), Value(data=-79.9737788653385, grad=0), Value(data=-158.5960813683014, grad=0), Value(data=-122.33418192845629, grad=0)]]\n",
            "scores.shape (5, 10)\n",
            "[[Value(data=0.07435580551882406, grad=0), Value(data=0.10935501154057141, grad=0), Value(data=0.0903875202864649, grad=0), Value(data=0.08692925578586136, grad=0), Value(data=0.17940321299871814, grad=0), Value(data=0.08359347937782527, grad=0), Value(data=0.11676213480009998, grad=0), Value(data=0.05744121580518564, grad=0), Value(data=0.11390785298202094, grad=0), Value(data=0.08786451090442841, grad=0)], [Value(data=0.0743548887207074, grad=0), Value(data=0.10935638160788042, grad=0), Value(data=0.09038765100851753, grad=0), Value(data=0.08692916054320168, grad=0), Value(data=0.17940157198784637, grad=0), Value(data=0.08359316617388583, grad=0), Value(data=0.116763988852505, grad=0), Value(data=0.05743919379941423, grad=0), Value(data=0.11390952053424075, grad=0), Value(data=0.08786447677180062, grad=0)], [Value(data=0.07435662579880548, grad=0), Value(data=0.10935378571040613, grad=0), Value(data=0.09038740332649195, grad=0), Value(data=0.08692934100162004, grad=0), Value(data=0.17940468124820833, grad=0), Value(data=0.08359375960846377, grad=0), Value(data=0.11676047593753823, grad=0), Value(data=0.057443024939417574, grad=0), Value(data=0.11390636098538712, grad=0), Value(data=0.0878645414436614, grad=0)], [Value(data=0.07436066936406367, grad=0), Value(data=0.10934774298794434, grad=0), Value(data=0.09038682677300543, grad=0), Value(data=0.08692976107219247, grad=0), Value(data=0.1794119189752813, grad=0), Value(data=0.08359514100371881, grad=0), Value(data=0.11675229858447005, grad=0), Value(data=0.05745194305578449, grad=0), Value(data=0.11389900619691176, grad=0), Value(data=0.08786469198662764, grad=0)], [Value(data=0.07435517898387632, grad=0), Value(data=0.10935594783726994, grad=0), Value(data=0.09038760962121911, grad=0), Value(data=0.08692919069753524, grad=0), Value(data=0.17940209154063258, grad=0), Value(data=0.08359326533592198, grad=0), Value(data=0.1167634018496342, grad=0), Value(data=0.05743983397721578, grad=0), Value(data=0.11390899257832238, grad=0), Value(data=0.08786448757837245, grad=0)]]\n",
            "total loss: Value(data=0.16042417222857497, grad=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('model total parameters',len(model.parameters()))\n",
        "# in_inputs\n",
        "layer_len = len(model.layers)\n",
        "print('layer length',layer_len)\n",
        "# print('in_inputs',in_inputs)\n",
        "# print('length of parameters',len(model.layers[layer_len-4].parameters()))\n",
        "# counter = 0\n",
        "# for l in range(len(model.layers):\n",
        "#   if(p.grad != 0):\n",
        "#     print('counter',counter)\n",
        "#     print('p ', p)\n",
        "#   counter += 1\n",
        "for l in range(len(model.layers)):\n",
        "  print(f'Layer {l}')\n",
        "  for p in model.layers[l].parameters():\n",
        "    print('p',p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BQBi4r2KwZu",
        "outputId": "e83022ef-51f3-4894-b9e9-06b065c80869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model total parameters 40\n",
            "layer length 2\n",
            "Layer 0\n",
            "p Value(data=0.3654248334954173, grad=0.0)\n",
            "p Value(data=-0.4374068669121398, grad=0.0)\n",
            "p Value(data=-0.8555745462165814, grad=0.0)\n",
            "p Value(data=-0.9496480928712234, grad=0.0)\n",
            "p Value(data=0, grad=0.0)\n",
            "p Value(data=-0.5086089169313228, grad=5.745404152435185e-15)\n",
            "p Value(data=0.8058789569529698, grad=1.1379786002407855e-14)\n",
            "p Value(data=-0.12017622482722823, grad=9.270362255620057e-15)\n",
            "p Value(data=-0.6389466672066417, grad=6.2450045135165055e-15)\n",
            "p Value(data=0, grad=1.942890293094024e-16)\n",
            "Layer 1\n",
            "p Value(data=0.2851531415759261, grad=0.0)\n",
            "p Value(data=0.5779119841823439, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=0.030763850698566575, grad=0.0)\n",
            "p Value(data=-0.7234122934672151, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=-0.848132684255062, grad=0.0)\n",
            "p Value(data=-0.04388960273528686, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=0.7352558441309898, grad=0.0)\n",
            "p Value(data=0.15517150222807108, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=-0.5019978680000179, grad=0.0)\n",
            "p Value(data=0.4768361512534742, grad=-8.587572353112424)\n",
            "p Value(data=0, grad=-0.7641282640818202)\n",
            "p Value(data=0.48405372699803917, grad=0.0)\n",
            "p Value(data=-0.1689058744699039, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=-0.3565075714869015, grad=0.0)\n",
            "p Value(data=-0.26396186461101, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=-0.49663513311351903, grad=0.0)\n",
            "p Value(data=-0.13519878440924926, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=-0.5122030691123258, grad=0.0)\n",
            "p Value(data=0.6767873254426542, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n",
            "p Value(data=0.3148266711155663, grad=0.0)\n",
            "p Value(data=-0.32738050119416173, grad=-16.193038476581734)\n",
            "p Value(data=0, grad=-1.4408680209647295)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Draft 3: Run MLP on full MNIST training set and test on test set(turns out there is a bug in my loss)\n",
        "- New problem the loss function is not optimizing for the prediction that is suppose to happen. The loss is going down but the accuracy /prediction is not getting better..\n",
        "- TODO: fix my loss function here!, implement batched gradient descent"
      ],
      "metadata": {
        "id": "KPrU2VeV3dQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziBLFpr038p4",
        "outputId": "31a9c907-d1a1-4eea-8d44-f9c5531eb2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the MLP model\n",
        "in_inputs=28*28\n",
        "output_dim = len(unique_integers)\n",
        "model = MLP(in_inputs, [6,6,output_dim])\n",
        "\n",
        "# limit training set to overfit\n",
        "# on smaller test size.\n",
        "limit_x=5\n",
        "\n",
        "# reshape here to flatten the 2D [28,28] into 1D -> 28*28\n",
        "inputs = train_X[:limit_x].reshape(limit_x,-1)\n",
        "expected_outputs = yy_one[:limit_x]\n",
        "\n",
        "# Begin gradient descent iterations\n",
        "iterations = 100\n",
        "for iter in range(iterations):\n",
        "  # forward the model to get scores\n",
        "  scores = list(map(model, inputs))\n",
        "  # Get probabilities of each output\n",
        "  probs_predicted = []\n",
        "  for i in range(len(scores)):\n",
        "      total = sum(scores[i])\n",
        "      probs_predicted.append([])\n",
        "      if total.data == 0:\n",
        "          print(f\"Alert: Sum of scores at index {i} is zero.\")\n",
        "      for j in range(len(scores[i])):\n",
        "          if total.data == 0:\n",
        "              probs_predicted[i].append(Value(0.0))\n",
        "          else:\n",
        "              probs_predicted[i].append(scores[i][j] / total)\n",
        "\n",
        "  # Mean Squared Error(MSE) Loss\n",
        "    # Gain an intuition for how this will back propagate to help you update your parameters\n",
        "  losses = []\n",
        "  correct = 0\n",
        "  # print('expected_outputs',expected_outputs)\n",
        "  # print('probs_predicted',probs_predicted)\n",
        "  # print('shape of probs_predicted',np.array(probs_predicted).shape)\n",
        "  for yi_one, probs in zip(expected_outputs, probs_predicted):\n",
        "    loss = []\n",
        "    probs_list = [p.data for p in probs]\n",
        "    print('yi_one',yi_one)\n",
        "    print('probs_list',probs_list)\n",
        "    print('yi_one.index(max(yi_one))',yi_one.index(max(yi_one)))\n",
        "    print('probs_list.index(max(probs_list))',probs_list.index(max(probs_list)))\n",
        "    if(yi_one.index(max(yi_one)) == probs_list.index(max(probs_list))):\n",
        "      correct += 1\n",
        "    for k in range(len(yi_one)):\n",
        "      loss.append((yi_one[k]-probs[k])**2)\n",
        "    losses.append(loss)\n",
        "  # Calculate total loss\n",
        "    # take (sum_of_each_example/num_classes)\n",
        "    # then data_loss = sum across all the examples / num_of_examples\n",
        "    # data_loss.backward()\n",
        "  data_loss = [sum(loss) for loss in losses ]\n",
        "  data_loss = sum(data_loss)/limit_x\n",
        "\n",
        "  # Back propagation\n",
        "  model.zero_grad()\n",
        "  data_loss.backward()\n",
        "  print('Iteration '+str(iter) +' total loss: '+str(data_loss.data))\n",
        "  # print('correct',correct)\n",
        "  # print('limit_x',limit_x)\n",
        "  # print('correct/limit_x',correct/limit_x)\n",
        "  print('Accuracy:'+str(correct/limit_x))\n",
        "  # Update parameters\n",
        "  for p in model.parameters():\n",
        "    p.data -= p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEYDxBTp3bqS",
        "outputId": "a7e1267c-b4e1-448b-9e4f-100325f423c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16535677076612484, 0.1800848730198886, 0.17284940061499218, 0.154763877300878, 0.04760576070154923, 0.05330214513224734, 0.056708955580511054, 0.0988851278899739, 0.16938976493741248, -0.09894667594357763]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.14055137118341016, 0.21871312863623024, 0.23468072841687193, 0.13009321648459654, 0.11592329693403318, 0.1529564095569175, 0.02050019596306311, 0.1494686555825496, -0.011814752557464829, -0.15107225020020731]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 2\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16535677076612482, 0.18008487301988857, 0.17284940061499218, 0.154763877300878, 0.04760576070154923, 0.05330214513224733, 0.05670895558051105, 0.0988851278899739, 0.16938976493741245, -0.09894667594357762]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3071577796611223, 0.13919642629119336, 0.09630528911837664, 0.4506154575442457, 0.20752311940132734, -0.34349386452517344, -0.016625623663437273, 0.31543333733054063, 0.09439609751558516, -0.2505080186737803]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 3\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16535677076612484, 0.1800848730198886, 0.1728494006149922, 0.154763877300878, 0.04760576070154924, 0.05330214513224734, 0.056708955580511054, 0.0988851278899739, 0.16938976493741248, -0.09894667594357763]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 0 total loss: 1.1655668202750726\n",
            "Accuracy:0.0\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1619059491125474, 0.16314747443465727, 0.1531815421613174, 0.138078693076545, 0.06398748242622054, 0.070295393779789, 0.058607102066731843, 0.0911083614652555, 0.15383757421670274, -0.054149572739766845]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16135711203510744, 0.16350577391500812, 0.15256246210326482, 0.13721811503432385, 0.0640935036888225, 0.07086809926587873, 0.05887473135156836, 0.09073265570777678, 0.15329785105584243, -0.05251030415759309]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1606475236010833, 0.16396901733937683, 0.15176205690655659, 0.1361054784242324, 0.06423057799519755, 0.07160854703396144, 0.0592207477796347, 0.090246907803596, 0.15260004595435794, -0.05039090283799672]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16117863006816963, 0.16362229300352185, 0.15236113709991664, 0.13693825482080546, 0.06412798183227211, 0.0710543432458048, 0.05896176446782685, 0.09061047609320436, 0.15312233293705646, -0.05197721356857798]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16105137184088267, 0.16370537149544867, 0.1522175917128157, 0.13673871357150438, 0.06415256486153166, 0.07118713581378727, 0.05902381936491436, 0.09052336162764885, 0.1529971879432139, -0.051597118231747584]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 1 total loss: 0.9786209890455306\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16201923380901728, 0.16304066888131005, 0.14124036919041527, 0.1277224970753369, 0.07412209503161339, 0.07988321970633787, 0.05640345631540878, 0.08558482199475059, 0.14182216704709924, -0.03183852905128941]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16147896096061803, 0.1633888556598364, 0.14065646695453088, 0.12690369898062864, 0.07425208571913502, 0.08037853895926925, 0.05666556421371162, 0.0852291614944604, 0.1413149797719984, -0.030268312714188637]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1607795828396512, 0.16383958016992933, 0.1399006110018006, 0.12584377254785506, 0.07442035744156457, 0.08101972507369311, 0.05700486042293023, 0.08476876232183485, 0.14065843061449526, -0.02823568243375419]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16130479629994995, 0.16350109863541964, 0.14046823773835346, 0.12663974773313758, 0.07429399007181403, 0.08053821218709246, 0.05675005843418113, 0.0851145092580402, 0.14115148071790962, -0.029762131075898115]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16117238984658164, 0.16358642992051198, 0.1403251388867337, 0.1264390821767132, 0.0743258473194189, 0.08065960171418048, 0.05681429408347744, 0.08502734636324337, 0.14102718265538694, -0.02937731296624771]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 2 total loss: 0.9518927956996301\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16280314105370977, 0.1636525696118267, 0.1316711465249643, 0.11933324981979698, 0.08234125381898137, 0.0877145473250706, 0.05406925763733656, 0.08078598834738178, 0.1321972678216867, -0.01456842196075482]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16226387746314316, 0.16399444652003808, 0.13111065974516467, 0.11854167473602689, 0.08249633048362504, 0.08814627149426665, 0.054329453816506154, 0.08044406027913635, 0.131711919095536, -0.013038693633443024]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16156479697782325, 0.16443764253603643, 0.13038406633724323, 0.11751550737852416, 0.08269736588055765, 0.08870594202831623, 0.05466676209096453, 0.0800007979412463, 0.13108273175753987, -0.011055612928251834]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16209129953134566, 0.16410385574176295, 0.130931289858249, 0.11828835077125495, 0.08254595892233743, 0.08828443410255359, 0.05441272314758693, 0.08033463468491199, 0.13155659527834368, -0.012549142038346185]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16195246104380276, 0.16419187516990946, 0.1307869872608617, 0.11808455231474907, 0.08258588486940478, 0.08839558555378339, 0.054479713103171325, 0.08024660208513311, 0.1314316376801516, -0.012155299080967323]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 3 total loss: 0.9320181430751875\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16396169988921175, 0.16466734939936264, 0.12352663487598627, 0.11212925553283928, 0.08940524144961373, 0.09448564036997104, 0.05167991939140693, 0.0764378051372851, 0.12400804496320901, -0.00030159100888582364]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16341890322640898, 0.1650052158476771, 0.1229827800296575, 0.11135642783349349, 0.0895862658010426, 0.09486136522515837, 0.051940343880805866, 0.07610592773807773, 0.12353838510717376, 0.0012043853105047574]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1627140443091545, 0.16544395874212628, 0.12227654698808452, 0.11035285774414856, 0.08982133841126455, 0.09534926987299716, 0.05227852304844557, 0.07567496203711224, 0.122928499379628, 0.0031599994670385386]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16324627786704624, 0.16511266735033683, 0.12280981813670135, 0.11111064581516614, 0.08964383688771332, 0.09498085681859096, 0.052023166554838525, 0.07600038092980019, 0.12338901941098897, 0.0016833302288174973]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16310005488717116, 0.16520368456222836, 0.12266331009474125, 0.1109024552037043, 0.089692602699867, 0.09508207263604815, 0.05209332182196145, 0.07591097709666915, 0.12326249861898084, 0.002089022378628325]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 4 total loss: 0.916169242671445\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1653583111652545, 0.1659384626500228, 0.11632809577226011, 0.10571375118575145, 0.09570015161366624, 0.1005511449101193, 0.04926290750818662, 0.07239478322147243, 0.11677199455977755, 0.011980397413489165]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16480883575688457, 0.1662738669457212, 0.11579647412661156, 0.10495411852202141, 0.09590797996698298, 0.10087536081834916, 0.049525013358883145, 0.07207055291516079, 0.1163140503138685, 0.013473747275516652]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16409388459615537, 0.1667102789977811, 0.11510475342931455, 0.10396572077684695, 0.09617839629530796, 0.10129721507494546, 0.04986605297473299, 0.0716486799244681, 0.11571819513058886, 0.015416822799858659]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16463504089501815, 0.16637995275475356, 0.11562832627310747, 0.10471385253040252, 0.09597371448286199, 0.10097790782614496, 0.04960791543133681, 0.07196800135336204, 0.11616920605742327, 0.01394608239558921]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.1644806011983307, 0.1664742240122226, 0.11547890468943728, 0.10450034445271, 0.09603212828511845, 0.101069034391166, 0.04968158487580143, 0.07187687074150771, 0.11604049279863017, 0.014365814555075683]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 5 total loss: 0.902972463294352\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16691977316562068, 0.1673869720801907, 0.10979829727292728, 0.09985621202957205, 0.1014503747895958, 0.10611771556969042, 0.0468292964515911, 0.06856950760188996, 0.11020973596227618, 0.022862115076645668]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16636121565956677, 0.16772103224875173, 0.10927583095148596, 0.09910584489055767, 0.10168593686894768, 0.10639310134663237, 0.047094166113368405, 0.06825123715246177, 0.10976073896427838, 0.024350895803949144]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16563277744638139, 0.16815669409134723, 0.10859446076217644, 0.09812725970988714, 0.10199314323233467, 0.10675224346023399, 0.047439593721199075, 0.06783616734321495, 0.10917518319356151, 0.026292477039663576]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1661854037503201, 0.16782618123592208, 0.10911137912603543, 0.0988696588615164, 0.1017600825360779, 0.10647978194567323, 0.0471775366534361, 0.0681510581471413, 0.10961941238893311, 0.024819505354944166]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16602194999197933, 0.1679239391023395, 0.10895848692976118, 0.09865007479420376, 0.10182901636433253, 0.10656036960181767, 0.04725504692089955, 0.06805792091316985, 0.10948801992529054, 0.025255175456206043]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 6 total loss: 0.8916593380020266\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.16860256287883457, 0.16896572477730623, 0.10376199443405623, 0.09441056641276059, 0.10679810096179491, 0.11131661324426179, 0.04438384405977748, 0.06490525516530332, 0.10414468004095827, 0.032710658024946535]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16803294827407597, 0.16929928861292104, 0.10324641045854178, 0.09366652552829112, 0.10706242952038132, 0.11154467359035336, 0.04465234068278204, 0.0645916983931663, 0.1037025960570029, 0.03420108888248395]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16728813953891566, 0.16973544536947893, 0.10257225034139635, 0.09269364290653302, 0.10740805657724185, 0.11184287756281766, 0.04500341775928993, 0.06418170219414801, 0.10312454203561074, 0.036149925714567634]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16785443189869328, 0.16940382702607845, 0.1030848272025204, 0.09343334421460567, 0.10714526970003052, 0.1116161473658021, 0.04473648712766051, 0.06449343016413743, 0.10356404758972142, 0.03466818771075037]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16768115915632367, 0.16950529479054488, 0.1029279901962132, 0.09320701222906651, 0.10722567658189455, 0.11168552171340994, 0.044818161905301926, 0.06439804840716902, 0.10342956876207604, 0.03512156625800016]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 7 total loss: 0.8817590537445487\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.17037851229832998, 0.17064409595505164, 0.0981015211816958, 0.0892786065464714, 0.11183890127169227, 0.1162362496950605, 0.041928893984019465, 0.061363386775568796, 0.09845826272060436, 0.041771569571505886]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16979612567997274, 0.17097782937271297, 0.0975910721265285, 0.08853859966403009, 0.11213314498976154, 0.11641766438455527, 0.04220174195404443, 0.06105358816096332, 0.09802153688816125, 0.043268696779269894]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16903235279977957, 0.1714155051804829, 0.09692164200439296, 0.0875681151608675, 0.11251903189880907, 0.11665558128638177, 0.04255956933769663, 0.06064730173078312, 0.09744879133325697, 0.045232109267549406]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16961431600550583, 0.17108201439707854, 0.09743171994770669, 0.08830758403599348, 0.11222500210479447, 0.11647429849083604, 0.04228691973637245, 0.0609568751124551, 0.09788519965285226, 0.04373607051640497]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.16943038692215184, 0.1711874139369378, 0.0972705101536344, 0.08807387539078629, 0.1123179300252536, 0.11653159279756282, 0.04237309046117936, 0.06085903465147499, 0.09774727309426333, 0.04420889256675546]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 8 total loss: 0.8729644234383628\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.17222787878939197, 0.17240059329310153, 0.0927344655315793, 0.08439155883702758, 0.1166396550940141, 0.12093860444686085, 0.039466114891531234, 0.05791686289699213, 0.09306744160956038, 0.05021682460994103]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17163116809796217, 0.17273503256350903, 0.09222776601948433, 0.08365373966192398, 0.11696508516090966, 0.1210734345861992, 0.03974394576835462, 0.057610068785096884, 0.09263484932783507, 0.05172491002872507]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17084599620986307, 0.17317509894269714, 0.09156103385207968, 0.08268289251084693, 0.11739329692875376, 0.12125084859368632, 0.04010952492968144, 0.05720637883022566, 0.09206562993308033, 0.05370929926908571]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1714455391638435, 0.1728390722701622, 0.09207013839239546, 0.083424213714067, 0.1170663222215416, 0.12111537848868313, 0.03983037534012316, 0.05751462912764992, 0.09250027549613077, 0.0521940557854033]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17125006722087327, 0.17294862870166416, 0.09190415253098252, 0.08318251711001817, 0.11717292739619432, 0.12115954647441887, 0.0399213878560539, 0.05741412876456727, 0.09235856586190223, 0.0526880780833254]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 9 total loss: 0.865065741524804\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.17413564410618973, 0.1742189022095363, 0.08760145557502028, 0.07969998896578369, 0.12124837122154991, 0.12546822507713, 0.03699737788512189, 0.05454664721770624, 0.08791238481624394, 0.05817100292571789]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17352316115359603, 0.1745544862751672, 0.0870973809276653, 0.0789628326813288, 0.12160638524154567, 0.12555604220140018, 0.03728075762833609, 0.054242250266109474, 0.08748293925051069, 0.05969376437434061]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17271423137030278, 0.17499770505266588, 0.08643163016101661, 0.0779892420353979, 0.12207922812212656, 0.12567202565368155, 0.03765502815014768, 0.05384022150914968, 0.086915753981184, 0.06170493396432722]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1733332280807275, 0.17465855204960393, 0.08694106564358789, 0.07873423797890002, 0.12171740662207527, 0.12558327459406105, 0.037368634662610166, 0.05414785572313688, 0.08734976670165186, 0.060165977943645414]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17312526494789468, 0.17477249663095398, 0.08676991158550085, 0.0784839431263601, 0.12183896709470736, 0.1256130921166586, 0.03746485373112565, 0.05404450044865821, 0.08720395228371115, 0.06068301803442929]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 10 total loss: 0.8579150406205852\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.17608937047041925, 0.1760855948548506, 0.08265904953685636, 0.07516792395911358, 0.12569990658924252, 0.1298574681735307, 0.03452525862791074, 0.05123960734058508, 0.08294930453962111, 0.06572651590787018]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17545973435137682, 0.17642268583756524, 0.08215667021154241, 0.07443014706433732, 0.12609203104570868, 0.12989743917386148, 0.034814703795900855, 0.0509371101758134, 0.08252219666353404, 0.06726728168035988]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17462470888318476, 0.17686973699481565, 0.08149041311693939, 0.073451704947772, 0.12661206777477718, 0.1299504488444567, 0.03519856691875417, 0.05053593745239275, 0.08195576480962366, 0.06931065025728367]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17526503970298465, 0.17652692034440326, 0.08200132561941473, 0.07420201337127856, 0.12621328287810635, 0.12990979891565504, 0.03490420537229763, 0.05084357269066337, 0.0823901273377038, 0.06774371376749268]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17504356477037783, 0.17664549232657065, 0.08182461335045185, 0.07394249984734362, 0.126351212922052, 0.12992385874217507, 0.03500601790676826, 0.050737169107458124, 0.08223989185214099, 0.06828567917466143]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 11 total loss: 0.8514053660099258\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.17807786944053178, 0.17798870980693396, 0.07787540264273439, 0.07076927289392479, 0.1300194483136992, 0.13412968766992642, 0.03205336340799148, 0.04798724833811312, 0.07814608943016588, 0.07295290805597897]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17742974411512621, 0.17832760607540002, 0.07737394046380273, 0.07002978022645433, 0.13044733986460605, 0.1341206335528191, 0.032349350328215426, 0.04768623892168175, 0.07772064783221262, 0.07451471861968191]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1765662686899509, 0.17877910609867234, 0.07670585938258377, 0.069044579185192, 0.1310174052892474, 0.1341085710591741, 0.03274368367975778, 0.04728521426850652, 0.07715384639693454, 0.07659546594998042]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17722984940822514, 0.17843212840711495, 0.07721927958055952, 0.06980170601885104, 0.1305793101067817, 0.13411784108350108, 0.03244063856576066, 0.04759340164667732, 0.07758943320412634, 0.07499641197840232]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17699376056828664, 0.17855557617831808, 0.07703661487134925, 0.06953233532901279, 0.13073517567153164, 0.13411454299296094, 0.03254845599842912, 0.04748375469854829, 0.07743446006947907, 0.07556532362208415]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 12 total loss: 0.8454580399084135\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.18009032703942504, 0.17991682151995742, 0.07322753472051675, 0.0664855742303875, 0.13422470484700152, 0.13830123701925626, 0.029586563726002702, 0.044784932948693304, 0.0734795502877355, 0.07990275366102387]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17942240858415562, 0.18025776581271144, 0.07272633300001452, 0.06574342349249965, 0.13469015029790382, 0.1382416760724697, 0.02988953284177483, 0.04448506738594931, 0.07305521352314108, 0.08148842898937995]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17852808634302103, 0.18071427972034826, 0.07205523933221157, 0.06474970651113589, 0.1353133674219297, 0.13816192579907322, 0.03029519915698777, 0.04408355663265819, 0.07248703966402113, 0.08361159941861308]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.17921688930735105, 0.18036267476368387, 0.07257211265422506, 0.065515062856965, 0.13483336839841706, 0.13822334910064732, 0.029982756787117797, 0.044392798407442244, 0.07292464461268053, 0.08197634311147002]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17896499452528655, 0.18049125646050912, 0.07238309242703979, 0.0652351725546318, 0.13500890371937277, 0.13820088664045926, 0.030097016752219253, 0.04427970889781703, 0.0727646127764643, 0.08257435524620019]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 13 total loss: 0.8400144256945888\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1821157070363528, 0.18185840834503675, 0.06869956035814144, 0.062304540310410036, 0.13832732177750795, 0.1423827584860307, 0.02713117267151767, 0.04163139225171316, 0.06893363592819444, 0.08661550283509496]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18142671797956367, 0.18220159245080253, 0.0681980631891825, 0.06155891832015675, 0.1388322363731526, 0.1422709405007888, 0.027441529354566684, 0.04133238248281623, 0.06850993310905527, 0.08822768623991495]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18049909150362853, 0.1826636413897392, 0.06752286806532849, 0.06055504359619283, 0.13951203257947947, 0.14212039337297303, 0.027859380804227323, 0.040929808050814906, 0.06793947709224495, 0.09039826354537112]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18121516117779088, 0.18230696848126293, 0.06804407650954279, 0.061329972153254524, 0.1389872723871073, 0.1422366063483007, 0.027536825595671954, 0.041240570356363235, 0.06837983349072907, 0.0887227134999768]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.18094617063126656, 0.18244095214799713, 0.0678482853046907, 0.06103887135175059, 0.139184397801063, 0.14219295111072458, 0.02765799299734283, 0.04112383294180035, 0.06821441424094407, 0.08935213147242012]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 14 total loss: 0.8350303395982164\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.184142343613712, 0.18380142290946316, 0.06428151133104916, 0.05821908990724373, 0.14233382358226632, 0.14638003714046888, 0.02469507041223101, 0.038528405145834846, 0.06449824611822631, 0.09312004983950437]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1834310327806826, 0.18414698985585484, 0.06377924909253394, 0.05746929693746032, 0.14288024716384534, 0.14621397313459733, 0.025013183058587282, 0.03823000990703412, 0.06407478303986833, 0.09476123502953583]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18246757222156348, 0.18461505544395462, 0.06309894192627952, 0.05645371286317523, 0.14362037025065658, 0.1459890417649102, 0.025444062181875733, 0.037825837736073294, 0.06350120823220866, 0.09698419737930282]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18321303664469743, 0.18425289610041004, 0.0636253202864995, 0.05723950714288416, 0.14304771014045725, 0.1461630793341303, 0.025110675356600432, 0.03813856042245662, 0.06394500389054585, 0.09526421068131834]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.18292555533621024, 0.18439255942803795, 0.0634223274473252, 0.056936473006415515, 0.14326855109904577, 0.14609596339060216, 0.02523924283452194, 0.0380179618743768, 0.06377385828976272, 0.09592750729370188]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 15 total loss: 0.8304720723396749\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1861576828808684, 0.1857330198022462, 0.059968520902426915, 0.05422667457653723, 0.14624627097520584, 0.15029459530306657, 0.022287771281413633, 0.03548056301075124, 0.06016840951177943, 0.09943649175570443]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1854228296808989, 0.18608106419211762, 0.05946510001622825, 0.053472114352662345, 0.14683636153263696, 0.1500720858526778, 0.022613967283048635, 0.035182581005911144, 0.059744858534631205, 0.10110903754918696]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18442092563718915, 0.18655559037179156, 0.058778732423910005, 0.05244334161335304, 0.14764089516693257, 0.14976871489625085, 0.023058705215867954, 0.03477631023562063, 0.05916738614049907, 0.10338939829858507]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18519800477701137, 0.18618754674741533, 0.059311080747673245, 0.0532412601768663, 0.14701689698225456, 0.15000401012571657, 0.022713765426023515, 0.035091414803462576, 0.059615275091662215, 0.10162074512191427]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.18489052556786054, 0.1863331763966454, 0.05910043805609234, 0.0529255351029285, 0.14726380422567942, 0.1499109071361168, 0.022850253215169838, 0.03496673238907935, 0.05943805177754446, 0.10232057613288369]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 16 total loss: 0.8263134159521832\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1881481601603126, 0.18763942453650187, 0.05576021534929504, 0.05032876659400619, 0.1500627631874932, 0.15412414837743502, 0.019920415820495, 0.03249505583133743, 0.05594367089595955, 0.1055773792471639]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18738858244944415, 0.18798999149463735, 0.055255310919265, 0.04956894020996159, 0.1506987873924238, 0.15384281275438286, 0.020254975929815053, 0.03219732038849706, 0.05551976334909405, 0.10728351511247906]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1863455425053048, 0.18847138442547082, 0.05456198424451024, 0.048525558791800476, 0.15157216564153486, 0.15345648718380062, 0.020714388512284687, 0.03178847484810664, 0.0549376602967318, 0.10962635355045514]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18715655431477216, 0.18809707915164717, 0.055101077808667874, 0.04933683611311698, 0.15089307364880633, 0.15375687318704226, 0.02035717397616428, 0.03210637116968836, 0.05539027234907495, 0.10780468828101948]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.18682745131268802, 0.18824896965172783, 0.0548823173562337, 0.04900762536815456, 0.15116864449856385, 0.15363497861744801, 0.020502129172689156, 0.03197737103360801, 0.055206605498029415, 0.1085439074908575]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 17 total loss: 0.8225333357298781\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1900992153603917, 0.18950594397785103, 0.05166020082873243, 0.04653041131408179, 0.15377788039564205, 0.15786301211773318, 0.017605666091004706, 0.02958142737962561, 0.0518275751644911, 0.11154866737044628]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1893137800123595, 0.18985902707372512, 0.05115355114442434, 0.04576491371385396, 0.15446220084155735, 0.15752031969978234, 0.01794881771673756, 0.029283802080624786, 0.05140309537321639, 0.11329049234371859]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18822682785279263, 0.19034765345720575, 0.050452406269951545, 0.044705553103467036, 0.15540922160957713, 0.15704607281912936, 0.018423700088130265, 0.0288719229077544, 0.05081566417728859, 0.11570097771470314]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.18907419286014474, 0.18996673062137878, 0.050999004044732434, 0.04553140832028425, 0.15467094416747204, 0.15741578569745085, 0.018053491794614476, 0.02919301523484133, 0.05127361316361249, 0.1138218140954687]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.18872171501490342, 0.1901251828340741, 0.050771636140468236, 0.045187877887968346, 0.15497804493246192, 0.15726199648314765, 0.01820748708643881, 0.029059450678135375, 0.051083120435532654, 0.11460348850686956]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 18 total loss: 0.8191140751995226\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.19199545545228855, 0.1913171255651805, 0.04767556012710639, 0.042839768829170205, 0.15738313994046516, 0.1615025317893558, 0.015357481779450384, 0.026751255581139294, 0.04782716206241836, 0.11735051887342529]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19118309063245234, 0.19167266402741373, 0.0471669622358522, 0.04206828671746707, 0.15811819905363017, 0.16109583651757975, 0.015709391834310565, 0.02645363049709847, 0.047401942320175, 0.11912999616402072]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19004936644656809, 0.19216884818483107, 0.04645717062975963, 0.04099161782726167, 0.1591440365521297, 0.16052825868230342, 0.016200512240695596, 0.026038269383638433, 0.04680851201112495, 0.12161340804168749]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.190935611883532, 0.19178097523400225, 0.04701202301795686, 0.04183326247323995, 0.1583421273987119, 0.16097194090492722, 0.015816597683188705, 0.026362962017066824, 0.04727240341443086, 0.1196720959729433]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19055787650352446, 0.19194629437739655, 0.0467755339270547, 0.04147453683481064, 0.1586839169822335, 0.16078283474316288, 0.01598022968085191, 0.026224571577851817, 0.047074683699099756, 0.12049952167401377]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 19 total loss: 0.8160395778459621\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.1938209720247351, 0.19305707183999685, 0.04381629379075403, 0.0392675872643223, 0.16086752273279584, 0.16503158769889398, 0.013190759053330866, 0.02401772394135105, 0.04395240581383439, 0.12297807583998573]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1929806799434908, 0.19341494735330292, 0.043305599492048714, 0.038489897434854106, 0.1616558236565336, 0.16455816562793082, 0.01355152708262429, 0.023720012213487338, 0.04352632177338686, 0.12479702542234056]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19179724047986235, 0.19391896734226388, 0.042586354600387996, 0.03739462490379288, 0.16276604050040142, 0.16389141370412258, 0.014059620795049957, 0.023300724902083417, 0.04292623915980185, 0.12735877361223383]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19272500524235922, 0.19352383772243664, 0.04315021112756748, 0.03825327064857294, 0.16189567906821375, 0.1644141180411401, 0.013661297554257004, 0.02362942780986877, 0.04339667767447183, 0.12535047511111222]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19231999093926896, 0.19369633096002628, 0.0429040604139061, 0.03787843014806979, 0.16227563403432546, 0.1641859322538187, 0.013835184962246328, 0.023485933052898117, 0.043191308452802855, 0.12622719478263753]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 20 total loss: 0.8132941747892888\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.19555981320163066, 0.1947099082796336, 0.04009465988590883, 0.035826568315450974, 0.1642181080355822, 0.16843721417862184, 0.011120824805614495, 0.021395063679850453, 0.04021555356284085, 0.12842228605486616]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19469068188754465, 0.19506994163926966, 0.03958177162260847, 0.035042535479397945, 0.16506219321863055, 0.1678943033827101, 0.011490477224454681, 0.021097198270851342, 0.039788519647596526, 0.13028237762693598]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19345449809984488, 0.19558202467551516, 0.0388522798349836, 0.033927389050722526, 0.1662627533662295, 0.16712210991413284, 0.012016241651358082, 0.020673538021181853, 0.03918114030886208, 0.13292802507716936]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19442654019415348, 0.19517936103280698, 0.03942589739256641, 0.03480425645569586, 0.16531872302719147, 0.16772930486675716, 0.011602819990497192, 0.021006672625001825, 0.03965873780717727, 0.1308476866081523]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19399207849913588, 0.19535933464686883, 0.03916951461056709, 0.03441233382055384, 0.16574066465260867, 0.1674579144096279, 0.011787601983567533, 0.020857775549975883, 0.039445271929650874, 0.13177750989744344]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 21 total loss: 0.8108615323266716\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.19719659335149595, 0.19626038677361277, 0.036524389907560725, 0.032530607889464686, 0.1674208325841422, 0.17170534738922927, 0.009162796108709468, 0.018897865452079953, 0.0366303398831, 0.1336708406606052]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1962978058031133, 0.1966223346522694, 0.036009256145931756, 0.03174018119527349, 0.16832326128507147, 0.17109018868800024, 0.009541282422129984, 0.018599795966338362, 0.0362023044368823, 0.13557358940498962]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19500575560107555, 0.19714265208500092, 0.03526872666041885, 0.030603904917566226, 0.16962054581850625, 0.17020586855512967, 0.010085374647933016, 0.018171306786702125, 0.035586982956561236, 0.1383088819711063]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19602496409740272, 0.19673220986890846, 0.03585287884136756, 0.03150023420460768, 0.16859720832237396, 0.17090344717202352, 0.009656178151969149, 0.018509312083849826, 0.03607236725488552, 0.1361512000026117]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.1955587286881341, 0.19691996604960213, 0.03558565929586609, 0.03109020970668682, 0.1690653325364562, 0.17058434087226582, 0.009852513450069067, 0.01835469206388481, 0.03585032893024704, 0.13713822840678783]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 22 total loss: 0.80872388015311\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.19871720283743824, 0.1976945862064331, 0.03311978633294621, 0.029393921704223686, 0.17046136306782983, 0.17482169063741348, 0.007330837070172097, 0.016540283763875768, 0.033211082644400806, 0.13870924573526672]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19778804186433607, 0.19805813825317417, 0.032602396153376484, 0.028597129296129675, 0.1714246894577357, 0.17413156687864167, 0.007718028904118046, 0.016241973297357038, 0.03278202265681074, 0.1406560132383203]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19643689515867058, 0.19858680030906325, 0.03185002917186696, 0.027438467375901623, 0.17282551807180932, 0.17312801801019012, 0.00828106694170374, 0.01580818279628096, 0.032158101715717306, 0.14348692044879613]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19750630898411864, 0.19816837164459108, 0.03244551717362366, 0.028355532170802448, 0.17171678170684468, 0.17392231298196095, 0.007835430165828463, 0.01615152194461593, 0.03265192646294431, 0.1412462967646698]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19700580114731653, 0.1983642049326293, 0.032166816445702934, 0.027926326838141922, 0.1722356933072065, 0.17355056647126174, 0.008043997413964946, 0.01599083210656318, 0.03242080624538925, 0.14229495509182377]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 23 total loss: 0.8068615499742219\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20010955737438174, 0.19900064936886006, 0.029894738283640296, 0.02643009546432127, 0.1733260414049446, 0.17777265640057377, 0.00563736938683119, 0.014335183546470719, 0.029971696566010248, 0.14352201220396607]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19914940458959418, 0.1993654258013346, 0.029375115049754496, 0.025627036647830496, 0.17435279532386863, 0.17700492750637956, 0.006033062988665892, 0.014036605576690654, 0.029541611930673447, 0.14551401458520816]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19773579767872196, 0.19990247625209528, 0.02861008785188697, 0.024444714926939642, 0.17586445727866606, 0.17587462107212876, 0.006615631949568502, 0.01359701732760937, 0.028908409983645238, 0.14844678567873854]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19885863376597257, 0.1994758939949271, 0.02921775334848808, 0.02538383985958267, 0.17466373550692313, 0.17677242996388445, 0.0061528940783946925, 0.013946184798285686, 0.02941136592646953, 0.14611726875707196]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.1983211624311587, 0.1996800874099513, 0.02892688027334648, 0.024934306096965005, 0.1752384886171291, 0.17634267307511067, 0.00637439421017058, 0.013779047752488092, 0.029170614489094304, 0.14723234564458584]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 24 total loss: 0.8052528447613074\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20136430804284985, 0.20016947745957, 0.026861721109289256, 0.023651127007517356, 0.176002834773016, 0.18054631673684562, 0.004092313253978129, 0.01229330168966093, 0.026924690228078235, 0.14809390969919464]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2003726358537595, 0.20053502722598318, 0.026339915237927437, 0.022841961871441774, 0.17709550738075616, 0.1796984475136965, 0.004496235822263156, 0.011994437049217672, 0.02649359760450226, 0.15013223444045232]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19889303229959948, 0.20108043803769868, 0.025561365803606066, 0.02163466411275596, 0.1787258064773041, 0.1784334021389895, 0.005098899962908465, 0.011548522371890444, 0.02585039495645757, 0.15317347383878996]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20007272562465417, 0.2006455800027985, 0.026182106114962925, 0.022597247031180785, 0.17742596304516797, 0.17944202744286722, 0.004618393639461116, 0.011904051774957788, 0.026363222780115082, 0.1507486825438347]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19949538007487816, 0.20085840086556153, 0.025878313893105753, 0.02212615598366877, 0.17806211042772138, 0.1789484031099854, 0.0048535549153534575, 0.011730054589150258, 0.026112243262386405, 0.15193538287818897]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 25 total loss: 0.8038742330920109\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20247542499772708, 0.20119529602328587, 0.02403086683565196, 0.021066547076435953, 0.17848220353808691, 0.18313327483258426, 0.0027024455259279704, 0.010422510197313708, 0.02408023354672727, 0.15241119742625905]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2014517810394386, 0.20156109550195944, 0.02350694783677927, 0.020251483735811197, 0.17964324002765797, 0.18220285275376324, 0.003114265328049425, 0.01012334418740726, 0.023648159989852497, 0.15449682959928104]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1999024165065446, 0.2021147613872694, 0.022713955792631538, 0.019017822146934624, 0.18140055881391334, 0.18079458676647892, 0.0037375865426026076, 0.009670533225701928, 0.022994183146436732, 0.1576535956714863]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2011426744080869, 0.20167155485033686, 0.023348741621101062, 0.020005361554833342, 0.17999383466094016, 0.18192189604787845, 0.00323862129256908, 0.010033005943540004, 0.023517688061033607, 0.1551266215596805]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20052228761510016, 0.20189325025879698, 0.0230312167386811, 0.01951138654733493, 0.18069748918698253, 0.1813580070463071, 0.003488207649483394, 0.009851694228706243, 0.023255826770187817, 0.1563906339584197]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 26 total loss: 0.8027008268183522\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20344057533857085, 0.20207601410867324, 0.02140919876512549, 0.01868270979628508, 0.18075779630850147, 0.18552736643024453, 0.0014709569438785383, 0.008727266391883324, 0.021445389164367126, 0.15646272675247044]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20238455951721102, 0.20244146618874798, 0.020883246837251648, 0.017861989722268157, 0.18198959750113214, 0.18451210723095224, 0.0018902967386468057, 0.008427786085054912, 0.02101236574503818, 0.15859658443369676]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20076136850261897, 0.2030031988073726, 0.020074811559896676, 0.016600469371252705, 0.18388298639474498, 0.18295156279928723, 0.002534859607082147, 0.007967457997862784, 0.020346769918587748, 0.16187651504129416]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2020662414567352, 0.20255162552061906, 0.020724707548163395, 0.017614597574470363, 0.18236090308064998, 0.18420607456301094, 0.0020166996082355295, 0.008337512825419868, 0.02088183817888495, 0.15923979964381058]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2013993418785938, 0.20278241736398275, 0.020392556162050535, 0.017096292961922662, 0.18313881537997695, 0.1835649137792261, 0.002281522849111588, 0.008148383755337971, 0.020608373397548632, 0.16058738247224907]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 27 total loss: 0.8017070633334488\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2042612397166308, 0.2028133228272432, 0.019000111214686685, 0.016502330045593008, 0.18282689569790964, 0.18772611423886146, 0.00039726816701002445, 0.00720831684862136, 0.01902358897787669, 0.16024081226556702]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20317247474278394, 0.20317775608683666, 0.01847220874721362, 0.015676212182701914, 0.18413182976198175, 0.1866238541227502, 0.0008237210526190091, 0.006908508606331766, 0.01858964463242977, 0.16242379006435162]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20147099751343292, 0.20374727743231613, 0.017647224430763796, 0.01438518908200204, 0.18617112717616832, 0.18490128723877108, 0.0014901641249846947, 0.006439980586344964, 0.017911494214002222, 0.1658352582012139]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20284496839231447, 0.20328737956821794, 0.018313412850322244, 0.015427711493542946, 0.1845243609355531, 0.1862922883610228, 0.0009520003705323075, 0.006818324677172103, 0.01845911184317036, 0.1630804415081519]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20212771794089546, 0.2035274588564336, 0.017965644238918083, 0.014883486225172776, 0.18538401804154955, 0.1855661476558635, 0.0012329365983310455, 0.006620818693523915, 0.018173240433693637, 0.16451853131561828]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 28 total loss: 0.800867486887316\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2049425492703386, 0.20341251648744538, 0.016803145444329613, 0.014524314093667513, 0.18469056949717955, 0.1897308896821066, -0.0005228714293156713, 0.005862688020387568, 0.01681440712452604, 0.16374179180933485]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2038206461102203, 0.20377518406910314, 0.01627336878095554, 0.013693058584467744, 0.18607099434731955, 0.18853956403379588, -8.972488906031393e-05, 0.00556253521800697, 0.016379562940519066, 0.1659748108046722]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20203591424232784, 0.2043521183477871, 0.015430596135685733, 0.012370691155291788, 0.1882669844370665, 0.18664439435680383, 0.0005993278396792964, 0.005085049913848099, 0.01568780958750854, 0.16952711398400133]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2034840082190191, 0.2038840059837178, 0.016114404170545625, 0.01344363233128125, 0.18648520417133313, 0.18818209525374632, 4.024491856308788e-05, 0.005472471467387994, 0.016249083738472985, 0.16664484974593277]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20271212383707457, 0.2041335261313299, 0.01574991073928191, 0.012871717421184217, 0.18743495493427667, 0.18736244727125556, 0.0003382555324926829, 0.005265962324183485, 0.015949905122932765, 0.16818119668598813]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 29 total loss: 0.8001575152002989\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2054928662249502, 0.2038820608729832, 0.014814071636969059, 0.01274388874663877, 0.1863535231344835, 0.19154677779809967, -0.0012970198185438897, 0.0046839551679953816, 0.014813639528409422, 0.16696623670801491]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20433738615186295, 0.2042421385610217, 0.014282483393775794, 0.011907741064484062, 0.18781181943041503, 0.19026438729157474, -0.0008575944174594625, 0.004383436085142067, 0.014377903603290783, 0.16925029883589252]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2024637845704783, 0.2048260016162517, 0.013420517362261925, 0.010551934369029391, 0.1901764350649231, 0.18818500147009704, -0.00014506968808649376, 0.0038961468259116243, 0.013671361329318803, 0.1729538870798146]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20399170246978957, 0.2043498626005206, 0.014123448733175418, 0.01165759169691252, 0.18824809630344191, 0.189880735956968, -0.0007261320113293935, 0.004293530126992169, 0.014247544973561947, 0.16993361914996705]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20316035819822334, 0.20460893112990672, 0.013740981868446266, 0.011056000547109764, 0.18929731065175154, 0.18895808222511962, -0.0004099744258539533, 0.004077312795473041, 0.01393404189055754, 0.17157695511926607]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 30 total loss: 0.7995540907320804\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20592316797498972, 0.20423296912260167, 0.013025244249712215, 0.011152992685652114, 0.18782369062916324, 0.19318218281870178, -0.0019354683285772586, 0.0036627421629429535, 0.013013657495966191, 0.1699188211888474]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20473358280388343, 0.20458955205596857, 0.012491886370108795, 0.010312168822538104, 0.18936230486719818, 0.1918067484868949, -0.001490158100222842, 0.0033618279668212727, 0.012577020410014919, 0.17225506631679469]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2027646849139766, 0.2051797371071406, 0.011609118806068191, 0.008920510309908154, 0.19190888530568018, 0.1895302492337297, -0.0007531193490205814, 0.0028637809667599137, 0.011854336689617667, 0.17612181601613955]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20437896417395765, 0.20469585041472158, 0.01233289091091927, 0.010061516903206329, 0.18982097002739762, 0.1913967277081014, -0.0013574098894124037, 0.003272124612622047, 0.012446857686944965, 0.17295150745154175]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2034826695592037, 0.20496451832573176, 0.011931031668860531, 0.009427996984859695, 0.1909802410819046, 0.19036040478269062, -0.0010218902736141575, 0.003045400389726744, 0.012117872862448547, 0.1747117546181878]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 31 total loss: 0.7990361462142208\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20624631741167895, 0.2044780679158826, 0.011426164212073733, 0.00974086146699162, 0.1891116329926477, 0.1946482441493197, -0.0024505373924503288, 0.00278737702349318, 0.011403968902634114, 0.17260790331772874]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20502196906063527, 0.2048301653165111, 0.010891051798556829, 0.008895534568024475, 0.19073313008815238, 0.19317775319095026, -0.001999701378570863, 0.0024860297490285252, 0.010966399742767835, 0.17499766786394416]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20295033923373876, 0.20542592344081695, 0.009985627426776352, 0.0074652190733489115, 0.1934767461059386, 0.19068964355536908, -0.0012368749063534827, 0.0019761421818971763, 0.010226021138805736, 0.1790412127496618]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20465854895259603, 0.20493467746394667, 0.010732215785123508, 0.00864461840295657, 0.1912144348157908, 0.19274127121871928, -0.0018658809076792441, 0.0023965816283609783, 0.010836517237337357, 0.17570701540284805]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20369099793110534, 0.20521292523497678, 0.010309338944664428, 0.007976592098276185, 0.1924958357910626, 0.19157920404425022, -0.0015096041622725664, 0.0021584395481407752, 0.010490724728824112, 0.1775955458409721]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 32 total loss: 0.7985848522486602\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20647630785719231, 0.20463124162626825, 0.010004163068277023, 0.008494721124450565, 0.1902298289511898, 0.19595814886463217, -0.002855829546844299, 0.002044616803147334, 0.009971902028145529, 0.17504489922354127]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20521636767687895, 0.20497776886909408, 0.009467278879152776, 0.007645009649371122, 0.19193695401272942, 0.19439049266483271, -0.0023997799015815086, 0.0017427872141052565, 0.009533344798129203, 0.17748977613728809]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20303332177571212, 0.20557818219737237, 0.008537041994273532, 0.006172749948608863, 0.19489481854201685, 0.19167428002642017, -0.0016096016658403056, 0.0012198196498473563, 0.008773474942104722, 0.18172591258948426]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20484430184259958, 0.20508009987632522, 0.00930873463486317, 0.007394086142198327, 0.19244107549418174, 0.19392755694696673, -0.0022651064508980873, 0.00165365561912017, 0.00940383693401404, 0.17821175896062913]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2037981835753836, 0.20536781867795748, 0.008862963981305167, 0.006688577491999948, 0.1938584877961328, 0.1926259445268305, -0.0018864520733957492, 0.001403048922376316, 0.009039706369160091, 0.18024172073224975]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 33 total loss: 0.7981836504598488\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.206627560661328, 0.20470673131788522, 0.008745122903973506, 0.007400505695206477, 0.19119194182973034, 0.1971264263151982, -0.0031655187549760816, 0.0014203606299819872, 0.008703325753588944, 0.17724354364808362]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20533098810362996, 0.20504649858781995, 0.008206412256979543, 0.006546462865345764, 0.19298769154032186, 0.195459331383013, -0.002704511235778819, 0.0011179858242499295, 0.008263695914860448, 0.17974544475955834]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20303370079500538, 0.2056485034910342, 0.00725191640172451, 0.005033256572020977, 0.19616942864798723, 0.19250554680131493, -0.0018876909839969298, 0.0005822334673672743, 0.00748475296792907, 0.18417835183961354]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20495045698341477, 0.20514621689442233, 0.00804830605246721, 0.006295809808693322, 0.19351472617863852, 0.1949700556396055, -0.0025692101246560903, 0.0010292418331273884, 0.008134668939842243, 0.18047972779444504]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20381721609972045, 0.20544318304486658, 0.007577457794858831, 0.005549352354015705, 0.19508426193415185, 0.19351296777904953, -0.0021662765862721285, 0.0007649577481217207, 0.007750420095470908, 0.18266645973601647]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 34 total loss: 0.7978215484322585\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20671395626301922, 0.2047183296014239, 0.007634213937730337, 0.006443554921026058, 0.1920126676177614, 0.19816790047065172, -0.0033935632115735755, 0.0009003775957042563, 0.0075833974803652775, 0.17921916532389162]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20537953108245338, 0.20505009420137543, 0.007093586310837422, 0.00558516647016355, 0.19390008317186674, 0.19639892614082408, -0.0029277912299535956, 0.0005973814435300788, 0.007142584536974208, 0.18178043787192869]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20296882148553455, 0.2056494444809333, 0.006116913937225881, 0.004034442378235713, 0.19730979909743593, 0.19320318054509852, -0.002086349534742851, 5.0002884946476524e-05, 0.0063462326631072066, 0.1864075120622252]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20499075703758007, 0.20514675114951117, 0.006936078799484623, 0.005335081898188619, 0.19444996651490684, 0.1958835496959697, -0.0027920923088598794, 0.0005091059512976375, 0.007014157230947204, 0.18252664403097404]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20376039830871165, 0.20545264276293745, 0.006437612546372501, 0.004543635709477834, 0.19619019012265598, 0.19425253055788308, -0.002362644010375668, 0.00022973925013649102, 0.006607721515705826, 0.18488817323649478]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 35 total loss: 0.7974889954506227\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20674848869235282, 0.20467897808687036, 0.006656498449322343, 0.005609210745083093, 0.19270695294616383, 0.19909722764482635, -0.0035532616389317966, 0.0004708215688222083, 0.006597164117665532, 0.18098791938782532]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20537481775446692, 0.2050014712294984, 0.006113825328886045, 0.0047463895182724685, 0.1946890148265704, 0.19722373686623582, -0.003082852337636783, 0.00016711281861650365, 0.00615503036405867, 0.18361145363103154]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20284120567289657, 0.2055962807285212, 0.00511291373036526, 0.0031549936284772126, 0.19834474909896238, 0.193768252193427, -0.002215224832261732, -0.00039305056373187014, 0.005339554554741176, 0.1884503257886031]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20497807924691516, 0.20509461249395494, 0.0059570925059425255, 0.004497192715480954, 0.195261466532885, 0.19668264225987114, -0.0029469904809235194, 7.939679219139209e-05, 0.006027334945376969, 0.18436917298830524]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2036388855416149, 0.2054090115066288, 0.005428039727085279, 0.0036560271030507997, 0.19719378141307123, 0.19485617349764495, -0.0024883877997176835, -0.00021668929021933928, 0.005596298134885535, 0.18692686016595567]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 36 total loss: 0.7971716520658263\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20674368024378548, 0.2046008744098766, 0.005797289592991938, 0.004883208499393011, 0.1932885343899478, 0.1999292380524178, -0.0036572461065420337, 0.00011843746329604185, 0.005729903575578081, 0.18256607987925544]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2053290586509498, 0.2049126979427244, 0.005252389755513574, 0.004015774737173406, 0.19536860256546149, 0.19794821948953262, -0.0031822538254124176, -0.00018609844469512436, 0.005286271103900301, 0.18525533802485195]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20266140953597797, 0.20550072499931812, 0.004224834700112729, 0.0023799953034356917, 0.19929113001421012, 0.19421247669952604, -0.002286528251314596, -0.000760382726473489, 0.004449682876746394, 0.19032665684846112]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2049246881061499, 0.20500183291174914, 0.005096629766228498, 0.003767818206053677, 0.1959631914686801, 0.19738194398547584, -0.0030464769586737105, -0.0002731502411961808, 0.005159458460030156, 0.1860240642955027]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20346260657697934, 0.20532411798787586, 0.0045334487772912746, 0.002871282420128119, 0.19811304502261726, 0.1953344631153921, -0.0025555488940553267, -0.0005879031958365282, 0.004700942312768362, 0.18880354587683945]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 37 total loss: 0.796860226114095\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2067109304318237, 0.20449503731110402, 0.005042559754906374, 0.0042520259040280586, 0.1937702825007627, 0.2006781453866272, -0.0037170509539669765, -0.0001690711640259267, 0.0049675470235152255, 0.18396959380522548]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2052532853552226, 0.20479463695230596, 0.004495191692726882, 0.003379695213033356, 0.19595219508289716, 0.19858610912326397, -0.0032374519267455984, -0.0004745769753383648, 0.004522191513349418, 0.18672872396928447]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20243843538549158, 0.205373192085175, 0.0034381723963351667, 0.0016951424652083306, 0.2001656738400843, 0.19454619000499973, -0.0023113010214751034, -0.0010645374791193867, 0.0036621680656436385, 0.19205686425765675]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20484168847292075, 0.20487923524048804, 0.004340630756404824, 0.0031333742131457202, 0.19656830419661628, 0.19799537848692098, -0.0031020270091657765, -0.0005608429954277811, 0.004396435976255543, 0.1875078226618413]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2032396605657475, 0.20520851086038308, 0.0037390447289257023, 0.0021746373205435783, 0.19896633983897088, 0.19569612160297398, -0.002574922683019781, -0.0008966098040856256, 0.003906967060020654, 0.1905402505095402]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 38 total loss: 0.7965461311038893\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20666047196471668, 0.20437125846039433, 0.004379167163644611, 0.003703089283602195, 0.1941639750883261, 0.2013573853310211, -0.003743022533858643, -0.00040290377713197745, 0.00429690613837665, 0.18521367288090876]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20515729121451953, 0.20465688863438902, 0.0038290187678488388, 0.0028254567234486574, 0.19645216946608784, 0.1991502349547176, -0.003258708213660502, -0.0007095569323520996, 0.0038495482764533766, 0.18804765710854782]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2021795538350507, 0.2052227099075102, 0.0027391981044316434, 0.0010869038052681648, 0.20098498558235164, 0.194777963571675, -0.002299302064748048, -0.0013170238405806748, 0.002963351305614431, 0.19366165979342687]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20473897416167358, 0.2047363760630123, 0.00367591911198443, 0.0025812221788026626, 0.19708894633295382, 0.19853601165490353, -0.003123929386131091, -0.0007948948028116246, 0.003725053985036565, 0.18883632070057568]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20297600223508017, 0.20507137102491194, 0.003030689869179717, 0.001551910457499667, 0.19977260393704013, 0.1959474046955058, -0.002555912166615412, -0.001154546098095609, 0.0032003803211354503, 0.19216009572435827]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 39 total loss: 0.7962209641067389\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2066014308773338, 0.20423815282228314, 0.003794974309058105, 0.0032248746183872715, 0.19448016659366757, 0.20197957447160775, -0.0037443278991879485, -0.000593125277160795, 0.003705791751089218, 0.18631248773292172]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20504966803264457, 0.20450783001551548, 0.0032416483145415913, 0.0023413924865778937, 0.19687983384013844, 0.19965244330939333, -0.0032550954720935842, -0.0009011468514999817, 0.0032560850762506336, 0.1892273412485314]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2018901679088943, 0.20505691206649146, 0.002115037019437816, 0.0005425596853311012, 0.201765727962512, 0.19491423784187387, -0.002258983263815442, -0.0015283008045496587, 0.002340450126189401, 0.19516219145763528]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20462527578166947, 0.20458158414067976, 0.003090318963449335, 0.002099768599333742, 0.1975361198105149, 0.19901599526217623, -0.0031212950968009506, -0.0009853877970349798, 0.0031330946150042874, 0.190024525721008]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20267508570649534, 0.20492050305959997, 0.002394922198064013, 0.0009894455297067728, 0.20055192036522243, 0.1960913549979043, -0.0025064484228790058, -0.001372496316401628, 0.0025679222389473956, 0.19368779064334046]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 40 total loss: 0.7958758907525065\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20654197404994518, 0.20410328851969806, 0.0032788749446158428, 0.0028069212612102847, 0.19472813136840048, 0.20255657926335532, -0.0037290426817274845, -0.0007487099286207543, 0.003183040516409744, 0.18727894268671322]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20493791776798, 0.20435472835142465, 0.002721867860737802, 0.0019168669671903163, 0.1972454206974246, 0.20010361167871574, -0.0032345808058857756, -0.0010583772719378983, 0.0027305538323118, 0.19028199092203876]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2015736678786908, 0.2048820829309115, 0.001553635148869185, 5.012133377046858e-05, 0.20252502992416763, 0.1949589069586645, -0.002197526601640355, -0.0017078546856573744, 0.001781535837122495, 0.1965804012751012]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20450828899234916, 0.2044220737359128, 0.0025726796594540513, 0.0016784757455828143, 0.19791964886790533, 0.19944661137772884, -0.0031021446484376125, -0.001141318252910985, 0.002609360266809136, 0.19108632425560668]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.2023373508557842, 0.20476237371533604, 0.001818823367550026, 0.0004738716227561462, 0.20132656137252816, 0.19612675225736959, -0.0024329373672398106, -0.0015604236501557095, 0.001996962429002262, 0.19515066539706874]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 41 total loss: 0.7955008566939079\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20648953603997666, 0.20397338445174557, 0.0028207445073976252, 0.002439774017568067, 0.19491585844350878, 0.2030996921035932, -0.0037043039597327914, -0.0008776515239878154, 0.002718464229326486, 0.1881245016906042]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20482862378212424, 0.2042039147248896, 0.002259415340469143, 0.0015422022736298014, 0.19755815870570184, 0.20051373895005017, -0.0032041707872857337, -0.0011893167131285902, 0.002262655545571662, 0.19122477817797795]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2012312089665036, 0.20470322648331415, 0.001043617304178193, -0.00040187266137072143, 0.2032811883634047, 0.1949127530201339, -0.002120918811849778, -0.0018643607822102142, 0.001275407179936524, 0.19793975093795968]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20439487154699248, 0.20426411839956837, 0.002112822539044035, 0.0013077987111997495, 0.1982482033719369, 0.19983840950083187, -0.003073559504006413, -0.0012707090153188183, 0.0021436197359216286, 0.19203442471383028]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20195935659727984, 0.20460216149844307, 0.0012897052603915362, -8.375210972323606e-06, 0.20212279804710762, 0.19604644063857884, -0.0023401783078696474, -0.0017277260695723968, 0.0014752347214542622, 0.1965805828251591]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 42 total loss: 0.7950834689180356\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20645113228634743, 0.2038545763057511, 0.002411322451945583, 0.002114863116665675, 0.1950500772223964, 0.20361992735479523, -0.003676523836246721, -0.0009871325516626504, 0.002302729932964813, 0.18885902771704305]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20472767505973677, 0.2040610130831652, 0.0018448448454729228, 0.0012085325717891614, 0.1978264209366744, 0.2008921030605585, -0.003170112482741817, -0.0013012503475734567, 0.0018429066635339414, 0.19206786660938463]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20086130996340582, 0.20452412869663603, 0.0005740217512287031, -0.0008247089443582322, 0.20405480784791305, 0.19477256352263697, -0.002034040666542731, -0.002005935130864725, 0.0008113495050748694, 0.1992665034548702]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 1\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2042913097178791, 0.2041132811949334, 0.0017014173263059545, 0.000979057054819792, 0.19852936856733755, 0.20020144015213043, -0.0030418932499225925, -0.0013807824167654224, 0.001726483154402875, 0.19288031849887907]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20153219156312796, 0.20444377008179215, 0.0007945316640767024, -0.0004719061730242429, 0.20297407437588114, 0.19583441008199576, -0.002231168888648353, -0.001883660062955857, 0.0009903426160277507, 0.19801741474172677]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 43 total loss: 0.7946072378674771\n",
            "Accuracy:0.2\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20643379186552663, 0.20375277221978275, 0.00204202308677119, 0.0018243204468972503, 0.1951362965187755, 0.20412848005035975, -0.0036516758455374574, -0.001083758686464361, 0.0019271667585146221, 0.1894905835853742]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20464054985671837, 0.20393123610997116, 0.0014693091431955151, 0.0009075766759182496, 0.19805796773760695, 0.2012474865952608, -0.0031381586635840816, -0.0014009308467160997, 0.0014624224438898289, 0.19282254094773957]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2004590953271575, 0.20434737550349724, 0.00013386345223790561, -0.0012300725508887593, 0.204870676391465, 0.19452962973417556, -0.0019407470839204613, -0.002140508081479081, 0.00037873869683833177, 0.20059194861091664]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20420367489608202, 0.20397471401458073, 0.001329782866024616, 0.0006842368272571193, 0.19876975398422025, 0.20054561038663551, -0.0030130540778393854, -0.0014782012733201425, 0.0013492000493884977, 0.19363428232697058]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20103838067826593, 0.20428972488145072, 0.00031887183161965343, -0.000933929456627381, 0.2039268655006257, 0.19546030016068822, -0.002106632658531625, -0.002038049414265877, 0.0005288687808708553, 0.1995155996959041]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 1\n",
            "Iteration 44 total loss: 0.7940485299991361\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20644519316121415, 0.2036741578690892, 0.0017046490620426897, 0.0015607098757251753, 0.19517884360869198, 0.20463744986031174, -0.003635696331897476, -0.0011738896029937528, 0.0015834723585290659, 0.19002511013928733]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20457268579961543, 0.20381978767088785, 0.0011242215624513152, 0.0006312889541367684, 0.19826034572993473, 0.20158848394305706, -0.0031139311842567647, -0.0014949392161323198, 0.0011125805657018321, 0.19349947617460425]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20001482693334932, 0.20417426429241287, -0.0002885935107981342, -0.0016310089010439874, 0.20576101144306314, 0.19416701440766482, -0.001843905787799866, -0.002276404141592257, -3.3614304879139865e-05, 0.20195640956962316]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20413832837856075, 0.20385356878514946, 0.0009895823097562113, 0.0004156952091643903, 0.1989751484280746, 0.20088122852721096, -0.0029928995832210576, -0.0015694117041199843, 0.0010033498364011857, 0.19430540981302358]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.20044543627559275, 0.20414077467605704, -0.00015511606288806366, -0.0014172755187780142, 0.20505237679159935, 0.19486816690248368, -0.001963893004746915, -0.0022025742781822365, 7.467387028938011e-05, 0.20115743034857317]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 4\n",
            "Iteration 45 total loss: 0.7933707291656059\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20649469661842518, 0.20362599468171522, 0.001390933410144099, 0.001316605736403164, 0.1951808986953592, 0.20516106671075263, -0.0036351074562245857, -0.0012641497526738369, 0.0012632420747323335, 0.19046581928136652]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2045300000628851, 0.2037324709250447, 0.0008006957766990031, 0.00037128076866221394, 0.19844161057954657, 0.2019239200461227, -0.0031034700508936275, -0.0015902554816913017, 0.0007844653268760783, 0.19410928204674824]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19951092521964328, 0.20400447844335154, -0.0007071436141756079, -0.002043675755233625, 0.2067715264349172, 0.19365420463255742, -0.0017453326228521878, -0.0024233353057146806, -0.00043863262375579246, 0.20341698519126244]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20410271189529136, 0.20375562770148248, 0.000672329105454777, 0.00016568862665548186, 0.19915076009279697, 0.20121989556831635, -0.0029878479350469596, -0.0016611779450105405, 0.0006803395071910132, 0.19490167338286912]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19969106354687582, 0.20399471589131302, -0.0006530261375308337, -0.0019570011703467886, 0.20647255956252736, 0.19395101086633873, -0.0017940771847645765, -0.0023934354515308294, -0.00039473472907405335, 0.20308292480619214]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 4\n",
            "Iteration 46 total loss: 0.7925116944377706\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20659525241139734, 0.2036180693488017, 0.0010917134509603338, 0.0010838425971256178, 0.1951445484801602, 0.20571799670555457, -0.0036581323756576167, -0.0013623363394239419, 0.0009571176118006165, 0.1908119281092811]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20451969466609718, 0.2036767482398094, 0.0004884930993675552, 0.00011772305959621628, 0.1986118476766334, 0.20226341649079688, -0.003114188002476384, -0.0016953003608229165, 0.0004678277359122138, 0.1946637373950866]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1989154046112412, 0.2038351892786333, -0.0011402844304183497, -0.0024909319528880762, 0.20797403017818225, 0.19293557698110006, -0.001645463729245681, -0.0025943488011645204, -0.0008533219124616611, 0.20506414977702145]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2041067595365835, 0.2036884224876172, 0.00036848156291463465, -7.448777975948392e-05, 0.19930167172320604, 0.20157612290350624, -0.003005969505209121, -0.0017615440206830695, 0.00037048282766902023, 0.1954300602641552]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.1986441350929868, 0.20384285844347896, -0.001219123621738534, -0.0026172010398914074, 0.2084271963619711, 0.1924840731321947, -0.0015743717404035624, -0.002637866255634513, -0.0009172707133174988, 0.20556757034035403]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 4\n",
            "Iteration 47 total loss: 0.7913525264979341\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20676752175931026, 0.20366580686505453, 0.0007951642434909411, 0.0008519182751727062, 0.1950710025401362, 0.20633633893675535, -0.0037170722286114922, -0.0014793504899609556, 0.0006529651189639263, 0.19105570497968846]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2045516150415872, 0.20366393299934007, 0.0001736682095572411, -0.00014314855140361253, 0.1987870398834148, 0.20261801543480887, -0.0031568404562452826, -0.0018222158246190864, 0.0001487736572774047, 0.19517915960628232]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19816530277838137, 0.20365853245991478, -0.0016175027415028826, -0.003010962176610463, 0.20949677539082645, 0.19190169114682296, -0.0015422350175397326, -0.002810364411309289, -0.0013043218584403693, 0.20706308442945726]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2041658498441924, 0.2036636067797518, 6.547252681799695e-05, -0.00031637883574052455, 0.1994339614653528, 0.20197069585757507, -0.0030593102134218115, -0.0018819049407927761, 6.099942148189497e-05, 0.1958970080947833]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19697724295592947, 0.2036575277855978, -0.0019507182427801774, -0.0035444679004095095, 0.21148913122014423, 0.189908109592054, -0.0012418663897965847, -0.002994191882637777, -0.0015746444373026002, 0.209273877299201]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 4\n",
            "Iteration 48 total loss: 0.789621227969094\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20705083338783545, 0.20379857862330003, 0.0004820568191104511, 0.0006036955800086479, 0.19496175516127645, 0.2070668190969634, -0.0038346336034661855, -0.0016343639592360472, 0.00033098891151418943, 0.19117426998269382]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20464044726566033, 0.20371478187738168, -0.0001681125550597503, -0.0004362854168284085, 0.1990017804633999, 0.20299945614434314, -0.003250547531264161, -0.0019931955069839484, -0.000196743039033228, 0.19568841829838418]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.197114259914427, 0.2034531349970738, -0.0021982007948740546, -0.0036835210990747713, 0.21161635165088602, 0.19029952590276736, -0.0014267977310986287, -0.0031136107927502163, -0.001844532782971736, 0.20978339073561533]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2043083401489115, 0.20370323621860784, -0.0002576940018941876, -0.0005795757748153345, 0.19955842204971558, 0.20243904792985054, -0.0031700711546423315, -0.002042635930501472, -0.0002694548485230759, 0.1963103853632908]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19414676963937416, 0.20334997060100218, -0.002998641552990539, -0.0049638692831113105, 0.2165901339361079, 0.18529208751106307, -0.0007077138784712083, -0.00355537782688962, -0.002494237581998282, 0.21534087843591357]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 4\n",
            "Iteration 49 total loss: 0.78684211257498\n",
            "Accuracy:0.6\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20752984275980166, 0.20407029728023524, 0.00012437638218729206, 0.00031674198951213867, 0.1947925605209993, 0.20802275481569374, -0.004054001029089462, -0.0018582728884942476, -3.850724347813447e-05, 0.1910942074126325]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2049320009640603, 0.2038730391280965, -0.0005467447587265129, -0.0007541964149053238, 0.19911499420894813, 0.20362946817234012, -0.003457584344708087, -0.0022297530161510567, -0.0005840022726335613, 0.1960227783336795]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.19534067867349816, 0.2031447551676548, -0.003024547359741797, -0.004708138262690979, 0.2150735697652667, 0.18740930103964445, -0.0012555931962294454, -0.0036012705715066087, -0.0025979888984189355, 0.21421923364252365]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 4\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20468093754568567, 0.20385397549379072, -0.0006116039691901896, -0.0008576951949782758, 0.1995327274901561, 0.2032048874436798, -0.003399944802607433, -0.002265653997827718, -0.0006367205894112255, 0.1964990905807026]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.19046840832937179, 0.20277479613228236, -0.004283239724130934, -0.006716690683697894, 0.22318032418994718, 0.17916966140464122, -0.00013700955929773278, -0.004297984132887296, -0.003621068617045099, 0.22346280266081647]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 50 total loss: 0.7828330261575477\n",
            "Accuracy:0.8\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20826517366329939, 0.20453933536338437, -0.00031449448109446094, -4.4774918285099275e-05, 0.1945627162551605, 0.20927138476553128, -0.004411516788669557, -0.002186859113882548, -0.0004923080719303178, 0.1908113433264865]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20539116534420201, 0.20417815118906027, -0.0010234151723518983, -0.0011703107794045564, 0.19928751087743293, 0.20442321364215876, -0.0037975095367990875, -0.0025824493167572655, -0.0010702632881779207, 0.19636390704063683]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.1914501143423757, 0.2024261426921307, -0.00446220115198811, -0.006629986292514717, 0.22220623465584605, 0.18090602322645913, -0.0008191234420414459, -0.004501352319735106, -0.003873770533769296, 0.223297918823237]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20529625549784672, 0.20416622361937883, -0.0010468262228482469, -0.0012074799256928117, 0.19944354018628369, 0.2042631100080232, -0.003777232861345918, -0.0025955130943131634, -0.001089349398823388, 0.19654727219149112]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.17958999941488582, 0.20093565089744458, -0.0073876905519037785, -0.011274713511704034, 0.2417039538714037, 0.1608991685735838, 0.001714688490619589, -0.006133826811582341, -0.006258807223500126, 0.246211576850753]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 51 total loss: 0.772852382991185\n",
            "Accuracy:0.6\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.20964293545264687, 0.20550601828458392, -0.0010066539522312018, -0.0006385427987077495, 0.19428533193826922, 0.21127190769729057, -0.005127810134061014, -0.0028044866880732656, -0.0012071213543258048, 0.19007842155460858]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20621111697627098, 0.20483620034733327, -0.0018193538054179044, -0.0019081411254530888, 0.1997794115071008, 0.20555514500412503, -0.004486210925907734, -0.0032717796826804563, -0.0018760932605741967, 0.19697970496520337]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.16911485949721675, 0.1975958002983832, -0.01060423657661882, -0.015631870031318152, 0.2591676896747205, 0.14375977258796116, 0.002449158642107987, -0.008322985440046962, -0.009107348133544916, 0.2715791594811392]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20657131366759007, 0.20490650307646788, -0.0017340544808270239, -0.0017748866658288537, 0.19920276408353807, 0.20615516479576304, -0.004553551874597366, -0.003222733559847103, -0.0018058793291338123, 0.19625536028687507]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 0\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [-0.10833091315363949, 0.1434442895424397, -0.07630705281028417, -0.11827269766975353, 0.703337205478915, -0.3184125868725731, 0.054319322889911634, -0.04610134313454758, -0.06319046141254467, 0.8295142371420763]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 52 total loss: 0.7537157547614375\n",
            "Accuracy:0.6\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.21111855165568258, 0.20494790491939527, 0.0030573622053488314, 0.0038009616242749, 0.1879579740629653, 0.21478112074970787, -0.001915865840998651, 0.0011524303953071616, 0.00274862560015609, 0.17235093462816045]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2026294996277624, 0.19647501517056903, 0.00873203989977765, 0.009490621754039417, 0.18109007112098435, 0.206250835916536, 0.0038967714262090965, 0.006911426608373699, 0.008423919584832717, 0.17609979889091568]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.08530672488315903, 0.07937561088279228, 0.08715881013301471, 0.08812445643690342, 0.08617235508158394, 0.08835820400687852, 0.08423020919167112, 0.08650351925174508, 0.0868592072451845, 0.22791090288706745]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20377379304247256, 0.1976171299686948, 0.00796711393454849, 0.008723676210883938, 0.18201583952050998, 0.20740068736379966, 0.0031132490110927233, 0.0061351348127434615, 0.00765891054591408, 0.17559446558934044]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.08530672488315903, 0.07937561088279228, 0.08715881013301471, 0.08812445643690342, 0.08617235508158394, 0.08835820400687852, 0.08423020919167112, 0.08650351925174508, 0.0868592072451845, 0.22791090288706745]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 53 total loss: 0.7900271791720387\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.21852551064627895, 0.21281849820745896, 0.0016274864964013738, 0.002333851389160912, 0.17951203430148888, 0.22323312733355657, -0.003113418516441782, -0.0001906643756091686, 0.0013337298768043371, 0.16391984464090106]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.20957389840314433, 0.2038520645035722, 0.006937965135168739, 0.0076591616002343365, 0.1746426224788235, 0.21405995186252946, 0.0023237723303170996, 0.0051982048612793305, 0.006644535603217297, 0.16910782322171353]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.08218543952986382, 0.0762526846260994, 0.08251023874329842, 0.08344250010789489, 0.10534707539071016, 0.0835184745856809, 0.07969925998057083, 0.08188603812654949, 0.08222146392492896, 0.24293682498440314]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.21069093532462896, 0.2049709509375738, 0.006275291133085151, 0.0069946368238522705, 0.17525025746614134, 0.21520463679861496, 0.0016452864039806577, 0.004525748800945204, 0.005981820785136907, 0.16846043552604087]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.08218543952986382, 0.0762526846260994, 0.08251023874329842, 0.08344250010789489, 0.10534707539071016, 0.0835184745856809, 0.07969925998057083, 0.08188603812654949, 0.08222146392492896, 0.24293682498440314]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 54 total loss: 0.7717801938488595\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.22604945453085185, 0.22076599610344688, 3.848265918448259e-05, 0.0007101828308601582, 0.1713460893283054, 0.23176134908955612, -0.004486406273465738, -0.0016990171447488274, -0.00024133567494978732, 0.15575520455095943]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2167119484352714, 0.2113859470810966, 0.004962213611434956, 0.005648689632740591, 0.1684043311701838, 0.22203826754942768, 0.0005523146735870592, 0.0032970159378217768, 0.004682398295661943, 0.16231687361277425]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.07880991112939441, 0.07285560964727711, 0.07767890289774446, 0.07858359776100202, 0.12495863602272209, 0.07844181475465972, 0.07496724698011137, 0.07708150758705774, 0.0773991321589883, 0.25922364106104273]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.21776833915496568, 0.21244715085821417, 0.004405171545707063, 0.005089975913975482, 0.16873714444880594, 0.22313828001535627, -1.7736686284626934e-05, 0.002731794032776781, 0.004125355888454345, 0.16157452482802892]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.07880991112939441, 0.07285560964727711, 0.07767890289774446, 0.07858359776100202, 0.12495863602272209, 0.07844181475465972, 0.07496724698011137, 0.07708150758705774, 0.0773991321589883, 0.25922364106104273]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 55 total loss: 0.7540437082069582\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.23369536597186308, 0.22879940647401856, -0.0016734572024231283, -0.0010344991277173412, 0.163355522053589, 0.24036789282422685, -0.005994456493152955, -0.0033348540560317755, -0.0019401144914339794, 0.14775919404706167]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2240507991121134, 0.21908828406581646, 0.002838792761695812, 0.003492532195743181, 0.16227297822900702, 0.2301909004773674, -0.0013792430779755575, 0.0012435069028391373, 0.0025717920183512323, 0.1556296573150418]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.07507555081816299, 0.06908498241289061, 0.07253747063331482, 0.07341953101842784, 0.14555141494872886, 0.07299151725920178, 0.0699098645049715, 0.07196337131412933, 0.07226516470671122, 0.27720113238346084]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.22501791323901343, 0.2200620720861186, 0.002386324470702324, 0.003038581695995074, 0.16238153089300597, 0.2312114038562259, -0.001842036084378359, 0.0007844092963048054, 0.002119358167425704, 0.15484044237958663]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.07507555081816299, 0.06908498241289061, 0.07253747063331482, 0.07341953101842784, 0.14555141494872886, 0.07299151725920178, 0.0699098645049715, 0.07196337131412933, 0.07226516470671122, 0.27720113238346084]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 56 total loss: 0.7365813691220402\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2414556058619065, 0.23691451412731743, -0.003472653726333963, -0.0028650393354125647, 0.1554582183260088, 0.24904010522860495, -0.007598493591379797, -0.005061209368645138, -0.003726712712183576, 0.13985566519011738]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.231587382649786, 0.22695970808582797, 0.0006000538193727534, 0.001222482663834742, 0.15616894077325838, 0.23851059279639833, -0.0034350159954894583, -0.0009286435464349283, 0.00034529395971078923, 0.14896920479373527]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.07085354238303052, 0.06481560475889536, 0.06693640536245582, 0.06780013235733942, 0.16774520388107936, 0.06700565893085736, 0.0643798001539981, 0.06638268094236936, 0.06667022965447139, 0.29741074157550323]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2324419322516873, 0.2278217554227093, 0.0002473732468894403, 0.0008685192175145317, 0.1561073949841833, 0.23942240746290333, -0.003795556899927332, -0.0012865076119602038, -7.325919836779012e-06, 0.1481800078458372]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.07085354238303052, 0.06481560475889536, 0.06693640536245582, 0.06780013235733942, 0.16774520388107936, 0.06700565893085736, 0.0643798001539981, 0.06638268094236936, 0.06667022965447139, 0.29741074157550323]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 57 total loss: 0.7192123299410711\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.24930784263119282, 0.24509212217519408, -0.005320873233847049, -0.004743642366576706, 0.14758967215421936, 0.25774832251079227, -0.009257436300610235, -0.0068387697020772555, -0.005562717095394773, 0.13198547922710732]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.23930649148845634, 0.23498834384488446, -0.001719728646515676, -0.0011276628976735724, 0.15002885076032305, 0.24697576096156734, -0.005577743403817111, -0.0031840453522808828, -0.0019626287878100664, 0.14227236203286606]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.06597808918058898, 0.05988482730279362, 0.060689902701653066, 0.061539064345296046, 0.19230103225917197, 0.06028189775825686, 0.05819316931410706, 0.060154149996046784, 0.06042869670565292, 0.3205491704364327]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.24003094600228628, 0.23572021774008767, -0.0019805799469063312, -0.0013895887725655543, 0.14985216723766595, 0.24775607861349927, -0.005844284403182551, -0.0034487777383582358, -0.002223403575875595, 0.14152722484334906]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.06597808918058898, 0.05988482730279362, 0.060689902701653066, 0.061539064345296046, 0.19230103225917197, 0.06028189775825686, 0.05819316931410706, 0.060154149996046784, 0.06042869670565292, 0.3205491704364327]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 58 total loss: 0.7018153049331364\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.25721227805341823, 0.25329548876297064, -0.007174643240807358, -0.00662721077270916, 0.13970027482713857, 0.26644290995232545, -0.010925369040559674, -0.00862313538659368, -0.007404501315604012, 0.12410390816042104]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.24717738784070298, 0.24314672476215618, -0.004080426900035776, -0.0035182071151809106, 0.14380070350076343, 0.2555470391149066, -0.007764668447108791, -0.005481596656489421, -0.004311676957915215, 0.135484720858201]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.06023320912199762, 0.054081143482731506, 0.053563027123067354, 0.05440072603404417, 0.22018930910943504, 0.0525632912164632, 0.05111734860472682, 0.053043446005978614, 0.05330584522849751, 0.3475026540730582]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.24776032645083604, 0.2437362784349714, -0.0042601735773691194, -0.0036988128051885336, 0.14356250476203444, 0.2561799931051861, -0.007948277273108545, -0.005664092347243043, -0.0044913427733092245, 0.13482359602319063]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.06023320912199762, 0.054081143482731506, 0.053563027123067354, 0.05440072603404417, 0.22018930910943504, 0.0525632912164632, 0.05111734860472682, 0.053043446005978614, 0.05330584522849751, 0.3475026540730582]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 59 total loss: 0.6843660666698339\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2651079725544825, 0.26146681257145266, -0.008982527479114688, -0.008464633571570283, 0.13175384969040965, 0.27505056283038587, -0.012548731200180872, -0.010362063215874143, -0.00920049551792458, 0.11617925333793397]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.255147690849152, 0.25138595346384307, -0.006430585572771008, -0.005898102493292624, 0.13743913143171532, 0.26416116470522105, -0.009941904999287257, -0.007768950285787227, -0.006650234365775374, 0.1285558372669821]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.05334917283295689, 0.04714449840971848, 0.045272580060383226, 0.046100644466018734, 0.2526247721436659, 0.04353844852536025, 0.04287323413323235, 0.04476835355975788, 0.045018878645612846, 0.37930941722329325]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.25558414497338483, 0.25182769122422904, -0.006542410278414658, -0.006010566488511419, 0.13719000547957572, 0.26463833220537303, -0.010056134704851652, -0.007882579083287235, -0.00676198542168484, 0.12801350209418708]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.05334917283295689, 0.04714449840971848, 0.045272580060383226, 0.046100644466018734, 0.2526247721436659, 0.04353844852536025, 0.04287323413323235, 0.04476835355975788, 0.045018878645612846, 0.37930941722329325]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 60 total loss: 0.6670373757819503\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2729075153051756, 0.2695220305637083, -0.01068175189277804, -0.010193418950406433, 0.12372673276863572, 0.2834694016810495, -0.01406289391806412, -0.011992073015725288, -0.010887809404239038, 0.1081922668626438]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.26313146534002496, 0.25962406021906603, -0.008698236504479756, -0.00819579082595032, 0.1308995910319373, 0.2727192739007826, -0.012035083345694562, -0.009973263159897014, -0.008906172408550996, 0.12143415575276169]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.04504910194631518, 0.03882191893958542, 0.035549667838265575, 0.036366937895375644, 0.2909104223927832, 0.03290735789561737, 0.03320094999226446, 0.035061983813164416, 0.03529982908986735, 0.41683183019676134]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.26342318518832564, 0.2599194182028853, -0.008757425114423345, -0.008255400563574898, 0.13068555109434374, 0.2730400604819121, -0.01209559373533688, -0.010033504965840049, -0.008965304966775408, 0.12103901437848381]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.04504910194631518, 0.03882191893958542, 0.035549667838265575, 0.036366937895375644, 0.2909104223927832, 0.03290735789561737, 0.03320094999226446, 0.035061983813164416, 0.03529982908986735, 0.41683183019676134]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 61 total loss: 0.6504065856170939\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.28048855926599614, 0.27734240368275, -0.012193544561515973, -0.011735031441898367, 0.11560734611009908, 0.291561925481869, -0.015387485490085754, -0.013433777660575585, -0.012387572353369843, 0.10013717696673118]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2709857594011349, 0.2677227369366831, -0.010774988787476611, -0.010303311151250952, 0.12413137617205969, 0.28106407801474503, -0.013933247839032017, -0.011985203049038471, -0.01097093058931728, 0.1140637308914926]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.03527491586337475, 0.029113085516787252, 0.024411375532431185, 0.02520959054275489, 0.3355644637692683, 0.020671718184417754, 0.022138182508749278, 0.023945759242966262, 0.02416795794293392, 0.4595029508963163]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.271141047392775, 0.26787993468371424, -0.010798169816258942, -0.010326707305193661, 0.12399208253988539, 0.28123562636606225, -0.01395701195565144, -0.01200887462429686, -0.01099408034071073, 0.11383615305967475]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.03527491586337475, 0.029113085516787252, 0.024411375532431185, 0.02520959054275489, 0.3355644637692683, 0.020671718184417754, 0.022138182508749278, 0.023945759242966262, 0.02416795794293392, 0.4595029508963163]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 62 total loss: 0.6357483352841031\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.28768368417105317, 0.28476410613695824, -0.013419774803095712, -0.012991495152524042, 0.10739915411336755, 0.29914839569903845, -0.016423154249854358, -0.014588554237588503, -0.013601584083757742, 0.09202922240640271]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.27847454562585733, 0.2754509218124947, -0.012496758294410219, -0.01205698590257122, 0.11707674320817477, 0.28894548740242626, -0.015469591259146695, -0.013639642251738577, -0.012680255865223743, 0.10639553552413744]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.024854540157550817, 0.018965491855530307, 0.012923149423480797, 0.01367943232156973, 0.3835978935958427, 0.007957027376560214, 0.010791567668016512, 0.01249342783501206, 0.012693156281409136, 0.5020443134850278]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2785066700121789, 0.27548340914338393, -0.012499978067764764, -0.012060245766240246, 0.11704298471825564, 0.28898107837177855, -0.015472917588286502, -0.013642952356703219, -0.01268346974928856, 0.10634542128268651]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.024854540157550817, 0.018965491855530307, 0.012923149423480797, 0.01367943232156973, 0.3835978935958427, 0.007957027376560214, 0.010791567668016512, 0.01249342783501206, 0.012693156281409136, 0.5020443134850278]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 63 total loss: 0.6249206745533142\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.2942951073600528, 0.29159158119966083, -0.014261655366101498, -0.013863944135531152, 0.09913783285239472, 0.3060293273737172, -0.017071009663340353, -0.015357492728176023, -0.014431071943880993, 0.08393132505120424]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.28527321613268275, 0.28248676444885973, -0.01366667232810396, -0.013260018013499133, 0.10970723108125356, 0.2960303866615967, -0.0164456834959653, -0.014738972548628979, -0.01383721395004939, 0.09845096201185397]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.01633859573696184, 0.01108020733798894, 0.004069247273800202, 0.004742487035886792, 0.4247716703272073, -0.0020292171402693814, 0.0021947380307685204, 0.0036985684836702694, 0.003865169077530278, 0.5312685338364553]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.28519598765496335, 0.28240882611865187, -0.013661579201492767, -0.0132548483330093, 0.10979770640566763, 0.2959447945223719, -0.016440330628504654, -0.014733677941245527, -0.013832130453952032, 0.09857525185654943]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.01633859573696184, 0.01108020733798894, 0.004069247273800202, 0.004742487035886792, 0.4247716703272073, -0.0020292171402693814, 0.0021947380307685204, 0.0036985684836702694, 0.003865169077530278, 0.5312685338364553]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 64 total loss: 0.6186298283001593\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3002098545057339, 0.2977098177282539, -0.0147060055736018, -0.01433857365495739, 0.09092885439089059, 0.3121129212396897, -0.017320749677221078, -0.015728343917532386, -0.014863077182718764, 0.07599530214146354]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.291184600745296, 0.2886277787846629, -0.014232109085471019, -0.013858803583004824, 0.1021315239529689, 0.3021323177981444, -0.01681263055379332, -0.015231624632887198, -0.0143895092582176, 0.09044845583230177]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.012124310793310994, 0.0078116944698464735, 0.0004207411163372738, 0.0009756574685228083, 0.44851737627477817, -0.006467325405494147, -0.0011016185781012689, 0.0001269050303389587, 0.0002531817764157702, 0.5373390770540452]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2910071462758348, 0.28844920780537076, -0.014222791336395703, -0.013849370347569945, 0.10235179075503965, 0.30193607925066046, -0.01680263991952814, -0.015221858142163773, -0.014380197969357822, 0.09073263362810988]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.012124310793310994, 0.0078116944698464735, 0.0004207411163372738, 0.0009756574685228083, 0.44851737627477817, -0.006467325405494147, -0.0011016185781012689, 0.0001269050303389587, 0.0002531817764157702, 0.5373390770540452]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 65 total loss: 0.6148977448750665\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3055128559639574, 0.3031980479587768, -0.01488079912552322, -0.014542354601142326, 0.08293416451739219, 0.3175246549850602, -0.01730587289259558, -0.0158310415476873, -0.015025955929260763, 0.06841630067102261]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.29638642058379244, 0.29403942133253025, -0.014426968899072051, -0.014085409759832938, 0.09461313052908099, 0.3074633864523381, -0.01681360930490113, -0.015354657757384465, -0.014571717588238976, 0.08275000441168781]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.010554513284398988, 0.007199312596040819, -0.0002134064496430754, 0.00022569968010715524, 0.4603880460739793, -0.007646670734892918, -0.0013963478765728874, -0.00043473757861340077, -0.00034537335038351935, 0.5316689643555795]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.2961148490499595, 0.2937668918972045, -0.014413464462173835, -0.014071812642638511, 0.09496065665305593, 0.3071639974780102, -0.016798961222490895, -0.015340482203486732, -0.014558201007245577, 0.08317652645980517]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.010554513284398988, 0.007199312596040819, -0.0002134064496430754, 0.00022569968010715524, 0.4603880460739793, -0.007646670734892918, -0.0013963478765728874, -0.00043473757861340077, -0.00034537335038351935, 0.5316689643555795]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 66 total loss: 0.6120542321557183\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3102846666158548, 0.3081347500606073, -0.014880692322823455, -0.014569508518831452, 0.0752668896245253, 0.3223691638508826, -0.01712402227212496, -0.015761396361700104, -0.015014547259402126, 0.06129469658301188]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3010571140594713, 0.2988952360672103, -0.014435479810352592, -0.01412328265323604, 0.0873408645359064, 0.3122253535217777, -0.01663780428824749, -0.015294162394654158, -0.014568383793761519, 0.07554054475588592]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.009503165031210981, 0.006963353217815023, -0.00036853569114761177, -2.4320606913679e-05, 0.46883043551061426, -0.008278695799324845, -0.0012752504125756298, -0.0005314279230798875, -0.00047139333775324135, 0.5256526700111546]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3006984162893736, 0.29853607332649795, -0.014418173299826958, -0.014105936751170356, 0.08781020977674528, 0.3118310385478872, -0.01661890379371955, -0.015275999855771912, -0.014551040317336277, 0.07609431607732114]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.009503165031210981, 0.006963353217815023, -0.00036853569114761177, -2.4320606913679e-05, 0.46883043551061426, -0.008278695799324845, -0.0012752504125756298, -0.0005314279230798875, -0.00047139333775324135, 0.5256526700111546]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 67 total loss: 0.6097714389935847\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.31451990624406817, 0.3125160223594039, -0.014719876919089046, -0.014434262834995038, 0.06798394900584977, 0.32664568293830054, -0.016789865348017102, -0.015533876762227426, -0.014843048622484627, 0.05465536993919066]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3052054141772752, 0.303205918908473, -0.014284343931464273, -0.013999253935551669, 0.08039107093041015, 0.3164318692157328, -0.016312233615713993, -0.015077117972635922, -0.014406190140422855, 0.0688448663638974]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.008644985889488753, 0.006785218025066748, -0.00041758142662130657, -0.00014917766699760983, 0.4754165178771151, -0.008761705516602233, -0.0011051058324791287, -0.0005345555554770288, -0.000497225742539285, 0.520618629949046]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3047670237958625, 0.302767735079062, -0.014263845393144257, -0.013978780063656415, 0.08097501720184803, 0.3159511518925115, -0.01628975368274527, -0.015055620433258922, -0.014385629217164653, 0.0695127008206852]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.008644985889488753, 0.006785218025066748, -0.00041758142662130657, -0.00014917766699760983, 0.4754165178771151, -0.008761705516602233, -0.0011051058324791287, -0.0005345555554770288, -0.000497225742539285, 0.520618629949046]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 68 total loss: 0.6079328130118604\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.31821959036270386, 0.3163445816184762, -0.014409692519736783, -0.014148013577456152, 0.061125424350283175, 0.3303579764161641, -0.016315052260499643, -0.015160032210576156, -0.014522795944885836, 0.048508013765527346]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.30883328232464213, 0.30697585214730133, -0.013985978371718277, -0.013725917417154634, 0.07381358845588942, 0.3200879423422531, -0.01584927472625033, -0.014716077343745882, -0.014097513159043997, 0.06266409574782729]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.007936822972686884, 0.006642908132293178, -0.0004029927719375293, -0.0001947995776629017, 0.48055750092627686, -0.009138083240206962, -0.0009178650246950967, -0.0004842359211534842, -0.00046424180632056934, 0.5164649863107196]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.30832266829991883, 0.30646619439449563, -0.013962928373191208, -0.013702955436964143, 0.07450382305228673, 0.3195292537278095, -0.015823936484587655, -0.014691926252557686, -0.014074377826808612, 0.0634341848995985]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.007936822972686884, 0.006642908132293178, -0.0004029927719375293, -0.0001947995776629017, 0.48055750092627686, -0.009138083240206962, -0.0009178650246950967, -0.0004842359211534842, -0.00046424180632056934, 0.5164649863107196]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 69 total loss: 0.6064489885104263\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3214045569273772, 0.3196428101291056, -0.013968933457815637, -0.013729592092168378, 0.05471815627873473, 0.3335302615869084, -0.015718725150233162, -0.014658868942909239, -0.014072585282797676, 0.04285292000379832]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3119615076871435, 0.31022796904619426, -0.01355955127318043, -0.013322577160235197, 0.06764311615377674, 0.32321798159165016, -0.015268150403599788, -0.014230356937056878, -0.013661492222899245, 0.056991553518206825]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.007346771063735303, 0.006523173713437424, -0.00035366372791068777, -0.00019305266677274954, 0.4845776410135315, -0.009436479359219783, -0.0007334694670543532, -0.0004073778884528424, -0.0004004151086201847, 0.5130768724273264]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3113859944634253, 0.309654174988303, -0.013534601190339774, -0.01329777135126194, 0.06843083685022516, 0.3225894924931639, -0.015240689811330912, -0.014204240973916567, -0.01363643786957211, 0.057853242401303843]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.007346771063735303, 0.006523173713437424, -0.00035366372791068777, -0.00019305266677274954, 0.4845776410135315, -0.009436479359219783, -0.0007334694670543532, -0.0004073778884528424, -0.0004004151086201847, 0.5130768724273264]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 70 total loss: 0.6052494275723419\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3241111137536999, 0.32244845638668385, -0.013421082084484875, -0.013202512935717097, 0.048775255933016015, 0.3362026068865212, -0.015024654544823676, -0.01405404624267679, -0.013515900071735091, 0.0376807629195165]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.31462549985520594, 0.3129996141828111, -0.01302842371850006, -0.012812706785256832, 0.06189931869570285, 0.325861332699347, -0.014592269227231421, -0.013643441774277006, -0.013121464659673222, 0.051812540731871484]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.006851805266866572, 0.006419027434506793, -0.0002880868986181522, -0.00016491399248236104, 0.487727454618747, -0.009675428273285089, -0.0005629372192895139, -0.0003208191579436372, -0.00032346915344355756, 0.5103373673749418]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3139921005528652, 0.3123686703004324, -0.01300220406232024, -0.012786677584997177, 0.06277567443679859, 0.3251707969126742, -0.014563396814603623, -0.013616023771962606, -0.013095126341722272, 0.052756186372835426]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.006851805266866572, 0.006419027434506793, -0.0002880868986181522, -0.00016491399248236104, 0.487727454618747, -0.009675428273285089, -0.0005629372192895139, -0.0003208191579436372, -0.00032346915344355756, 0.5103373673749418]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 71 total loss: 0.6042780477740541\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.32638578337858526, 0.3248094086060362, -0.012791541633230244, -0.01259221661741764, 0.04329712329694706, 0.33842541490805994, -0.014258409671693905, -0.013371085809521841, -0.012878139990363094, 0.032973663532598264]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3168703050348097, 0.31533760328081323, -0.012417594149645527, -0.012221406446387046, 0.05658822104206214, 0.3280670407964388, -0.013846602409543832, -0.012980406169378601, -0.012502405427495766, 0.047105244448327005]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.006434887352005123, 0.00632698541006549, -0.00021783507668290107, -0.0001239998666941734, 0.49020041907378387, -0.009867225635822725, -0.0004116961639744227, -0.00023477290887424437, -0.00024434421947616724, 0.5081375820356702]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3161855893701448, 0.31465603024322875, -0.012390685602274396, -0.012194723654040847, 0.05754462307440189, 0.32732167196069073, -0.013816969544749246, -0.012952293607948973, -0.012475368285309471, 0.04812212604585676]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.006434887352005123, 0.00632698541006549, -0.00021783507668290107, -0.0001239998666941734, 0.49020041907378387, -0.009867225635822725, -0.0004116961639744227, -0.00023477290887424437, -0.00024434421947616724, 0.5081375820356702]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 72 total loss: 0.6034901209256471\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.32828011689828496, 0.32677851884220277, -0.01210526617003301, -0.01192370479933182, 0.03827348611969345, 0.3402539997330172, -0.013444959600769498, -0.012634991508192537, -0.012184248911930626, 0.028707049397059113]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.31874568447027757, 0.31729332648400166, -0.01175148256737449, -0.011573194831623874, 0.051704448711510774, 0.32988870590667096, -0.01305543327816393, -0.012265686936761661, -0.011828708576688505, 0.04284234061815153]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.006083034479846226, 0.006245406140836187, -0.00014985661159731147, -7.892118931440359e-05, 0.49214601537932035, -0.010020382562496516, -0.0002816962795015859, -0.00015508184002076955, -0.00016947408793771678, 0.5063809565708657]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.31801569051424344, 0.3165671025429763, -0.011724395491805517, -0.011546358398528508, 0.05273277646880289, 0.32909509790715086, -0.013025609598215979, -0.012237411514274175, -0.011801486998706506, 0.04392459456835705]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.006083034479846226, 0.006245406140836187, -0.00014985661159731147, -7.892118931440359e-05, 0.49214601537932035, -0.010020382562496516, -0.0002816962795015859, -0.00015508184002076955, -0.00016947408793771678, 0.5063809565708657]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 73 total loss: 0.6028499416577726\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.32984634310507044, 0.32840925028157175, -0.011385050544806038, -0.011219831650185202, 0.03368592238579195, 0.3417440584352459, -0.012606962346531726, -0.011868540121994084, -0.011457004518289729, 0.024851814974126744]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3203019860918546, 0.31891863121375436, -0.011052326177861017, -0.010890408524409617, 0.047233853098568104, 0.3313801909522387, -0.012240745889367766, -0.011521478697984987, -0.011122581865306345, 0.03899287979851402]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.005786030067324734, 0.006173505979436712, -8.803364170930271e-05, -3.490205116766281e-05, 0.49367989177699584, -0.010141158785209011, -0.00017278583953401369, -8.473597971607039e-05, -0.00010232557421347415, 0.5049845140477923]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3195321757044215, 0.3181531551181451, -0.011025489935935894, -0.010863838547644122, 0.04832657603176096, 0.33054428206583053, -0.012211208306858706, -0.01149348608529148, -0.011095608646292946, 0.040133442601865424]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.005786030067324734, 0.006173505979436712, -8.803364170930271e-05, -3.490205116766281e-05, 0.49367989177699584, -0.010141158785209011, -0.00017278583953401369, -8.473597971607039e-05, -0.00010232557421347415, 0.5049845140477923]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 74 total loss: 0.6023289931507771\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3311342067560004, 0.329752507946333, -0.010650526196789467, -0.010500298441069913, 0.02951040316286821, 0.3429484004840435, -0.011763778653295339, -0.011091285352102081, -0.01071601489143863, 0.021376385185450403]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32158714481446643, 0.32026282617065616, -0.010339240206215586, -0.010192263646915103, 0.0431561120589025, 0.3325925249183338, -0.011421297769710468, -0.010766801573984148, -0.010403107729871288, 0.03552410296433783]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.005535583203042214, 0.006110811365959359, -3.424543074158405e-05, 5.1016073882955574e-06, 0.494891696503386, -0.010234479288811191, -8.360888260277106e-05, -2.4899466321685297e-05, -4.444475498052468e-05, 0.5038784851436819]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3207823961712095, 0.3194629142626071, -0.010313001036498945, -0.010166298529668556, 0.04430634715610952, 0.33171959910489734, -0.011392429094918772, -0.010739449925718073, -0.010376731907102067, 0.036716653799083045]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.005535583203042214, 0.006110811365959359, -3.424543074158405e-05, 5.1016073882955574e-06, 0.494891696503386, -0.010234479288811191, -8.360888260277106e-05, -2.4899466321685297e-05, -4.444475498052468e-05, 0.5038784851436819]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 75 total loss: 0.6019044748895\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3321890079005277, 0.3308546696324783, -0.00991776263193151, -0.009781252420030893, 0.025719547889316553, 0.34391494029928493, -0.010931101183876876, -0.010319171271101558, -0.009977321367347233, 0.018248443152680607]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3226448226773199, 0.3213708226075906, -0.009627853137460415, -0.009494490256785072, 0.039447029151622445, 0.3335720048108216, -0.010612277257348677, -0.010017147065826336, -0.00968587934920894, 0.032402967819274625]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.005324790861469273, 0.006056883356256763, 1.0904688151669404e-05, 3.962676176152004e-05, 0.4958510792652259, -0.010304454154776176, -1.2187658963920665e-05, 2.439426910591031e-05, 3.8310142532620264e-06, 0.5030051315975159]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32180945038603975, 0.32054073152762425, -0.00960247827800449, -0.009469390873258795, 0.04064855209018776, 0.3326667204397104, -0.010584371609271859, -0.009990711844119897, -0.009660370352812317, 0.03364186851390537]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.005324790861469273, 0.006056883356256763, 1.0904688151669404e-05, 3.962676176152004e-05, 0.4958510792652259, -0.010304454154776176, -1.2187658963920665e-05, 2.439426910591031e-05, 3.8310142532620264e-06, 0.5030051315975159]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 76 total loss: 0.6015581205726931\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3330506474371771, 0.33175662517058885, -0.00919930925141144, -0.009075325592767637, 0.02228444403318179, 0.3446857431699321, -0.010121026650142894, -0.009564587069054744, -0.009253441914626416, 0.015436230667123128]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32351350405877627, 0.3222822311907958, -0.008930360546895525, -0.00880938461477441, 0.036080397778116335, 0.3343592968414499, -0.009825382666319559, -0.009284543555708749, -0.008983055550870101, 0.02959729706543007]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.005147797516368869, 0.006011203928151126, 4.7594480056357525e-05, 6.816749890574728e-05, 0.4966122768918924, -0.010354654810470808, 4.370517900869807e-05, 6.377464100961793e-05, 4.2890932399138974e-05, 0.5023172437426788]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3226512972098098, 0.32142569721043385, -0.00890604619973163, -0.008785342181568897, 0.037327623004261706, 0.33342573294326355, -0.009798654928506, -0.009259226180721768, -0.008958611231911258, 0.03087753035467062]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.005147797516368869, 0.006011203928151126, 4.7594480056357525e-05, 6.816749890574728e-05, 0.4966122768918924, -0.010354654810470808, 4.370517900869807e-05, 6.377464100961793e-05, 4.2890932399138974e-05, 0.5023172437426788]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 77 total loss: 0.601275256854706\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3337534064695407, 0.33249355278857096, -0.008504509194807683, -0.008391945680211453, 0.01917600466019852, 0.3452968355816942, -0.009342397942930993, -0.008836692919348204, -0.008553686433780709, 0.0129094326710747]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32422628765107364, 0.32303115754068296, -0.00825583737271332, -0.0081461198019749, 0.03302940755777472, 0.3349892626141603, -0.009069158614781808, -0.008577879509741839, -0.008303674143786717, 0.02707655407930724]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004999578488791511, 0.005973151512567228, 7.644953806801557e-05, 9.080760825857888e-05, 0.49721761618179816, -0.010388249787371075, 8.631568975847762e-05, 9.422321197099484e-05, 7.352804143277296e-05, 0.5017765795147253]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.323340557600523, 0.32215144479846375, -0.008232718514876971, -0.008123265529691127, 0.03431734943008381, 0.3340309742481234, -0.009043755731859338, -0.008553817795099478, -0.00828043066352011, 0.028393662157853175]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004999578488791511, 0.005973151512567228, 7.644953806801557e-05, 9.080760825857888e-05, 0.49721761618179816, -0.010388249787371075, 8.631568975847762e-05, 9.422321197099484e-05, 7.352804143277296e-05, 0.5017765795147253]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 78 total loss: 0.6010440605590138\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3343261964677387, 0.33309516963384045, -0.007839947526147207, -0.007737781891705645, 0.016365909960999243, 0.3457785027755016, -0.008601276229523138, -0.008141878351102427, -0.007884606168229332, 0.010639711328627807]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32481112576373905, 0.323646447272086, -0.0076106771941538715, -0.007511183586809634, 0.03026763769558026, 0.33549124739679986, -0.0083494557253068, -0.007903352030185386, -0.007654092097651359, 0.02481230250590187]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004875797749090814, 0.005942020035772693, 9.832268111576363e-05, 0.000107971883469095, 0.49770019401530835, -0.010408066054640501, 0.0001177725406273876, 0.00011687179123526811, 9.67273209951794e-05, 0.5013523880370261]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32390475750340203, 0.3227463990942169, -0.007588837802895503, -0.007489598722356911, 0.03159186167398692, 0.33451132385747007, -0.0083254682932189, -0.007880630949779406, -0.007632134232740788, 0.026162327871915605]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004875797749090814, 0.005942020035772693, 9.832268111576363e-05, 0.000107971883469095, 0.49770019401530835, -0.010408066054640501, 0.0001177725406273876, 0.00011687179123526811, 9.67273209951794e-05, 0.5013523880370261]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 79 total loss: 0.6008549758850215\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33479306877323234, 0.33358624442773777, -0.007209937044728953, -0.007117228896768104, 0.013827210319996038, 0.3461558516797818, -0.007901445548752163, -0.0074842561120551515, -0.007250480464843679, 0.008600972866400323]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3252913102990192, 0.3241521794984762, -0.006999066050927514, -0.006908851209121918, 0.027769712026157967, 0.3358896200320067, -0.007669920425615768, -0.007264947993249476, -0.007038460052197865, 0.0227784238754527]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004772708810098272, 0.00591705431729153, 0.00011415159307422206, 0.0001202608449372562, 0.4980859340437876, -0.01041661572807229, 0.00014001379641495599, 0.00013287544390983976, 0.000113530427539935, 0.5010200864510186]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.324366813270536, 0.3232342688804269, -0.006978548837435738, -0.00688857658800269, 0.02912628212125643, 0.3348907417003962, -0.007647393617663357, -0.007243609868868781, -0.007017831003164384, 0.024157853942519077]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004772708810098272, 0.00591705431729153, 0.00011415159307422206, 0.0001202608449372562, 0.4980859340437876, -0.01041661572807229, 0.00014001379641495599, 0.00013287544390983976, 0.000113530427539935, 0.5010200864510186]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 80 total loss: 0.6007002578596587\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3351738335432487, 0.3339872215643101, -0.006616982503824909, -0.006532869755841521, 0.011534673268305004, 0.3464494826286555, -0.007244890900131347, -0.006866132394843457, -0.0066537816782939385, 0.006769446228416044]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3256860630524844, 0.3245682658362095, -0.006423434195491356, -0.006341636481506152, 0.025511695370293908, 0.33620441590906025, -0.0070324583670321504, -0.0066649012363646665, -0.006459174549666866, 0.020951164662013425]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004687079829311361, 0.005897486996491671, 0.00012487030240022844, 0.00012834365553930876, 0.49839517074457884, -0.010416110298323691, 0.00015475460304800447, 0.000143336518478951, 0.00012495293087036563, 0.5007601147176048]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3247456189071513, 0.3236346427286242, -0.0064042493539536545, -0.0063226811101239466, 0.026897121864094476, 0.3351889072577529, -0.00701140168862431, -0.006644954857493657, -0.006439884756038788, 0.022356881008611308]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004687079829311361, 0.005897486996491671, 0.00012487030240022844, 0.00012834365553930876, 0.49839517074457884, -0.010416110298323691, 0.00015475460304800447, 0.000143336518478951, 0.00012495293087036563, 0.5007601147176048]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 81 total loss: 0.6005736139472505\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33548469272883946, 0.33431486048095194, -0.006062192570243482, -0.005985887061244999, 0.009464947450965657, 0.34667617072780094, -0.006632219842919326, -0.006288423039234673, -0.00609558759004534, 0.005123638715130055]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3260111396511632, 0.32491106360026406, -0.005884856523032056, -0.005810691900484307, 0.02347130248031684, 0.33645198888321654, -0.0064376427903779605, -0.006104096794917529, -0.005917278763760389, 0.019309072157612035]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.00461613224305454, 0.005882569924016292, 0.00013135721852024324, 0.0001328912017448019, 0.4986438741130794, -0.01040847336777249, 0.00016348064559473316, 0.00014926286561103077, 0.0001319369924508585, 0.5005569681637005]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3250566456626864, 0.32396359779542, -0.005866989288889207, -0.0057930403682254815, 0.024882492301746016, 0.3354218663908704, -0.006418038463952229, -0.0060855252736860925, -0.005899313518684348, 0.02073830476271464]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.00461613224305454, 0.005882569924016292, 0.00013135721852024324, 0.0001328912017448019, 0.4986438741130794, -0.01040847336777249, 0.00016348064559473316, 0.00014926286561103077, 0.0001319369924508585, 0.5005569681637005]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 82 total loss: 0.6004699214451445\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33573883301809354, 0.3345828355946138, -0.005545627964345924, -0.005476410628267038, 0.007596602359791482, 0.34684950112378554, -0.006063016876240351, -0.005751004490217355, -0.005575929827707382, 0.003644217690493657]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3262793956581883, 0.3251939512069673, -0.005383390746464015, -0.005316146761511999, 0.021627977379899185, 0.3366456191865827, -0.005885057643405598, -0.005582411570536572, -0.005412800829911492, 0.017832864120192148]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.0045574873300653395, 0.005871597525669994, 0.00013440754881807436, 0.0001345365177090953, 0.4988445999107996, -0.010395356327064287, 0.0001674570901745588, 0.00015154847239503446, 0.00013532750772082656, 0.5003983944237118]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3253125033056777, 0.3242342703964045, -0.005366807738480104, -0.005299765458771307, 0.023062188389071366, 0.33560263374932814, -0.005866867616373345, -0.005565178917205865, -0.005396126669024279, 0.019283150559373144]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.0045574873300653395, 0.005871597525669994, 0.00013440754881807436, 0.0001345365177090953, 0.4988445999107996, -0.010395356327064287, 0.0001674570901745588, 0.00015154847239503446, 0.00013532750772082656, 0.5003983944237118]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 83 total loss: 0.6003850033650121\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33594695286749127, 0.334802270449118, -0.005066585614887251, -0.005003801475618845, 0.00591008800591587, 0.3469804319098342, -0.00553613123661006, -0.0052529996753960355, -0.005094078163367702, 0.0023138529335203074]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3265012901442342, 0.32542784071100817, -0.004918353311783358, -0.004857383200526961, 0.019962887042932524, 0.33679605234992555, -0.005373576162828079, -0.005098991731842058, -0.004945029809023198, 0.016505263967903184]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004509118036353009, 0.005863922107971303, 0.00013472159162770923, 0.00013385349873003738, 0.49900722926608876, -0.010378157882228636, 0.00016774611679785378, 0.0001509683524529203, 0.00013586337662116057, 0.5002747355355859]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32552343888362617, 0.3244573637624378, -0.004903007734802712, -0.0048422254186889415, 0.021417686738414276, 0.33574172628695415, -0.005356747837651428, -0.005083048238393249, -0.004929599751285856, 0.017974413309389786]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004509118036353009, 0.005863922107971303, 0.00013472159162770923, 0.00013385349873003738, 0.49900722926608876, -0.010378157882228636, 0.00016774611679785378, 0.0001509683524529203, 0.00013586337662116057, 0.5002747355355859]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 84 total loss: 0.6003154496391531\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3361177153239015, 0.33498219744878627, -0.004623824597024841, -0.004566877782769262, 0.004387646176056256, 0.3470777766986341, -0.0050499045726294725, -0.004793004854812035, -0.004648766497141616, 0.0011170426569987741]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3266853187405223, 0.32562161925089916, -0.004488538734000901, -0.004433255780144827, 0.01845886129924579, 0.33691196153415076, -0.004901581221504825, -0.004652472792570738, -0.004512734996572595, 0.015310822699975643]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004469304957520219, 0.00585896222458461, 0.00013290302997024942, 0.00013134756946569845, 0.49913954578896574, -0.010358046697533794, 0.0001652285259282885, 0.0001481821103292057, 0.00013417816858263875, 0.5001783943221871]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3256977652637011, 0.3246415850185949, -0.0044743745686996374, -0.004419265817773641, 0.019932090005775466, 0.3358476205661195, -0.004886052056694788, -0.004637759360470586, -0.004498492764478487, 0.01679688371392606]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004469304957520219, 0.00585896222458461, 0.00013290302997024942, 0.00013134756946569845, 0.49913954578896574, -0.010358046697533794, 0.0001652285259282885, 0.0001481821103292057, 0.00013417816858263875, 0.5001783943221871]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 85 total loss: 0.6002584736961222\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3362581283270693, 0.3351299446637543, -0.0042157420729231785, -0.00416409097965406, 0.003013195079219828, 0.3471486092222336, -0.004602347273631957, -0.004369265893254574, -0.0042383687756361475, 3.993770282286086e-05]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3268383777001237, 0.32578252079642406, -0.0040923903723177005, -0.004042262590425527, 0.017100301281369325, 0.3370003354917942, -0.004467135958906184, -0.0042411505999775945, -0.004114336620960302, 0.014235740872875893]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004436596118053629, 0.005856205612515197, 0.0001294632214094921, 0.00012745392225978964, 0.4992476867882727, -0.010335985845311155, 0.00016062654607405493, 0.00014374242280093611, 0.000130806294667159, 0.5001034049192583]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3258422211166149, 0.32479401290560456, -0.004079345694861627, -0.004029379006051104, 0.01859003961326497, 0.3359271362014746, -0.00445283710465163, -0.004227602163516766, -0.004101219984189294, 0.01573697411631143]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004436596118053629, 0.005856205612515197, 0.0001294632214094921, 0.00012745392225978964, 0.4992476867882727, -0.010335985845311155, 0.00016062654607405493, 0.00014374242280093611, 0.000130806294667159, 0.5001034049192583]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 86 total loss: 0.6002117968577987\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33637385918580426, 0.3352514562879688, -0.003840507887682717, -0.0037936605733481068, 0.0017722019024506628, 0.3471985974366216, -0.004191272534424409, -0.0039798127864722746, -0.003861033521128322, -0.0009298275097894987]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32696606527256955, 0.3259164344490639, -0.0037281310625427284, -0.0036826762462213946, 0.015873071550751433, 0.33706679925281835, -0.0040681134962478735, -0.0038631118172261754, -0.0037480363681434473, 0.013267698465178524]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004409770473321828, 0.0058552081937395415, 0.00012482879954197723, 0.00012254032941164177, 0.4993364965737616, -0.010312757735975592, 0.00015452609297367107, 0.00013810595887199458, 0.00012619209878660012, 0.5000450892155667]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3259622686940537, 0.3249204025346017, -0.0037161406348590054, -0.003670834395850719, 0.017377611811476238, 0.33598575257546626, -0.004054972623661263, -0.0038506600102755657, -0.003735979752469852, 0.014782551801518645]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004409770473321828, 0.0058552081937395415, 0.00012482879954197723, 0.00012254032941164177, 0.4993364965737616, -0.010312757735975592, 0.00015452609297367107, 0.00013810595887199458, 0.00012619209878660012, 0.5000450892155667]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 87 total loss: 0.600173554793987\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33646949188478037, 0.3353515553594942, -0.0034961658637155716, -0.003453675719933455, 0.000651552609826683, 0.34723227656050737, -0.0038143965193110575, -0.0036225606184657646, -0.0035147850315558117, -0.0018032926616269962]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32707292858409237, 0.3260281574876991, -0.003393861422396468, -0.003352642571466033, 0.014764385872892279, 0.33711587649489744, -0.003702293836042703, -0.0035163318394312794, -0.0034119155619951806, 0.012395696791750796]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.0043878051150876484, 0.005855590439641261, 0.0001193508257523378, 0.00011691251419867033, 0.49940980337955554, -0.010288988429936696, 0.00014739748557130984, 0.00013164514766510985, 0.00012070018528899298, 0.4999997833371758]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32606233758517406, 0.32502543535759004, -0.0033828586819010264, -0.003341776557247188, 0.016282206996264367, 0.3360278677707916, -0.003690237304410836, -0.0035049070403336694, -0.003400852053276641, 0.013922783927349315]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.0043878051150876484, 0.005855590439641261, 0.0001193508257523378, 0.00011691251419867033, 0.49940980337955554, -0.010288988429936696, 0.00014739748557130984, 0.00013164514766510985, 0.00012070018528899298, 0.4999997833371758]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 88 total loss: 0.6001422215894414\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3365487361254122, 0.3354341576423776, -0.0031807087806636396, -0.0031421705041880885, -0.00036057525744883246, 0.34725327065137107, -0.0034694118448803115, -0.003295384035051198, -0.00319759825054848, -0.002590315746380383]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32716266446701586, 0.326121601637128, -0.0030876326152187356, -0.0030502537389800175, 0.013762692994907734, 0.3371512027322064, -0.0033674349362117625, -0.00319874701931864, -0.003104007795564613, 0.011609914274035914]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004369846116535185, 0.0058570321361955426, 0.00011331436863897868, 0.00011082075256521589, 0.499470636575312, -0.01026517053595422, 0.00013961412049815226, 0.00012465981163046068, 0.0001146259241046054, 0.499964620730474]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32614602286146654, 0.32511292279538107, -0.0030775511769216353, -0.003040297879792171, 0.015292438625907206, 0.33605700881141726, -0.00335638942410287, -0.003188279891599456, -0.0030938706525849113, 0.013147995930829113]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.0048637798965155184, 0.006347097219476335, 0.00010841631715402647, 0.00010598371349976477, 0.49872741198386944, -0.009733558081401158, 0.00013424767521597644, 0.00011957437352557447, 0.00010970080858421545, 0.49921734609356033]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 89 total loss: 0.6001177288964962\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33650921191669336, 0.33539783821349195, -0.002893228282211837, -0.002858285739818117, -0.0011331922241309218, 0.34715159219318675, -0.0031550473268798537, -0.0029972312130520803, -0.002908543431431745, -0.003113114105847889]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32684676658867357, 0.3258115020921611, -0.0028083463301159487, -0.002774492281143355, 0.013439407030043007, 0.3367546861315529, -0.0030618367676765175, -0.0029090204993529136, -0.0028231794403662087, 0.01152451347622424]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004223141071607536, 0.00572912026275689, 2.5814402129447644e-05, 2.3324266793214676e-05, 0.5000103158408012, -0.010392170993496624, 5.0411480647235055e-05, 3.6285714235302794e-05, 2.7076302484533887e-05, 0.5002666816520412]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32601964921671933, 0.3249908997632297, -0.0028010803291440927, -0.0027673194565660153, 0.014686839702464158, 0.3358646980047154, -0.003053857827548072, -0.002901469552235884, -0.002815872176257308, 0.01277751265462269]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004223141071607536, 0.00572912026275689, 2.5814402129447644e-05, 2.3324266793214676e-05, 0.5000103158408012, -0.010392170993496624, 5.0411480647235055e-05, 3.6285714235302794e-05, 2.7076302484533887e-05, 0.5002666816520412]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 90 total loss: 0.6001023744896972\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3366173987701979, 0.33552469443720345, -0.0026486325861362256, -0.0026169290308065553, -0.0020128937585459023, 0.3472382582818552, -0.0028862255069827102, -0.002743017207318728, -0.002662529340172755, -0.003810124059293794]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32695940901986176, 0.3259407881712361, -0.0025680087950584636, -0.002537297562286756, 0.012568453635808797, 0.336845442020549, -0.002798030863041766, -0.0026593700425299196, -0.0025814667281231947, 0.010830081143584256]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004380251806362972, 0.00583603697481877, 0.00012484502333749036, 0.0001224124464027799, 0.4995889284032903, -0.010277095620391906, 0.00014769124359269374, 0.00013446517767553873, 0.00012604381521340023, 0.49981642072969795]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3261254627154684, 0.3251132388137854, -0.0025610471069273345, -0.0025304215590394763, 0.013827521111229917, 0.33594804505312587, -0.002790415448314361, -0.0026521472926873675, -0.002574467148760331, 0.012094230862119274]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004380251806362972, 0.00583603697481877, 0.00012484502333749036, 0.0001224124464027799, 0.4995889284032903, -0.010277095620391906, 0.00014769124359269374, 0.00013446517767553873, 0.00012604381521340023, 0.49981642072969795]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 91 total loss: 0.6000836673754724\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3367026144184026, 0.3356266474514945, -0.0024223603449790385, -0.002393597271774173, -0.002802310260705438, 0.3473034320055046, -0.0026379501727646663, -0.0025080081090066188, -0.0024349691461221044, -0.004433498570049374]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32705417369436685, 0.3260506832783888, -0.002349030212247676, -0.0023211703689023045, 0.011786961653836666, 0.3369202813009135, -0.0025577456926241613, -0.0024319346916241253, -0.0023612400723167846, 0.010209021110209096]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004408622221720715, 0.00582876039118018, 0.00010314229845998514, 0.0001007979767533811, 0.4996547754370134, -0.010294100890484397, 0.00012430620214935544, 0.00011197373936604776, 0.00010427309793304253, 0.4998574495259083]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3262146229666283, 0.3252174390350675, -0.002342649454147933, -0.0023148682045678695, 0.013056434535865993, 0.33601680041943355, -0.0025507667691280454, -0.002425315228982257, -0.0023548246007044082, 0.011483127300535198]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004408622221720715, 0.00582876039118018, 0.00010314229845998514, 0.0001007979767533811, 0.4996547754370134, -0.010294100890484397, 0.00012430620214935544, 0.00011197373936604776, 0.00010427309793304253, 0.4998574495259083]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 92 total loss: 0.600068507680914\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3367644257336472, 0.33570348542223016, -0.002210511733018421, -0.002184418296916395, -0.003511017691441541, 0.3473456421252644, -0.0024061176985565895, -0.002288223543659644, -0.002221950999430331, -0.004991313318119068]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32712459811967065, 0.3261348605424365, -0.0021436161451445605, -0.0021183443887438976, 0.011084791270818645, 0.3369715404733234, -0.0023329814303804054, -0.002218839052880149, -0.002154692863000678, 0.009652683473900777]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004439690718061751, 0.005833403198918674, 9.565590857512531e-05, 9.342264632132635e-05, 0.4996668958522076, -0.01029255645699376, 0.00011519200893653679, 0.00010374687695819963, 9.671519063925942e-05, 0.4998478340563754]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3262800776574992, 0.3252965779683672, -0.0021377555950340427, -0.0021125558238751225, 0.012363492490817625, 0.33606269215439616, -0.0023265741503464663, -0.0022127604563982294, -0.002148800550945221, 0.010935606305518689]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004439690718061751, 0.005833403198918674, 9.565590857512531e-05, 9.342264632132635e-05, 0.4996668958522076, -0.01029255645699376, 0.00011519200893653679, 0.00010374687695819963, 9.671519063925942e-05, 0.4998478340563754]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 93 total loss: 0.6000561094239142\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33681009478272167, 0.3357625855045954, -0.0020140897566613214, -0.0019904191840997283, -0.0041483529697536724, 0.3473723899875078, -0.00219155331041326, -0.0020845962023589653, -0.0020244674302585404, -0.005491591421279684]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32717845215787394, 0.32620113388196176, -0.001953180704250375, -0.001930257229555046, 0.010452989036106938, 0.33700713223103035, -0.002124980097617523, -0.0020214293459906115, -0.0019632290259702346, 0.009153369096410721]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004462129099578483, 0.005836619650945065, 8.76285533850748e-05, 8.551988291511676e-05, 0.49968328830942843, -0.010289585578281206, 0.00010561163885250173, 9.502954065425154e-05, 8.861544455607371e-05, 0.4998451434579662]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3263295452095955, 0.32535841337890425, -0.0019478123449975808, -0.001924954717488907, 0.011739911855584085, 0.3360935664278858, -0.0021191125145776655, -0.0020158619899994677, -0.0019578316385331514, 0.010444136333627202]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004462129099578483, 0.005836619650945065, 8.76285533850748e-05, 8.551988291511676e-05, 0.49968328830942843, -0.010289585578281206, 0.00010561163885250173, 9.502954065425154e-05, 8.861544455607371e-05, 0.4998451434579662]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 94 total loss: 0.6000459620696235\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3368439926935241, 0.335808450380368, -0.001832890795685113, -0.0018114186856579835, -0.004722198604476897, 0.3473881010369699, -0.0019938877429070477, -0.001896856899901317, -0.0018423050696940793, -0.005940986312539537]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3272199821712579, 0.3262538260659353, -0.001777487967075741, -0.0017566948552121288, 0.009883871800543021, 0.33703128164243984, -0.0019333448582276279, -0.0018394060914412474, -0.0017866031343922713, 0.008704575226172984]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004479204890765199, 0.005839912268904086, 8.044349793643292e-05, 7.846643570697221e-05, 0.49969781211403613, -0.01028420952529043, 9.695816513585795e-05, 8.72042894282779e-05, 8.135886063472926e-05, 0.4998428490027427]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32636718476475995, 0.32540717707105327, -0.0017725786427933733, -0.0017518456979330624, 0.01117813669475826, 0.3361135489883879, -0.0019279800661882735, -0.0018343152927204228, -0.0017816673058359332, 0.010002339486511606]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004479204890765199, 0.005839912268904086, 8.044349793643292e-05, 7.846643570697221e-05, 0.49969781211403613, -0.01028420952529043, 9.695816513585795e-05, 8.72042894282779e-05, 8.135886063472926e-05, 0.4998428490027427]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 95 total loss: 0.6000376536970364\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33686933496141874, 0.3358444245155458, -0.0016664091033787578, -0.0016469315671221025, -0.005239393890202872, 0.34739603152984894, -0.0018124630746670708, -0.001724439620262565, -0.0016749492242536354, -0.006345204526926633]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3272523904759863, 0.3262962251152921, -0.0016160572709600872, -0.001597196626012489, 0.009370757773332239, 0.33704717532489586, -0.001757447388276859, -0.0016722302500646405, -0.0016243258176068009, 0.008300708663414307]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004492120423092768, 0.005843151728728342, 7.383197127541756e-05, 7.198874236721784e-05, 0.49971116720164943, -0.010277240294734317, 8.896836501649684e-05, 8.000097575760063e-05, 7.467789662699576e-05, 0.49984133299022004]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32639613230679476, 0.32544608776138284, -0.001611574124789538, -0.0015927684056267026, 0.010671593161742685, 0.3361257503670309, -0.0017525489893127537, -0.0016675817154070851, -0.0016198184914431406, 0.009604728129627907]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004492120423092768, 0.005843151728728342, 7.383197127541756e-05, 7.198874236721784e-05, 0.49971116720164943, -0.010277240294734317, 8.896836501649684e-05, 8.000097575760063e-05, 7.467789662699576e-05, 0.49984133299022004]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 96 total loss: 0.6000308493300934\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33688842198206626, 0.33587293291441933, -0.0015139125770994514, -0.0014962444762370653, -0.005705903554430287, 0.3473985010606104, -0.0016464078671913412, -0.0015665570487094816, -0.0015216596063282245, -0.006709170827100194]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3272779809650154, 0.32633072558458043, -0.001468181571205613, -0.0014510737755000194, 0.00890780024827957, 0.33705709432803516, -0.0015964455047289025, -0.0015191413102943222, -0.0014756820718300225, 0.00793692310764811]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004501910897971835, 0.005846350702533575, 6.7739031859025e-05, 6.60284303415438e-05, 0.4997233491074511, -0.01026917490178233, 8.158935114078193e-05, 7.336268383232702e-05, 6.851843576079656e-05, 0.4998403262608914]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32641863632388335, 0.32547748225069806, -0.0014640924045608435, -0.0014470347101183487, 0.010214525717763196, 0.3361323883294615, -0.0015919779794234335, -0.0015149014985479004, -0.001471570861136008, 0.009246544831980338]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004501910897971835, 0.005846350702533575, 6.7739031859025e-05, 6.60284303415438e-05, 0.4997233491074511, -0.01026917490178233, 8.158935114078193e-05, 7.336268383232702e-05, 6.851843576079656e-05, 0.4998403262608914]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 97 total loss: 0.600025275803127\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.33690291365121244, 0.3358957535383561, -0.0013745507046460715, -0.0013585239948617814, -0.006126965224082009, 0.34739717490669686, -0.0014947444027701567, -0.001422308246455664, -0.0013815782366658391, -0.007037171286784071]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.3272984329532961, 0.3263590981719491, -0.0013330385121579867, -0.0013175205922241456, 0.008489852032454254, 0.3370626924001444, -0.0014493935309015985, -0.001379268093537422, -0.0013398422862754527, 0.007608987457252792]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004509339952923922, 0.005849490958360533, 6.211062532665725e-05, 6.052904560821923e-05, 0.4997344422592933, -0.010260431029317727, 7.476662493108231e-05, 6.72330094415979e-05, 6.282694652795215e-05, 0.4998396916069046]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32643632982370385, 0.32550308307901377, -0.0013293123563994582, -0.0013138401057043998, 0.009801865070730501, 0.3361350639325742, -0.0014453228133066217, -0.001375404787264445, -0.0013360960458924753, 0.008923634202545253]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004509339952923922, 0.005849490958360533, 6.211062532665725e-05, 6.052904560821923e-05, 0.4997344422592933, -0.010260431029317727, 7.476662493108231e-05, 6.72330094415979e-05, 6.282694652795215e-05, 0.4998396916069046]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 98 total loss: 0.6000207099754261\n",
            "Accuracy:0.4\n",
            "yi_one [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "probs_list [0.3369140121244263, 0.3359141989310267, -0.0012474205276361112, -0.0012328827214888552, -0.006507203323251631, 0.3473932506681455, -0.0013564538192640076, -0.0012907442924560252, -0.0012537953573693132, -0.007332961682132481]\n",
            "yi_one.index(max(yi_one)) 5\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32731497671237875, 0.32638266252766635, -0.0012097540789353471, -0.0011956781941928176, 0.008112358927523806, 0.3370651727926609, -0.00131530512511433, -0.0012516920903290526, -0.001215925843862935, 0.007313184372204805]\n",
            "yi_one.index(max(yi_one)) 0\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "probs_list [0.004514983761012921, 0.005852551766866915, 5.690750248245853e-05, 5.544971953973702e-05, 0.4997445270492724, -0.010251335824787584, 6.845872315763532e-05, 6.15701313625764e-05, 5.756447763209724e-05, 0.4998393226934607]\n",
            "yi_one.index(max(yi_one)) 4\n",
            "probs_list.index(max(probs_list)) 9\n",
            "yi_one [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "probs_list [0.32645040390448093, 0.32552416926890715, -0.0012063615102116307, -0.0011923272301375672, 0.009429124148487967, 0.3361349360651468, -0.0013115989150093372, -0.0012481747085715967, -0.0012125149853526266, 0.008632343962259556]\n",
            "yi_one.index(max(yi_one)) 1\n",
            "probs_list.index(max(probs_list)) 5\n",
            "yi_one [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "probs_list [0.004514983761012921, 0.005852551766866915, 5.690750248245853e-05, 5.544971953973702e-05, 0.4997445270492724, -0.010251335824787584, 6.845872315763532e-05, 6.15701313625764e-05, 5.756447763209724e-05, 0.4998393226934607]\n",
            "yi_one.index(max(yi_one)) 9\n",
            "probs_list.index(max(probs_list)) 9\n",
            "Iteration 99 total loss: 0.6000169693763086\n",
            "Accuracy:0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Draft 3b.\n",
        "-  make the model train each example one by one.\n",
        "- Use softmax to get probabilities instead of dividing by the total."
      ],
      "metadata": {
        "id": "QmEZSdAU1MpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def softmax(scores):\n",
        "#     print('scores',scores)\n",
        "#     exp_scores = [math.exp(score.data) for score in scores]\n",
        "#     sum_exp_scores = sum(exp_scores)\n",
        "#     return [Value(exp_score / sum_exp_scores) for exp_score in exp_scores]\n",
        "\n",
        "def softmax(scores):\n",
        "    max_score = max(scores, key=lambda x: x.data)\n",
        "    exp_scores = [math.exp(score.data - max_score.data) for score in scores]\n",
        "    sum_exp_scores = sum(exp_scores)\n",
        "    return [Value(exp_score / sum_exp_scores) for exp_score in exp_scores]\n",
        "\n",
        "# define the MLP model\n",
        "in_inputs=28*28\n",
        "output_dim = len(unique_integers)\n",
        "model = MLP(in_inputs, [6,6,output_dim])\n",
        "\n",
        "# limit training set to overfit\n",
        "# on smaller test size.\n",
        "limit_x=5\n",
        "\n",
        "# reshape here to flatten the 2D [28,28] into 1D -> 28*28\n",
        "inputs = train_X[:limit_x].reshape(limit_x,-1)\n",
        "expected_outputs = yy_one[:limit_x]\n",
        "\n",
        "parameters_data_log = []\n",
        "parameters_grad_log = []\n",
        "# Begin gradient descent iterations\n",
        "iterations = 15\n",
        "for iter in range(iterations):\n",
        "  parameters_data_log.append([])\n",
        "  parameters_grad_log.append([])\n",
        "  # forward the model one input at a time to get scores\n",
        "  correct = 0\n",
        "  for i_input in range(len(inputs)):\n",
        "    scores = model(inputs[i_input])\n",
        "    # print('raw scores',scores)\n",
        "    probs_predicted = softmax(scores)\n",
        "    # Loss for a single input\n",
        "    # Squared Error Loss\n",
        "    yi_one = expected_outputs[i_input]\n",
        "    loss = []\n",
        "    probs_list = [p.data for p in probs_predicted]\n",
        "    # print('yi_one',yi_one)\n",
        "    # print('probs_list',probs_list)\n",
        "    # print('correct answer:',yi_one.index(max(yi_one)))\n",
        "    # print('prediction:',probs_list.index(max(probs_list)))\n",
        "    if(yi_one.index(max(yi_one)) == probs_list.index(max(probs_list))):\n",
        "      correct += 1\n",
        "    for k in range(len(yi_one)):\n",
        "      loss.append((yi_one[k]-probs_predicted[k])**2)\n",
        "    total_loss = sum(loss)\n",
        "    # Back propagation\n",
        "    model.zero_grad()\n",
        "    total_loss.backward()\n",
        "    # Update parameters\n",
        "    for p in model.parameters():\n",
        "      parameters_data_log[iter].append(p.data)\n",
        "      parameters_grad_log[iter].append(p.grad)\n",
        "      # print('p.grad',p.grad)\n",
        "      p.data -= p.grad\n",
        "  print('Iteration '+str(iter) +' total loss: '+str(total_loss.data))\n",
        "  print('Accuracy:'+str(correct/len(inputs)))"
      ],
      "metadata": {
        "id": "cxwwtOc61L3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dad752-03c5-4975-8aa9-2021c44d34a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "p.grad 0\n",
            "Iteration 14 total loss: 0.015265840608459967\n",
            "Accuracy:0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(parameters_grad_log,axis=1)\n",
        "# np.mean(parameters_data_log,axis=1)\n",
        "# np.all(parameters_grad_log)\n",
        "# for arr in parameters_grad_log:\n",
        "#   for e in arr:\n",
        "#     if e != 0:\n",
        "#       print('e',e)\n",
        "#       print('no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8x0jDAhcvp5",
        "outputId": "786bd155-6f6e-42db-f0fd-ef1c34fd320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.exp(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSg1mKNmQ6ak",
        "outputId": "afec0bf3-9571-46d1-8809-2a04bf1d5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.718281828459045"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why is back propping through softmax giving back zero gradients?\n",
        "- Why does exp_score have 0 gradients?\n",
        "- THE VALUES ARE TOO BIG and the gradients end up being zero because of exp(val1)/(exp(val1)+exp(val2)+exp(val3)). The answer is to normalize my inputs to be between 0-1 instead of 0-255.\n",
        "  - That did not work either"
      ],
      "metadata": {
        "id": "IMeDuyQemmrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "vf08xtCXQ0Sd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import from local Value Class\n",
        "from engine import Value\n",
        "\n",
        "\n",
        "# def softmax(scores):\n",
        "#     max_score = max(scores, key=lambda x: x.data)\n",
        "#     exp_scores = [math.exp (score.data - max_score.data) for score in scores]\n",
        "#     sum_exp_scores = sum(exp_scores)\n",
        "#     return [Value(exp_score / sum_exp_scores) for exp_score in exp_scores]\n",
        "\n",
        "# Trying to figure out softmax to make sure\n",
        "# that the gradients will flow through\n",
        "scores = [0.5,0.1,0.99,0.8,0.4]\n",
        "scores_value = [Value(score) for score in scores]\n",
        "# max_score = max(scores_value, key=lambda x: x.data)\n",
        "exp_scores = [(score).exp() for score in scores_value]\n",
        "sum_exp_scores = sum(exp_scores)\n",
        "result = [exp_score/sum_exp_scores for exp_score in exp_scores]\n",
        "# result = softmax(scores_value)\n",
        "total = sum(result)\n",
        "total.backward()\n",
        "print('total:',total)\n",
        "print('result:',result)\n",
        "print('sum_exp_scores',sum_exp_scores)\n",
        "print('exp_scores:',exp_scores)\n",
        "# print('max_score',max_score)\n",
        "print('scores_value',scores_value)\n",
        "total.draw_dot(total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "kdBS5GmzCeWt",
        "outputId": "8e891829-7d30-410f-d4cb-d29802832134"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total: Value(data=1.0, grad=1, _op=+)\n",
            "result: [Value(data=0.17994244568072545, grad=1, _op=*), Value(data=0.12061902847246941, grad=1, _op=*), Value(data=0.29372297274308784, grad=1, _op=*), Value(data=0.2428968951588938, grad=1, _op=*), Value(data=0.16281865794482353, grad=1, _op=*)]\n",
            "sum_exp_scores Value(data=9.162492287258775, grad=-0.10914061028903514, _op=+)\n",
            "exp_scores: [Value(data=1.6487212707001282, grad=-2.7755575615628914e-17, _op=e), Value(data=1.1051709180756477, grad=-2.7755575615628914e-17, _op=e), Value(data=2.691234472349262, grad=-2.7755575615628914e-17, _op=e), Value(data=2.225540928492468, grad=-2.7755575615628914e-17, _op=e), Value(data=1.4918246976412703, grad=-2.7755575615628914e-17, _op=e)]\n",
            "scores_value [Value(data=0.5, grad=-4.5761207898013195e-17, _op=), Value(data=0.1, grad=-3.067465498484267e-17, _op=), Value(data=0.99, grad=-7.469676189667712e-17, _op=), Value(data=0.8, grad=-6.177116952644967e-17, _op=), Value(data=0.4, grad=-4.140645320064502e-17, _op=)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"4303pt\" height=\"468pt\"\n viewBox=\"0.00 0.00 4302.88 468.34\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 464.34)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-464.34 4298.88,-464.34 4298.88,4 -4,4\"/>\n<!-- 135811838779472 -->\n<g id=\"node1\" class=\"node\">\n<title>135811838779472</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"292,-399.5 292,-435.5 458,-435.5 458,-399.5 292,-399.5\"/>\n<text text-anchor=\"middle\" x=\"332\" y=\"-413.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.6487</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"372,-399.5 372,-435.5 \"/>\n<text text-anchor=\"middle\" x=\"415\" y=\"-413.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838782160* -->\n<g id=\"node21\" class=\"node\">\n<title>135811838782160*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.88\" cy=\"-277.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 135811838779472&#45;&gt;135811838782160* -->\n<g id=\"edge55\" class=\"edge\">\n<title>135811838779472&#45;&gt;135811838782160*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M458.11,-434.49C515.96,-445 595.39,-456.5 666,-456.5 666,-456.5 666,-456.5 2054.44,-456.5 2188.61,-456.5 2243.69,-480.19 2350.88,-399.5 2367.15,-387.25 2389.44,-336.69 2402.38,-304.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2405.79,-305.52 2406.24,-294.94 2399.29,-302.94 2405.79,-305.52\"/>\n</g>\n<!-- 135811838780576+ -->\n<g id=\"node33\" class=\"node\">\n<title>135811838780576+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"521\" cy=\"-269.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"521\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838779472&#45;&gt;135811838780576+ -->\n<g id=\"edge31\" class=\"edge\">\n<title>135811838779472&#45;&gt;135811838780576+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M403.32,-399.26C420.21,-387.19 441.71,-370.34 458,-352.5 477.7,-330.93 476,-320.51 494,-297.5 495.4,-295.72 496.88,-293.91 498.41,-292.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"501.17,-294.28 505.21,-284.49 495.94,-289.63 501.17,-294.28\"/>\n</g>\n<!-- 135811838779472e -->\n<g id=\"node2\" class=\"node\">\n<title>135811838779472e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"229\" cy=\"-417.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"229\" y=\"-413.8\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- 135811838779472e&#45;&gt;135811838779472 -->\n<g id=\"edge1\" class=\"edge\">\n<title>135811838779472e&#45;&gt;135811838779472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M256.08,-417.5C263.64,-417.5 272.35,-417.5 281.56,-417.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"281.7,-421 291.7,-417.5 281.7,-414 281.7,-421\"/>\n</g>\n<!-- 135811838773424 -->\n<g id=\"node3\" class=\"node\">\n<title>135811838773424</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3556.88,-177.5 3556.88,-213.5 3718.88,-213.5 3718.88,-177.5 3556.88,-177.5\"/>\n<text text-anchor=\"middle\" x=\"3596.88\" y=\"-191.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.5943</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3636.88,-177.5 3636.88,-213.5 \"/>\n<text text-anchor=\"middle\" x=\"3677.88\" y=\"-191.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838773184+ -->\n<g id=\"node55\" class=\"node\">\n<title>135811838773184+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"3781.88\" cy=\"-195.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"3781.88\" y=\"-191.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838773424&#45;&gt;135811838773184+ -->\n<g id=\"edge44\" class=\"edge\">\n<title>135811838773424&#45;&gt;135811838773184+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3719.01,-195.5C3727.84,-195.5 3736.47,-195.5 3744.35,-195.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3744.58,-199 3754.58,-195.5 3744.58,-192 3744.58,-199\"/>\n</g>\n<!-- 135811838773424+ -->\n<g id=\"node4\" class=\"node\">\n<title>135811838773424+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"3493.88\" cy=\"-195.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"3493.88\" y=\"-191.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838773424+&#45;&gt;135811838773424 -->\n<g id=\"edge2\" class=\"edge\">\n<title>135811838773424+&#45;&gt;135811838773424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3520.93,-195.5C3528.51,-195.5 3537.26,-195.5 3546.48,-195.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3546.64,-199 3556.64,-195.5 3546.64,-192 3546.64,-199\"/>\n</g>\n<!-- 135811838781680 -->\n<g id=\"node5\" class=\"node\">\n<title>135811838781680</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1752,-204.5 1752,-240.5 1918,-240.5 1918,-204.5 1752,-204.5\"/>\n<text text-anchor=\"middle\" x=\"1792\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 9.1625</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1832,-204.5 1832,-240.5 \"/>\n<text text-anchor=\"middle\" x=\"1875\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 1358118387819209.162492287258775**&#45;1 -->\n<g id=\"node14\" class=\"node\">\n<title>1358118387819209.162492287258775**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2053.44\" cy=\"-277.5\" rx=\"99.38\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2053.44\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">9.162492287258775**&#45;1</text>\n</g>\n<!-- 135811838781680&#45;&gt;1358118387819209.162492287258775**&#45;1 -->\n<g id=\"edge62\" class=\"edge\">\n<title>135811838781680&#45;&gt;1358118387819209.162492287258775**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1906.87,-240.51C1932.01,-246.9 1960.22,-254.07 1985.06,-260.38\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1984.21,-263.77 1994.76,-262.84 1985.93,-256.99 1984.21,-263.77\"/>\n</g>\n<!-- 1358118387824009.162492287258775**&#45;1 -->\n<g id=\"node28\" class=\"node\">\n<title>1358118387824009.162492287258775**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2053.44\" cy=\"-222.5\" rx=\"99.38\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2053.44\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">9.162492287258775**&#45;1</text>\n</g>\n<!-- 135811838781680&#45;&gt;1358118387824009.162492287258775**&#45;1 -->\n<g id=\"edge28\" class=\"edge\">\n<title>135811838781680&#45;&gt;1358118387824009.162492287258775**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1918.14,-222.5C1926.47,-222.5 1935.03,-222.5 1943.59,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1943.63,-226 1953.63,-222.5 1943.63,-219 1943.63,-226\"/>\n</g>\n<!-- 1358118387744809.162492287258775**&#45;1 -->\n<g id=\"node37\" class=\"node\">\n<title>1358118387744809.162492287258775**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2053.44\" cy=\"-371.5\" rx=\"99.38\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2053.44\" y=\"-367.8\" font-family=\"Times,serif\" font-size=\"14.00\">9.162492287258775**&#45;1</text>\n</g>\n<!-- 135811838781680&#45;&gt;1358118387744809.162492287258775**&#45;1 -->\n<g id=\"edge43\" class=\"edge\">\n<title>135811838781680&#45;&gt;1358118387744809.162492287258775**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1862.19,-240.81C1886.07,-257.48 1922.35,-282.73 1954,-304.5 1975.27,-319.13 1999.21,-335.43 2018.16,-348.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2016.25,-351.22 2026.49,-353.94 2020.18,-345.43 2016.25,-351.22\"/>\n</g>\n<!-- 1358118387828809.162492287258775**&#45;1 -->\n<g id=\"node41\" class=\"node\">\n<title>1358118387828809.162492287258775**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2053.44\" cy=\"-168.5\" rx=\"99.38\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2053.44\" y=\"-164.8\" font-family=\"Times,serif\" font-size=\"14.00\">9.162492287258775**&#45;1</text>\n</g>\n<!-- 135811838781680&#45;&gt;1358118387828809.162492287258775**&#45;1 -->\n<g id=\"edge40\" class=\"edge\">\n<title>135811838781680&#45;&gt;1358118387828809.162492287258775**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1908.37,-204.44C1932.89,-198.33 1960.18,-191.52 1984.35,-185.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1985.29,-188.86 1994.15,-183.04 1983.6,-182.07 1985.29,-188.86\"/>\n</g>\n<!-- 1358118387833609.162492287258775**&#45;1 -->\n<g id=\"node53\" class=\"node\">\n<title>1358118387833609.162492287258775**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2053.44\" cy=\"-113.5\" rx=\"99.38\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2053.44\" y=\"-109.8\" font-family=\"Times,serif\" font-size=\"14.00\">9.162492287258775**&#45;1</text>\n</g>\n<!-- 135811838781680&#45;&gt;1358118387833609.162492287258775**&#45;1 -->\n<g id=\"edge46\" class=\"edge\">\n<title>135811838781680&#45;&gt;1358118387833609.162492287258775**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1857.73,-204.35C1880.46,-186.17 1917.79,-158.52 1954,-141.5 1962.65,-137.43 1972.02,-133.84 1981.41,-130.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1982.72,-133.96 1991.18,-127.59 1980.59,-127.29 1982.72,-133.96\"/>\n</g>\n<!-- 135811838781680+ -->\n<g id=\"node6\" class=\"node\">\n<title>135811838781680+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1689\" cy=\"-222.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1689\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838781680+&#45;&gt;135811838781680 -->\n<g id=\"edge3\" class=\"edge\">\n<title>135811838781680+&#45;&gt;135811838781680</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1716.08,-222.5C1723.64,-222.5 1732.35,-222.5 1741.56,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1741.7,-226 1751.7,-222.5 1741.7,-219 1741.7,-226\"/>\n</g>\n<!-- 135811838779664 -->\n<g id=\"node7\" class=\"node\">\n<title>135811838779664</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"584,-306.5 584,-342.5 750,-342.5 750,-306.5 584,-306.5\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.1052</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"664,-306.5 664,-342.5 \"/>\n<text text-anchor=\"middle\" x=\"707\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838782640* -->\n<g id=\"node35\" class=\"node\">\n<title>135811838782640*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.88\" cy=\"-222.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 135811838779664&#45;&gt;135811838782640* -->\n<g id=\"edge49\" class=\"edge\">\n<title>135811838779664&#45;&gt;135811838782640*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M750.19,-324.5C808.25,-324.5 887.89,-324.5 958,-324.5 958,-324.5 958,-324.5 2054.44,-324.5 2186.49,-324.5 2236.62,-370.69 2350.88,-304.5 2375.84,-290.04 2369.01,-273.14 2386.88,-250.5 2388.28,-248.72 2389.78,-246.92 2391.31,-245.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2394.07,-247.3 2398.12,-237.51 2388.85,-242.64 2394.07,-247.3\"/>\n</g>\n<!-- 135811838780816+ -->\n<g id=\"node39\" class=\"node\">\n<title>135811838780816+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"813\" cy=\"-269.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"813\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838779664&#45;&gt;135811838780816+ -->\n<g id=\"edge63\" class=\"edge\">\n<title>135811838779664&#45;&gt;135811838780816+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M722.92,-306.44C732.01,-303.25 741.3,-299.87 750,-296.5 760.18,-292.55 771.15,-287.91 780.98,-283.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"782.65,-286.69 790.37,-279.43 779.81,-280.29 782.65,-286.69\"/>\n</g>\n<!-- 135811838779664e -->\n<g id=\"node8\" class=\"node\">\n<title>135811838779664e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"521\" cy=\"-324.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"521\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- 135811838779664e&#45;&gt;135811838779664 -->\n<g id=\"edge4\" class=\"edge\">\n<title>135811838779664e&#45;&gt;135811838779664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.08,-324.5C555.64,-324.5 564.35,-324.5 573.56,-324.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"573.7,-328 583.7,-324.5 573.7,-321 573.7,-328\"/>\n</g>\n<!-- 135811838773664 -->\n<g id=\"node9\" class=\"node\">\n<title>135811838773664</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3268.88,-204.5 3268.88,-240.5 3430.88,-240.5 3430.88,-204.5 3268.88,-204.5\"/>\n<text text-anchor=\"middle\" x=\"3308.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.3006</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3348.88,-204.5 3348.88,-240.5 \"/>\n<text text-anchor=\"middle\" x=\"3389.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838773664&#45;&gt;135811838773424+ -->\n<g id=\"edge53\" class=\"edge\">\n<title>135811838773664&#45;&gt;135811838773424+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3431.01,-207.26C3440.39,-205.48 3449.55,-203.74 3457.83,-202.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3458.62,-205.58 3467.79,-200.27 3457.31,-198.7 3458.62,-205.58\"/>\n</g>\n<!-- 135811838773664+ -->\n<g id=\"node10\" class=\"node\">\n<title>135811838773664+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"3151.88\" cy=\"-222.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"3151.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838773664+&#45;&gt;135811838773664 -->\n<g id=\"edge5\" class=\"edge\">\n<title>135811838773664+&#45;&gt;135811838773664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3178.91,-222.5C3199.5,-222.5 3229.53,-222.5 3258.64,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3258.88,-226 3268.88,-222.5 3258.88,-219 3258.88,-226\"/>\n</g>\n<!-- 135811838779856 -->\n<g id=\"node11\" class=\"node\">\n<title>135811838779856</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"876,-114.5 876,-150.5 1042,-150.5 1042,-114.5 876,-114.5\"/>\n<text text-anchor=\"middle\" x=\"916\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.6912</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"956,-114.5 956,-150.5 \"/>\n<text text-anchor=\"middle\" x=\"999\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838783120* -->\n<g id=\"node45\" class=\"node\">\n<title>135811838783120*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.88\" cy=\"-167.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.88\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 135811838779856&#45;&gt;135811838783120* -->\n<g id=\"edge39\" class=\"edge\">\n<title>135811838779856&#45;&gt;135811838783120*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1007.71,-114.46C1064.55,-94.61 1162.8,-65.5 1250,-65.5 1250,-65.5 1250,-65.5 2054.44,-65.5 2186.46,-65.5 2236.81,-18.03 2350.88,-84.5 2376.12,-99.21 2368.88,-116.49 2386.88,-139.5 2388.28,-141.28 2389.76,-143.09 2391.29,-144.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2388.83,-147.37 2398.09,-152.51 2394.05,-142.72 2388.83,-147.37\"/>\n</g>\n<!-- 135811838781104+ -->\n<g id=\"node47\" class=\"node\">\n<title>135811838781104+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1105\" cy=\"-155.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1105\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838779856&#45;&gt;135811838781104+ -->\n<g id=\"edge50\" class=\"edge\">\n<title>135811838779856&#45;&gt;135811838781104+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1042.1,-145.61C1051.42,-147.1 1060.52,-148.55 1068.74,-149.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1068.21,-153.33 1078.64,-151.45 1069.32,-146.42 1068.21,-153.33\"/>\n</g>\n<!-- 135811838779856e -->\n<g id=\"node12\" class=\"node\">\n<title>135811838779856e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"813\" cy=\"-132.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"813\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- 135811838779856e&#45;&gt;135811838779856 -->\n<g id=\"edge6\" class=\"edge\">\n<title>135811838779856e&#45;&gt;135811838779856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M840.08,-132.5C847.64,-132.5 856.35,-132.5 865.56,-132.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"865.7,-136 875.7,-132.5 865.7,-129 865.7,-136\"/>\n</g>\n<!-- 135811838781920 -->\n<g id=\"node13\" class=\"node\">\n<title>135811838781920</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2188.88,-259.5 2188.88,-295.5 2350.88,-295.5 2350.88,-259.5 2188.88,-259.5\"/>\n<text text-anchor=\"middle\" x=\"2228.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1091</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2268.88,-259.5 2268.88,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"2309.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.6487</text>\n</g>\n<!-- 135811838781920&#45;&gt;135811838782160* -->\n<g id=\"edge37\" class=\"edge\">\n<title>135811838781920&#45;&gt;135811838782160*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2351.01,-277.5C2359.84,-277.5 2368.47,-277.5 2376.35,-277.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.58,-281 2386.58,-277.5 2376.58,-274 2376.58,-281\"/>\n</g>\n<!-- 1358118387819209.162492287258775**&#45;1&#45;&gt;135811838781920 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1358118387819209.162492287258775**&#45;1&#45;&gt;135811838781920</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2153.19,-277.5C2161.63,-277.5 2170.14,-277.5 2178.51,-277.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2178.63,-281 2188.63,-277.5 2178.63,-274 2178.63,-281\"/>\n</g>\n<!-- 135811838745120 -->\n<g id=\"node15\" class=\"node\">\n<title>135811838745120</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"292,-306.5 292,-342.5 458,-342.5 458,-306.5 292,-306.5\"/>\n<text text-anchor=\"middle\" x=\"332\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"372,-306.5 372,-342.5 \"/>\n<text text-anchor=\"middle\" x=\"415\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838745120&#45;&gt;135811838779664e -->\n<g id=\"edge47\" class=\"edge\">\n<title>135811838745120&#45;&gt;135811838779664e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M458.1,-324.5C466.95,-324.5 475.6,-324.5 483.5,-324.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"483.73,-328 493.73,-324.5 483.73,-321 483.73,-328\"/>\n</g>\n<!-- 135811838780048 -->\n<g id=\"node16\" class=\"node\">\n<title>135811838780048</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1168,-0.5 1168,-36.5 1334,-36.5 1334,-0.5 1168,-0.5\"/>\n<text text-anchor=\"middle\" x=\"1208\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.2255</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1248,-0.5 1248,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"1291\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838774720* -->\n<g id=\"node43\" class=\"node\">\n<title>135811838774720*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.88\" cy=\"-112.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.88\" y=\"-108.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 135811838780048&#45;&gt;135811838774720* -->\n<g id=\"edge61\" class=\"edge\">\n<title>135811838780048&#45;&gt;135811838774720*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1334.18,-20.67C1392.24,-22.02 1471.88,-23.5 1542,-23.5 1542,-23.5 1542,-23.5 2054.44,-23.5 2186.78,-23.5 2230.91,4.36 2350.88,-51.5 2368.57,-59.73 2384.19,-75.19 2395.33,-88.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2392.69,-90.78 2401.67,-96.4 2398.15,-86.41 2392.69,-90.78\"/>\n</g>\n<!-- 135811838781392+ -->\n<g id=\"node57\" class=\"node\">\n<title>135811838781392+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1397\" cy=\"-155.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1397\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838780048&#45;&gt;135811838781392+ -->\n<g id=\"edge32\" class=\"edge\">\n<title>135811838780048&#45;&gt;135811838781392+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1271.12,-36.69C1297.56,-61.84 1345.18,-107.15 1373.36,-133.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1371.1,-136.64 1380.76,-141 1375.93,-131.57 1371.1,-136.64\"/>\n</g>\n<!-- 135811838780048e -->\n<g id=\"node17\" class=\"node\">\n<title>135811838780048e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1105\" cy=\"-18.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1105\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- 135811838780048e&#45;&gt;135811838780048 -->\n<g id=\"edge8\" class=\"edge\">\n<title>135811838780048e&#45;&gt;135811838780048</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1132.08,-18.5C1139.64,-18.5 1148.35,-18.5 1157.56,-18.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1157.7,-22 1167.7,-18.5 1157.7,-15 1157.7,-22\"/>\n</g>\n<!-- 135811838773904 -->\n<g id=\"node18\" class=\"node\">\n<title>135811838773904</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2872.88,-259.5 2872.88,-295.5 3034.88,-295.5 3034.88,-259.5 2872.88,-259.5\"/>\n<text text-anchor=\"middle\" x=\"2912.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1799</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2952.88,-259.5 2952.88,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"2993.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838773904&#45;&gt;135811838773664+ -->\n<g id=\"edge45\" class=\"edge\">\n<title>135811838773904&#45;&gt;135811838773664+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3019.06,-259.49C3051.73,-250.32 3090.11,-239.55 3117.01,-232\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3118.04,-235.35 3126.72,-229.28 3116.15,-228.61 3118.04,-235.35\"/>\n</g>\n<!-- 135811838773904+ -->\n<g id=\"node19\" class=\"node\">\n<title>135811838773904+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2755.88\" cy=\"-277.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2755.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838773904+&#45;&gt;135811838773904 -->\n<g id=\"edge9\" class=\"edge\">\n<title>135811838773904+&#45;&gt;135811838773904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2782.91,-277.5C2803.5,-277.5 2833.53,-277.5 2862.64,-277.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2862.88,-281 2872.88,-277.5 2862.88,-274 2862.88,-281\"/>\n</g>\n<!-- 135811838782160 -->\n<g id=\"node20\" class=\"node\">\n<title>135811838782160</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2476.88,-251.5 2476.88,-287.5 2638.88,-287.5 2638.88,-251.5 2476.88,-251.5\"/>\n<text text-anchor=\"middle\" x=\"2516.88\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1799</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2556.88,-251.5 2556.88,-287.5 \"/>\n<text text-anchor=\"middle\" x=\"2597.88\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838782160&#45;&gt;135811838773904+ -->\n<g id=\"edge51\" class=\"edge\">\n<title>135811838782160&#45;&gt;135811838773904+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2638.89,-272.77C2666.48,-273.89 2696.05,-275.1 2718.43,-276.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2718.35,-279.51 2728.48,-276.42 2718.63,-272.52 2718.35,-279.51\"/>\n</g>\n<!-- 135811838782160*&#45;&gt;135811838782160 -->\n<g id=\"edge10\" class=\"edge\">\n<title>135811838782160*&#45;&gt;135811838782160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2440.93,-276.03C2448.51,-275.61 2457.26,-275.11 2466.48,-274.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2466.85,-278.08 2476.64,-274.02 2466.46,-271.09 2466.85,-278.08\"/>\n</g>\n<!-- 135811838745312 -->\n<g id=\"node22\" class=\"node\">\n<title>135811838745312</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"584,-114.5 584,-150.5 750,-150.5 750,-114.5 584,-114.5\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.9900</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"664,-114.5 664,-150.5 \"/>\n<text text-anchor=\"middle\" x=\"707\" y=\"-128.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838745312&#45;&gt;135811838779856e -->\n<g id=\"edge65\" class=\"edge\">\n<title>135811838745312&#45;&gt;135811838779856e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M750.1,-132.5C758.95,-132.5 767.6,-132.5 775.5,-132.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"775.73,-136 785.73,-132.5 775.73,-129 775.73,-136\"/>\n</g>\n<!-- 135811838774000 -->\n<g id=\"node23\" class=\"node\">\n<title>135811838774000</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2476.88,-306.5 2476.88,-342.5 2638.88,-342.5 2638.88,-306.5 2476.88,-306.5\"/>\n<text text-anchor=\"middle\" x=\"2516.88\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2556.88,-306.5 2556.88,-342.5 \"/>\n<text text-anchor=\"middle\" x=\"2597.88\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838774000&#45;&gt;135811838773904+ -->\n<g id=\"edge36\" class=\"edge\">\n<title>135811838774000&#45;&gt;135811838773904+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2634.1,-306.46C2663.82,-299.34 2696.49,-291.5 2720.35,-285.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2721.42,-289.12 2730.33,-283.39 2719.79,-282.32 2721.42,-289.12\"/>\n</g>\n<!-- 135811838780240 -->\n<g id=\"node24\" class=\"node\">\n<title>135811838780240</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1460,-372.5 1460,-408.5 1626,-408.5 1626,-372.5 1460,-372.5\"/>\n<text text-anchor=\"middle\" x=\"1500\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.4918</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1540,-372.5 1540,-408.5 \"/>\n<text text-anchor=\"middle\" x=\"1583\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838780240&#45;&gt;135811838781680+ -->\n<g id=\"edge58\" class=\"edge\">\n<title>135811838780240&#45;&gt;135811838781680+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1559.68,-372.2C1585.89,-341.63 1638.57,-280.17 1667.61,-246.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1670.61,-248.17 1674.46,-238.3 1665.29,-243.61 1670.61,-248.17\"/>\n</g>\n<!-- 135811838774240* -->\n<g id=\"node30\" class=\"node\">\n<title>135811838774240*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2413.88\" cy=\"-371.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2413.88\" y=\"-367.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 135811838780240&#45;&gt;135811838774240* -->\n<g id=\"edge33\" class=\"edge\">\n<title>135811838780240&#45;&gt;135811838774240*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1626.3,-402.7C1684.24,-410.25 1763.69,-418.5 1834,-418.5 1834,-418.5 1834,-418.5 2054.44,-418.5 2186.46,-418.5 2222.77,-431.41 2350.88,-399.5 2361.91,-396.75 2373.41,-392.11 2383.47,-387.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2385.18,-390.45 2392.61,-382.9 2382.09,-384.17 2385.18,-390.45\"/>\n</g>\n<!-- 135811838780240e -->\n<g id=\"node25\" class=\"node\">\n<title>135811838780240e</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1397\" cy=\"-390.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1397\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">e</text>\n</g>\n<!-- 135811838780240e&#45;&gt;135811838780240 -->\n<g id=\"edge11\" class=\"edge\">\n<title>135811838780240e&#45;&gt;135811838780240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1424.08,-390.5C1431.64,-390.5 1440.35,-390.5 1449.56,-390.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1449.7,-394 1459.7,-390.5 1449.7,-387 1449.7,-394\"/>\n</g>\n<!-- 135811874231184 -->\n<g id=\"node26\" class=\"node\">\n<title>135811874231184</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-399.5 0,-435.5 166,-435.5 166,-399.5 0,-399.5\"/>\n<text text-anchor=\"middle\" x=\"40\" y=\"-413.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.5000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"80,-399.5 80,-435.5 \"/>\n<text text-anchor=\"middle\" x=\"123\" y=\"-413.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811874231184&#45;&gt;135811838779472e -->\n<g id=\"edge27\" class=\"edge\">\n<title>135811874231184&#45;&gt;135811838779472e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.1,-417.5C174.95,-417.5 183.6,-417.5 191.5,-417.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"191.73,-421 201.73,-417.5 191.73,-414 191.73,-421\"/>\n</g>\n<!-- 135811838782400 -->\n<g id=\"node27\" class=\"node\">\n<title>135811838782400</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2188.88,-204.5 2188.88,-240.5 2350.88,-240.5 2350.88,-204.5 2188.88,-204.5\"/>\n<text text-anchor=\"middle\" x=\"2228.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1091</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2268.88,-204.5 2268.88,-240.5 \"/>\n<text text-anchor=\"middle\" x=\"2309.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.1052</text>\n</g>\n<!-- 135811838782400&#45;&gt;135811838782640* -->\n<g id=\"edge60\" class=\"edge\">\n<title>135811838782400&#45;&gt;135811838782640*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2351.01,-222.5C2359.84,-222.5 2368.47,-222.5 2376.35,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.58,-226 2386.58,-222.5 2376.58,-219 2376.58,-226\"/>\n</g>\n<!-- 1358118387824009.162492287258775**&#45;1&#45;&gt;135811838782400 -->\n<g id=\"edge12\" class=\"edge\">\n<title>1358118387824009.162492287258775**&#45;1&#45;&gt;135811838782400</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2153.19,-222.5C2161.63,-222.5 2170.14,-222.5 2178.51,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2178.63,-226 2188.63,-222.5 2178.63,-219 2178.63,-226\"/>\n</g>\n<!-- 135811838774240 -->\n<g id=\"node29\" class=\"node\">\n<title>135811838774240</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2674.88,-333.5 2674.88,-369.5 2836.88,-369.5 2836.88,-333.5 2674.88,-333.5\"/>\n<text text-anchor=\"middle\" x=\"2714.88\" y=\"-347.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1628</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2754.88,-333.5 2754.88,-369.5 \"/>\n<text text-anchor=\"middle\" x=\"2795.88\" y=\"-347.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838772944+ -->\n<g id=\"node49\" class=\"node\">\n<title>135811838772944+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"4069.88\" cy=\"-277.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"4069.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 135811838774240&#45;&gt;135811838772944+ -->\n<g id=\"edge38\" class=\"edge\">\n<title>135811838774240&#45;&gt;135811838772944+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2837.17,-344.06C2916.73,-337.34 3042.11,-328.5 3150.88,-328.5 3150.88,-328.5 3150.88,-328.5 3782.88,-328.5 3875.32,-328.5 3981.99,-302.36 4035.14,-287.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4036.37,-290.8 4045.03,-284.7 4034.46,-284.06 4036.37,-290.8\"/>\n</g>\n<!-- 135811838774240*&#45;&gt;135811838774240 -->\n<g id=\"edge13\" class=\"edge\">\n<title>135811838774240*&#45;&gt;135811838774240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2441,-369.96C2488.15,-367.19 2589.55,-361.23 2664.4,-356.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2665,-360.29 2674.78,-356.21 2664.59,-353.31 2665,-360.29\"/>\n</g>\n<!-- 135811838780480 -->\n<g id=\"node31\" class=\"node\">\n<title>135811838780480</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"292,-251.5 292,-287.5 458,-287.5 458,-251.5 292,-251.5\"/>\n<text text-anchor=\"middle\" x=\"332\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"372,-251.5 372,-287.5 \"/>\n<text text-anchor=\"middle\" x=\"415\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 135811838780480&#45;&gt;135811838780576+ -->\n<g id=\"edge48\" class=\"edge\">\n<title>135811838780480&#45;&gt;135811838780576+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M458.1,-269.5C466.95,-269.5 475.6,-269.5 483.5,-269.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"483.73,-273 493.73,-269.5 483.73,-266 483.73,-273\"/>\n</g>\n<!-- 135811838780576 -->\n<g id=\"node32\" class=\"node\">\n<title>135811838780576</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"584,-251.5 584,-287.5 750,-287.5 750,-251.5 584,-251.5\"/>\n<text text-anchor=\"middle\" x=\"624\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.6487</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"664,-251.5 664,-287.5 \"/>\n<text text-anchor=\"middle\" x=\"707\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 135811838780576&#45;&gt;135811838780816+ -->\n<g id=\"edge64\" class=\"edge\">\n<title>135811838780576&#45;&gt;135811838780816+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M750.1,-269.5C758.95,-269.5 767.6,-269.5 775.5,-269.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"775.73,-273 785.73,-269.5 775.73,-266 775.73,-273\"/>\n</g>\n<!-- 135811838780576+&#45;&gt;135811838780576 -->\n<g id=\"edge14\" class=\"edge\">\n<title>135811838780576+&#45;&gt;135811838780576</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.08,-269.5C555.64,-269.5 564.35,-269.5 573.56,-269.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"573.7,-273 583.7,-269.5 573.7,-266 573.7,-273\"/>\n</g>\n<!-- 135811838782640 -->\n<g id=\"node34\" class=\"node\">\n<title>135811838782640</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2872.88,-204.5 2872.88,-240.5 3034.88,-240.5 3034.88,-204.5 2872.88,-204.5\"/>\n<text text-anchor=\"middle\" x=\"2912.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1206</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2952.88,-204.5 2952.88,-240.5 \"/>\n<text text-anchor=\"middle\" x=\"2993.88\" y=\"-218.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838782640&#45;&gt;135811838773664+ -->\n<g id=\"edge59\" class=\"edge\">\n<title>135811838782640&#45;&gt;135811838773664+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3034.89,-222.5C3062.48,-222.5 3092.05,-222.5 3114.43,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3114.48,-226 3124.48,-222.5 3114.48,-219 3114.48,-226\"/>\n</g>\n<!-- 135811838782640*&#45;&gt;135811838782640 -->\n<g id=\"edge15\" class=\"edge\">\n<title>135811838782640*&#45;&gt;135811838782640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2441.2,-222.5C2516.71,-222.5 2736.72,-222.5 2862.29,-222.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2862.65,-226 2872.65,-222.5 2862.65,-219 2862.65,-226\"/>\n</g>\n<!-- 135811838774480 -->\n<g id=\"node36\" class=\"node\">\n<title>135811838774480</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2188.88,-353.5 2188.88,-389.5 2350.88,-389.5 2350.88,-353.5 2188.88,-353.5\"/>\n<text text-anchor=\"middle\" x=\"2228.88\" y=\"-367.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1091</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2268.88,-353.5 2268.88,-389.5 \"/>\n<text text-anchor=\"middle\" x=\"2309.88\" y=\"-367.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.4918</text>\n</g>\n<!-- 135811838774480&#45;&gt;135811838774240* -->\n<g id=\"edge57\" class=\"edge\">\n<title>135811838774480&#45;&gt;135811838774240*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2351.01,-371.5C2359.84,-371.5 2368.47,-371.5 2376.35,-371.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.58,-375 2386.58,-371.5 2376.58,-368 2376.58,-375\"/>\n</g>\n<!-- 1358118387744809.162492287258775**&#45;1&#45;&gt;135811838774480 -->\n<g id=\"edge16\" class=\"edge\">\n<title>1358118387744809.162492287258775**&#45;1&#45;&gt;135811838774480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2153.19,-371.5C2161.63,-371.5 2170.14,-371.5 2178.51,-371.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2178.63,-375 2188.63,-371.5 2178.63,-368 2178.63,-375\"/>\n</g>\n<!-- 135811838780816 -->\n<g id=\"node38\" class=\"node\">\n<title>135811838780816</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"876,-228.5 876,-264.5 1042,-264.5 1042,-228.5 876,-228.5\"/>\n<text text-anchor=\"middle\" x=\"916\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.7539</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"956,-228.5 956,-264.5 \"/>\n<text text-anchor=\"middle\" x=\"999\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 135811838780816&#45;&gt;135811838781104+ -->\n<g id=\"edge30\" class=\"edge\">\n<title>135811838780816&#45;&gt;135811838781104+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M988.79,-228.3C1014.23,-212.23 1051.09,-188.94 1076.22,-173.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1078.32,-175.87 1084.9,-167.57 1074.58,-169.95 1078.32,-175.87\"/>\n</g>\n<!-- 135811838780816+&#45;&gt;135811838780816 -->\n<g id=\"edge17\" class=\"edge\">\n<title>135811838780816+&#45;&gt;135811838780816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M839.41,-265.44C847.2,-264.2 856.27,-262.75 865.85,-261.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"866.67,-264.63 875.99,-259.6 865.57,-257.72 866.67,-264.63\"/>\n</g>\n<!-- 135811838782880 -->\n<g id=\"node40\" class=\"node\">\n<title>135811838782880</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2188.88,-149.5 2188.88,-185.5 2350.88,-185.5 2350.88,-149.5 2188.88,-149.5\"/>\n<text text-anchor=\"middle\" x=\"2228.88\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1091</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2268.88,-149.5 2268.88,-185.5 \"/>\n<text text-anchor=\"middle\" x=\"2309.88\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 2.6912</text>\n</g>\n<!-- 135811838782880&#45;&gt;135811838783120* -->\n<g id=\"edge42\" class=\"edge\">\n<title>135811838782880&#45;&gt;135811838783120*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2351.01,-167.5C2359.84,-167.5 2368.47,-167.5 2376.35,-167.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.58,-171 2386.58,-167.5 2376.58,-164 2376.58,-171\"/>\n</g>\n<!-- 1358118387828809.162492287258775**&#45;1&#45;&gt;135811838782880 -->\n<g id=\"edge18\" class=\"edge\">\n<title>1358118387828809.162492287258775**&#45;1&#45;&gt;135811838782880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2152.88,-168.04C2161.41,-168 2170.01,-167.96 2178.48,-167.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2178.73,-171.42 2188.72,-167.87 2178.7,-164.42 2178.73,-171.42\"/>\n</g>\n<!-- 135811838774720 -->\n<g id=\"node42\" class=\"node\">\n<title>135811838774720</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3070.88,-99.5 3070.88,-135.5 3232.88,-135.5 3232.88,-99.5 3070.88,-99.5\"/>\n<text text-anchor=\"middle\" x=\"3110.88\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.2429</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3150.88,-99.5 3150.88,-135.5 \"/>\n<text text-anchor=\"middle\" x=\"3191.88\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838774720&#45;&gt;135811838773184+ -->\n<g id=\"edge52\" class=\"edge\">\n<title>135811838774720&#45;&gt;135811838773184+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3233.12,-116C3344.18,-115.84 3550.17,-122.52 3718.88,-167.5 3729.87,-170.43 3741.35,-175.11 3751.41,-179.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3750.04,-183.04 3760.56,-184.28 3753.11,-176.75 3750.04,-183.04\"/>\n</g>\n<!-- 135811838774720*&#45;&gt;135811838774720 -->\n<g id=\"edge19\" class=\"edge\">\n<title>135811838774720*&#45;&gt;135811838774720</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2441.08,-112.68C2539.83,-113.35 2892.47,-115.74 3060.54,-116.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3060.59,-120.39 3070.61,-116.95 3060.63,-113.39 3060.59,-120.39\"/>\n</g>\n<!-- 135811838783120 -->\n<g id=\"node44\" class=\"node\">\n<title>135811838783120</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3268.88,-149.5 3268.88,-185.5 3430.88,-185.5 3430.88,-149.5 3268.88,-149.5\"/>\n<text text-anchor=\"middle\" x=\"3308.88\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.2937</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3348.88,-149.5 3348.88,-185.5 \"/>\n<text text-anchor=\"middle\" x=\"3389.88\" y=\"-163.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838783120&#45;&gt;135811838773424+ -->\n<g id=\"edge29\" class=\"edge\">\n<title>135811838783120&#45;&gt;135811838773424+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3431.01,-183.3C3440.39,-185.15 3449.55,-186.96 3457.83,-188.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3457.3,-192.05 3467.79,-190.55 3458.65,-185.18 3457.3,-192.05\"/>\n</g>\n<!-- 135811838783120*&#45;&gt;135811838783120 -->\n<g id=\"edge20\" class=\"edge\">\n<title>135811838783120*&#45;&gt;135811838783120</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2440.9,-167.5C2497.83,-167.5 2637.71,-167.5 2754.88,-167.5 2754.88,-167.5 2754.88,-167.5 2954.88,-167.5 3059.02,-167.5 3178.64,-167.5 3258.49,-167.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3258.52,-171 3268.52,-167.5 3258.52,-164 3258.52,-171\"/>\n</g>\n<!-- 135811838781104 -->\n<g id=\"node46\" class=\"node\">\n<title>135811838781104</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1168,-137.5 1168,-173.5 1334,-173.5 1334,-137.5 1168,-137.5\"/>\n<text text-anchor=\"middle\" x=\"1208\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 5.4451</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1248,-137.5 1248,-173.5 \"/>\n<text text-anchor=\"middle\" x=\"1291\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 135811838781104&#45;&gt;135811838781392+ -->\n<g id=\"edge35\" class=\"edge\">\n<title>135811838781104&#45;&gt;135811838781392+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1334.1,-155.5C1342.95,-155.5 1351.6,-155.5 1359.5,-155.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1359.73,-159 1369.73,-155.5 1359.73,-152 1359.73,-159\"/>\n</g>\n<!-- 135811838781104+&#45;&gt;135811838781104 -->\n<g id=\"edge21\" class=\"edge\">\n<title>135811838781104+&#45;&gt;135811838781104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1132.08,-155.5C1139.64,-155.5 1148.35,-155.5 1157.56,-155.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1157.7,-159 1167.7,-155.5 1157.7,-152 1157.7,-159\"/>\n</g>\n<!-- 135811838772944 -->\n<g id=\"node48\" class=\"node\">\n<title>135811838772944</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"4132.88,-259.5 4132.88,-295.5 4294.88,-295.5 4294.88,-259.5 4132.88,-259.5\"/>\n<text text-anchor=\"middle\" x=\"4172.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"4212.88,-259.5 4212.88,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"4253.88\" y=\"-273.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838772944+&#45;&gt;135811838772944 -->\n<g id=\"edge22\" class=\"edge\">\n<title>135811838772944+&#45;&gt;135811838772944</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4096.93,-277.5C4104.51,-277.5 4113.26,-277.5 4122.48,-277.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4122.64,-281 4132.64,-277.5 4122.64,-274 4122.64,-281\"/>\n</g>\n<!-- 135811838779184 -->\n<g id=\"node50\" class=\"node\">\n<title>135811838779184</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1168,-372.5 1168,-408.5 1334,-408.5 1334,-372.5 1168,-372.5\"/>\n<text text-anchor=\"middle\" x=\"1208\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.4000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1248,-372.5 1248,-408.5 \"/>\n<text text-anchor=\"middle\" x=\"1291\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838779184&#45;&gt;135811838780240e -->\n<g id=\"edge41\" class=\"edge\">\n<title>135811838779184&#45;&gt;135811838780240e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1334.1,-390.5C1342.95,-390.5 1351.6,-390.5 1359.5,-390.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1359.73,-394 1369.73,-390.5 1359.73,-387 1359.73,-394\"/>\n</g>\n<!-- 135811838779232 -->\n<g id=\"node51\" class=\"node\">\n<title>135811838779232</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"876,-0.5 876,-36.5 1042,-36.5 1042,-0.5 876,-0.5\"/>\n<text text-anchor=\"middle\" x=\"916\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.8000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"956,-0.5 956,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"999\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.0000</text>\n</g>\n<!-- 135811838779232&#45;&gt;135811838780048e -->\n<g id=\"edge56\" class=\"edge\">\n<title>135811838779232&#45;&gt;135811838780048e</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1042.1,-18.5C1050.95,-18.5 1059.6,-18.5 1067.5,-18.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1067.73,-22 1077.73,-18.5 1067.73,-15 1067.73,-22\"/>\n</g>\n<!-- 135811838783360 -->\n<g id=\"node52\" class=\"node\">\n<title>135811838783360</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2188.88,-94.5 2188.88,-130.5 2350.88,-130.5 2350.88,-94.5 2188.88,-94.5\"/>\n<text text-anchor=\"middle\" x=\"2228.88\" y=\"-108.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1091</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2268.88,-94.5 2268.88,-130.5 \"/>\n<text text-anchor=\"middle\" x=\"2309.88\" y=\"-108.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 2.2255</text>\n</g>\n<!-- 135811838783360&#45;&gt;135811838774720* -->\n<g id=\"edge54\" class=\"edge\">\n<title>135811838783360&#45;&gt;135811838774720*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2351.01,-112.5C2359.84,-112.5 2368.47,-112.5 2376.35,-112.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2376.58,-116 2386.58,-112.5 2376.58,-109 2376.58,-116\"/>\n</g>\n<!-- 1358118387833609.162492287258775**&#45;1&#45;&gt;135811838783360 -->\n<g id=\"edge23\" class=\"edge\">\n<title>1358118387833609.162492287258775**&#45;1&#45;&gt;135811838783360</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2152.88,-113.04C2161.41,-113 2170.01,-112.96 2178.48,-112.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2178.73,-116.42 2188.72,-112.87 2178.7,-109.42 2178.73,-116.42\"/>\n</g>\n<!-- 135811838773184 -->\n<g id=\"node54\" class=\"node\">\n<title>135811838773184</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"3844.88,-236.5 3844.88,-272.5 4006.88,-272.5 4006.88,-236.5 3844.88,-236.5\"/>\n<text text-anchor=\"middle\" x=\"3884.88\" y=\"-250.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.8372</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"3924.88,-236.5 3924.88,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"3965.88\" y=\"-250.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 135811838773184&#45;&gt;135811838772944+ -->\n<g id=\"edge34\" class=\"edge\">\n<title>135811838773184&#45;&gt;135811838772944+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4007.01,-267.48C4016.3,-268.98 4025.38,-270.45 4033.59,-271.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4033.06,-275.24 4043.49,-273.39 4034.18,-268.33 4033.06,-275.24\"/>\n</g>\n<!-- 135811838773184+&#45;&gt;135811838773184 -->\n<g id=\"edge24\" class=\"edge\">\n<title>135811838773184+&#45;&gt;135811838773184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3805.38,-204.85C3823.25,-212.27 3848.98,-222.96 3871.98,-232.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3870.73,-235.79 3881.31,-236.4 3873.42,-229.33 3870.73,-235.79\"/>\n</g>\n<!-- 135811838781392 -->\n<g id=\"node56\" class=\"node\">\n<title>135811838781392</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1460,-182.5 1460,-218.5 1626,-218.5 1626,-182.5 1460,-182.5\"/>\n<text text-anchor=\"middle\" x=\"1500\" y=\"-196.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 7.6707</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1540,-182.5 1540,-218.5 \"/>\n<text text-anchor=\"middle\" x=\"1583\" y=\"-196.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1091</text>\n</g>\n<!-- 135811838781392&#45;&gt;135811838781680+ -->\n<g id=\"edge26\" class=\"edge\">\n<title>135811838781392&#45;&gt;135811838781680+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1626.1,-213.04C1635.23,-214.44 1644.14,-215.8 1652.23,-217.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1651.92,-220.53 1662.34,-218.58 1652.98,-213.61 1651.92,-220.53\"/>\n</g>\n<!-- 135811838781392+&#45;&gt;135811838781392 -->\n<g id=\"edge25\" class=\"edge\">\n<title>135811838781392+&#45;&gt;135811838781392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1421.78,-162.93C1436.33,-167.48 1455.76,-173.55 1474.74,-179.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1473.71,-182.83 1484.3,-182.47 1475.79,-176.14 1473.71,-182.83\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7b8528680040>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using pytorch\n",
        "import torch\n",
        "\n",
        "# Trying to figure out softmax to make sure\n",
        "# that the gradients will flow through\n",
        "scores = torch.tensor([0.5,0.1,0.99,0.8,0.4], requires_grad=True)\n",
        "scores_value = scores\n",
        "exp_scores = [(score).exp() for score in scores_value]\n",
        "sum_exp_scores = sum(exp_scores)\n",
        "result = [exp_score/sum_exp_scores for exp_score in exp_scores]\n",
        "total = sum(result)\n",
        "total.backward()\n",
        "print('total:',total)\n",
        "print('result:',result)\n",
        "print('sum_exp_scores',sum_exp_scores)\n",
        "print('exp_scores:',exp_scores)\n",
        "print('scores_value',scores_value)"
      ],
      "metadata": {
        "id": "1sJvD1EtSPZR",
        "outputId": "9cce6ec9-d944-4134-8e9e-e28ac4a2d998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total: tensor(1.0000, grad_fn=<AddBackward0>)\n",
            "result: [tensor(0.1799, grad_fn=<DivBackward0>), tensor(0.1206, grad_fn=<DivBackward0>), tensor(0.2937, grad_fn=<DivBackward0>), tensor(0.2429, grad_fn=<DivBackward0>), tensor(0.1628, grad_fn=<DivBackward0>)]\n",
            "sum_exp_scores tensor(9.1625, grad_fn=<AddBackward0>)\n",
            "exp_scores: [tensor(1.6487, grad_fn=<ExpBackward0>), tensor(1.1052, grad_fn=<ExpBackward0>), tensor(2.6912, grad_fn=<ExpBackward0>), tensor(2.2255, grad_fn=<ExpBackward0>), tensor(1.4918, grad_fn=<ExpBackward0>)]\n",
            "scores_value tensor([0.5000, 0.1000, 0.9900, 0.8000, 0.4000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtotal = 1\n",
        "\n",
        "cmp('total',dtotal, total)"
      ],
      "metadata": {
        "id": "fhIvEuoBSCC6",
        "outputId": "13194144-d613-4aa8-c73e-70b7eae4db20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-826f62320c03>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  ex = torch.all(dt == t.grad).item()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, Tensor out)\n * (Tensor input, name dim, bool keepdim, *, Tensor out)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fa875794804b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-826f62320c03>\u001b[0m in \u001b[0;36mcmp\u001b[0;34m(s, dt, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmaxdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, Tensor out)\n * (Tensor input, name dim, bool keepdim, *, Tensor out)\n"
          ]
        }
      ]
    }
  ]
}